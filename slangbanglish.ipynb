{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2K_QNRAFZCyB",
        "outputId": "091a03bb-60d4-4f3b-d661-f22c163e7706"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-235ad4d2-7d36-43fe-aa02-0d3d5cc66dbf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-235ad4d2-7d36-43fe-aa02-0d3d5cc66dbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset.csv to dataset.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGqLbSyCT8dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM4K25zeZzQG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnFjQEEYZ7rk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "cc3fe335-8eb0-4b00-ef9d-7472f20b9021"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ae25537a5a32>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/h.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/h.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/dtaset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Pobhx74CaGuJ",
        "outputId": "5658333b-34e2-493b-87a1-a50b9946bbc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SL.                                  Comment Hate    Type\n",
              "0     1  Kanki ki der Allah sob samoy valo rake  Yes  Others\n",
              "1     2                             khanki akta  Yes  Sexual\n",
              "2     3                           Ore saniliyon  Yes  Sexual\n",
              "3     4                    Bokachoda Shangbadik  Yes   Slang\n",
              "4     5                         Balda dekhaiche  Yes   Slang"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f81da9d-844d-4d23-b8a1-8102692a71b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SL.</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Hate</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Kanki ki der Allah sob samoy valo rake</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>khanki akta</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sexual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ore saniliyon</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sexual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Bokachoda Shangbadik</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Slang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Balda dekhaiche</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Slang</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f81da9d-844d-4d23-b8a1-8102692a71b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f81da9d-844d-4d23-b8a1-8102692a71b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f81da9d-844d-4d23-b8a1-8102692a71b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b90c7c8-bbd3-476b-b11f-9ea095b9c6ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b90c7c8-bbd3-476b-b11f-9ea095b9c6ed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b90c7c8-bbd3-476b-b11f-9ea095b9c6ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data.head(\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rdcjzd3aLqu"
      },
      "outputs": [],
      "source": [
        "data['Comment'] = data['Comment'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Obe-pG151eIe",
        "outputId": "d13e1fcc-8370-415a-adc0-38ed3bbc43fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SL.                                  Comment Hate    Type\n",
              "0     1  kanki ki der allah sob samoy valo rake  Yes  Others\n",
              "1     2                             khanki akta  Yes  Sexual\n",
              "2     3                           ore saniliyon  Yes  Sexual\n",
              "3     4                    bokachoda shangbadik  Yes   Slang\n",
              "4     5                         balda dekhaiche  Yes   Slang"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99b71a26-8c2b-4c0c-a712-dae3887233af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SL.</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Hate</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>kanki ki der allah sob samoy valo rake</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>khanki akta</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sexual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>ore saniliyon</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Sexual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>bokachoda shangbadik</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Slang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>balda dekhaiche</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Slang</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99b71a26-8c2b-4c0c-a712-dae3887233af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99b71a26-8c2b-4c0c-a712-dae3887233af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99b71a26-8c2b-4c0c-a712-dae3887233af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99c44ed2-1fb2-493d-a3c4-a98b930c8c0a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99c44ed2-1fb2-493d-a3c4-a98b930c8c0a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99c44ed2-1fb2-493d-a3c4-a98b930c8c0a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxcAjIH1aN62"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO4r52tvaSTF"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "data['Hate'] = label_encoder.fit_transform(data['Hate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x2kzVrbaVUX"
      },
      "outputs": [],
      "source": [
        "data['Type'] = label_encoder.fit_transform(data['Type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6v_3QeS2aXAr",
        "outputId": "be0fa8e3-0e6b-48ab-cea5-d670c7866cb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SL.                                  Comment  Hate  Type\n",
              "0     1  Kanki ki der Allah sob samoy valo rake     1     2\n",
              "1     2                             khanki akta     1     5\n",
              "2     3                           Ore saniliyon     1     5\n",
              "3     4                    Bokachoda Shangbadik     1     6\n",
              "4     5                         Balda dekhaiche     1     6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-053b54f9-38ac-4182-8d1b-a4bd671944b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SL.</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Hate</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Kanki ki der Allah sob samoy valo rake</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>khanki akta</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ore saniliyon</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Bokachoda Shangbadik</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Balda dekhaiche</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-053b54f9-38ac-4182-8d1b-a4bd671944b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-053b54f9-38ac-4182-8d1b-a4bd671944b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-053b54f9-38ac-4182-8d1b-a4bd671944b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-313165d5-47c6-4b7e-891b-4d268d4d444f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-313165d5-47c6-4b7e-891b-4d268d4d444f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-313165d5-47c6-4b7e-891b-4d268d4d444f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "custom_stopwords = ['ki', 'e', 'ei', 'r', 'ar', 'ni', 'er', 'a', 'but', 'k', 'to', 'o', 'ai', 'by', 'the', 'way', 'kn', 'ta', 'ke', 're', 'ra', 'or']\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in custom_stopwords]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "data['Comment'] = data['Comment'].apply(remove_stopwords)\n",
        "\n"
      ],
      "metadata": {
        "id": "qjxZu29M2gTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Tv6E22eY3INd",
        "outputId": "876b9e23-b7d5-4893-cf87-9f3aecf8a6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SL.                               Comment  Hate  Type\n",
              "0     1  Kanki der Allah sob samoy valo rake     1     2\n",
              "1     2                          khanki akta     1     5\n",
              "2     3                        Ore saniliyon     1     5\n",
              "3     4                 Bokachoda Shangbadik     1     6\n",
              "4     5                      Balda dekhaiche     1     6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5789c7f-80e9-4fb0-8c63-711f6d23117b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SL.</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Hate</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Kanki der Allah sob samoy valo rake</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>khanki akta</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ore saniliyon</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Bokachoda Shangbadik</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Balda dekhaiche</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5789c7f-80e9-4fb0-8c63-711f6d23117b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5789c7f-80e9-4fb0-8c63-711f6d23117b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5789c7f-80e9-4fb0-8c63-711f6d23117b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d1d4426-9cd0-406d-a938-59ebf671f611\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d1d4426-9cd0-406d-a938-59ebf671f611')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d1d4426-9cd0-406d-a938-59ebf671f611 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eca4-tsaZxU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElBQ6JLsan0I"
      },
      "outputs": [],
      "source": [
        "comments = data['Comment'].values\n",
        "hate_labels = data['Hate'].values\n",
        "type_labels = data['Type'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hate_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyM5h_607DBs",
        "outputId": "fe0e4d13-1185-47f9-ce61-560c55cf5446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_auGRaVas7i"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(comments)\n",
        "comment_sequences = tokenizer.texts_to_sequences(comments)\n",
        "\n",
        "max_sequence_length = 85\n",
        "\n",
        "comment_sequences = pad_sequences(comment_sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(comments)\n",
        "comment_sequences = tokenizer.texts_to_sequences(comments)\n",
        "\n",
        "\n",
        "for i in range(len(comments)):\n",
        "    print(f\"Original Comment: {comments[i]}\")\n",
        "    print(f\"Tokenized Sequence: {comment_sequences[i]}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "max_sequence_length = 85\n",
        "comment_sequences = pad_sequences(comment_sequences, maxlen=max_sequence_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pScsl3zKkE8i",
        "outputId": "2f211292-c4eb-4ae3-f6e2-504cfcfb7152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Original Comment: na dada , tiple esob jinis bare na\n",
            "Tokenized Sequence: [1, 288, 9179, 369, 467, 867, 1]\n",
            "\n",
            "\n",
            "Original Comment: tahole ami tipe dim ne, dikho dada boro hoibo\n",
            "Tokenized Sequence: [113, 4, 1750, 349, 1101, 9180, 288, 18, 454]\n",
            "\n",
            "\n",
            "Original Comment: taito torta jhoira porse\n",
            "Tokenized Sequence: [9181, 9182, 9183, 611]\n",
            "\n",
            "\n",
            "Original Comment: 2 pahare jokhn aksathe bari khay\n",
            "Tokenized Sequence: [166, 3865, 3866, 9184, 751, 574]\n",
            "\n",
            "\n",
            "Original Comment: tiktok nh thakle bujtam nh je bd te atto abal cho...a ache\n",
            "Tokenized Sequence: [367, 135, 143, 9185, 135, 46, 344, 25, 608, 235, 9186, 1022, 74]\n",
            "\n",
            "\n",
            "Original Comment: ganta sone onek haslam\n",
            "Tokenized Sequence: [3863, 9187, 56, 1678]\n",
            "\n",
            "\n",
            "Original Comment: kothar majhe jokhn lal pipra jayga moto kamor dey tokhn obostha\n",
            "Tokenized Sequence: [1837, 1098, 3866, 629, 2337, 2352, 16, 1208, 264, 3096, 383]\n",
            "\n",
            "\n",
            "Original Comment: sob gaja khor obaber dine ogore gaja dilo\n",
            "Tokenized Sequence: [8, 421, 1007, 9188, 702, 9189, 421, 321]\n",
            "\n",
            "\n",
            "Original Comment: bokachoda der nobel deoa dorkar\n",
            "Tokenized Sequence: [372, 44, 1697, 9190, 100]\n",
            "\n",
            "\n",
            "Original Comment: khankir pola pagol hoigace\n",
            "Tokenized Sequence: [318, 116, 108, 9191]\n",
            "\n",
            "\n",
            "Original Comment: dudh gula cosar moto yuummy\n",
            "Tokenized Sequence: [119, 55, 9192, 16, 9193]\n",
            "\n",
            "\n",
            "Original Comment: era kon highbrit use kore janta cawaa abar oboj mon..ato boro kamna\n",
            "Tokenized Sequence: [331, 145, 9194, 403, 2, 3105, 9195, 86, 3106, 84, 43, 18, 9196]\n",
            "\n",
            "\n",
            "Original Comment: bhai faltu marka news kora off kore gali dilam na je news korche\n",
            "Tokenized Sequence: [53, 416, 325, 118, 39, 619, 2, 587, 596, 1, 46, 118, 334]\n",
            "\n",
            "\n",
            "Original Comment: norar jonno nise\n",
            "Tokenized Sequence: [9197, 28, 1324]\n",
            "\n",
            "\n",
            "Original Comment: hoy news title dey.. shala matha mota article writer..\n",
            "Tokenized Sequence: [14, 118, 9198, 264, 243, 420, 214, 9199, 9200]\n",
            "\n",
            "\n",
            "Original Comment: ami jashim uddin theke cng metre bracu giyechilam 500tk\n",
            "Tokenized Sequence: [4, 9201, 9202, 21, 9203, 9204, 9205, 9206, 9207]\n",
            "\n",
            "\n",
            "Original Comment: ajob koyekta buddhi protibondhi ase group e.\n",
            "Tokenized Sequence: [662, 9208, 3782, 1478, 45, 1379, 744]\n",
            "\n",
            "\n",
            "Original Comment: deikha chatai koira diyo\n",
            "Tokenized Sequence: [482, 9209, 99, 9210]\n",
            "\n",
            "\n",
            "Original Comment: magi der sheet lagena.\n",
            "Tokenized Sequence: [96, 44, 9211, 1348]\n",
            "\n",
            "\n",
            "Original Comment: sob test series squad tahke kinto kono somoy nei na\n",
            "Tokenized Sequence: [8, 1117, 1548, 9212, 9213, 1281, 27, 210, 277, 1]\n",
            "\n",
            "\n",
            "Original Comment: hero alam ponde lagaw molom\n",
            "Tokenized Sequence: [614, 1935, 9214, 9215, 2157]\n",
            "\n",
            "\n",
            "Original Comment: besi dami kinbn na .r oi dike iphone kohono original hoi na. chok chok ala phone bhuleyo nibn na.1 la khono jaben na .taile prb hoibo na\n",
            "Tokenized Sequence: [176, 3867, 9216, 1, 162, 57, 386, 626, 9217, 2248, 38, 1, 1465, 1465, 9218, 1844, 9219, 9220, 1, 297, 3868, 9221, 926, 1, 312, 9222, 454, 1]\n",
            "\n",
            "\n",
            "Original Comment: copy phone sobgula\n",
            "Tokenized Sequence: [807, 1844, 9223]\n",
            "\n",
            "\n",
            "Original Comment: ata gulistan kon jaiga?\n",
            "Tokenized Sequence: [102, 9224, 145, 556]\n",
            "\n",
            "\n",
            "Original Comment: akhan thaka nia bar hota parban na\n",
            "Tokenized Sequence: [9225, 292, 228, 134, 1724, 9226, 1]\n",
            "\n",
            "\n",
            "Original Comment: bai orginal charger koto\n",
            "Tokenized Sequence: [471, 9227, 3573, 33]\n",
            "\n",
            "\n",
            "Original Comment: hijratar rate koto??\n",
            "Tokenized Sequence: [2465, 374, 33]\n",
            "\n",
            "\n",
            "Original Comment: joto boro hoche tomr toto pore jache amr\n",
            "Tokenized Sequence: [337, 18, 1780, 1085, 1014, 62, 2264, 7]\n",
            "\n",
            "\n",
            "Original Comment: maigga,hijra go loge eto ki... khacchor go moto\n",
            "Tokenized Sequence: [3849, 284, 137, 615, 60, 175, 2373, 137, 16]\n",
            "\n",
            "\n",
            "Original Comment: hijra naki pisoner gulo\n",
            "Tokenized Sequence: [284, 29, 1740, 107]\n",
            "\n",
            "\n",
            "Original Comment: kono cal girl aso...thakle knock daw.....valo price debo\n",
            "Tokenized Sequence: [27, 3869, 1775, 237, 143, 2906, 376, 6, 3870, 500]\n",
            "\n",
            "\n",
            "Original Comment: shb pic baler hijra\n",
            "Tokenized Sequence: [1752, 63, 194, 284]\n",
            "\n",
            "\n",
            "Original Comment: sob khule tmr pix gulo dekhum hat marum apu\n",
            "Tokenized Sequence: [8, 279, 32, 3847, 107, 3848, 379, 2332, 19]\n",
            "\n",
            "\n",
            "Original Comment: oita chele na meye?\n",
            "Tokenized Sequence: [311, 346, 1, 50]\n",
            "\n",
            "\n",
            "Original Comment: chilllll bro\n",
            "Tokenized Sequence: [9228, 406]\n",
            "\n",
            "\n",
            "Original Comment: hijra sagoler baccha 3 tare thabraite mon chay\n",
            "Tokenized Sequence: [284, 1875, 153, 402, 721, 9229, 84, 300]\n",
            "\n",
            "\n",
            "Original Comment: bobbs gula kamor daoya dorkr\n",
            "Tokenized Sequence: [9230, 55, 1208, 3391, 9231]\n",
            "\n",
            "\n",
            "Original Comment: amr moto din 5 bar falay\n",
            "Tokenized Sequence: [7, 16, 35, 443, 134, 1330]\n",
            "\n",
            "\n",
            "Original Comment: dudh beshi barse\n",
            "Tokenized Sequence: [119, 120, 3480]\n",
            "\n",
            "\n",
            "Original Comment: sob khuila hat na mere thaka gelona my step sis\n",
            "Tokenized Sequence: [8, 1203, 379, 1, 939, 292, 9232, 1699, 1456, 3871]\n",
            "\n",
            "\n",
            "Original Comment: kih kono saririk somosha ase ...nski???\n",
            "Tokenized Sequence: [1833, 27, 3852, 2287, 45, 3853]\n",
            "\n",
            "\n",
            "Original Comment: salar beta dekhte hijra\n",
            "Tokenized Sequence: [512, 1179, 112, 284]\n",
            "\n",
            "\n",
            "Original Comment: apnare dekhlei apnare oidin j chuida disilo oitar kotha mone pore\n",
            "Tokenized Sequence: [355, 461, 355, 1944, 42, 1714, 1702, 1512, 10, 34, 62]\n",
            "\n",
            "\n",
            "Original Comment: pola na maiya!\n",
            "Tokenized Sequence: [116, 1, 150]\n",
            "\n",
            "\n",
            "Original Comment: eta tmr lage\n",
            "Tokenized Sequence: [95, 32, 47]\n",
            "\n",
            "\n",
            "Original Comment: hijra magi\n",
            "Tokenized Sequence: [284, 96]\n",
            "\n",
            "\n",
            "Original Comment: hijra\n",
            "Tokenized Sequence: [284]\n",
            "\n",
            "\n",
            "Original Comment: sathe ata meye naki\n",
            "Tokenized Sequence: [77, 102, 50, 29]\n",
            "\n",
            "\n",
            "Original Comment: eita\n",
            "Tokenized Sequence: [289]\n",
            "\n",
            "\n",
            "Original Comment: ata kon dhoroner prani?\n",
            "Tokenized Sequence: [102, 145, 1673, 2402]\n",
            "\n",
            "\n",
            "Original Comment: hijra niye ghuro kn..deshe polar ovab porche?\n",
            "Tokenized Sequence: [284, 65, 2467, 239, 875, 3856, 485, 895]\n",
            "\n",
            "\n",
            "Original Comment: halar mukher mddhe doi falay dear dorkar\n",
            "Tokenized Sequence: [563, 1847, 9233, 2257, 1330, 2370, 100]\n",
            "\n",
            "\n",
            "Original Comment: hizra\n",
            "Tokenized Sequence: [2411]\n",
            "\n",
            "\n",
            "Original Comment: diya tumi tomare codao\n",
            "Tokenized Sequence: [76, 13, 819, 2128]\n",
            "\n",
            "\n",
            "Original Comment: halar manush laganor jonno ekhon maiya saija thake\n",
            "Tokenized Sequence: [563, 67, 3854, 28, 185, 150, 3855, 114]\n",
            "\n",
            "\n",
            "Original Comment: 2jon ladies\n",
            "Tokenized Sequence: [1954, 2471]\n",
            "\n",
            "\n",
            "Original Comment: bhoday tel lagaise naki\n",
            "Tokenized Sequence: [9234, 720, 9235, 29]\n",
            "\n",
            "\n",
            "Original Comment: tumi aco kothai..\n",
            "Tokenized Sequence: [13, 9236, 687]\n",
            "\n",
            "\n",
            "Original Comment: sob mapa jacce\n",
            "Tokenized Sequence: [8, 2771, 1066]\n",
            "\n",
            "\n",
            "Original Comment: nongrami last level\n",
            "Tokenized Sequence: [2778, 426, 909]\n",
            "\n",
            "\n",
            "Original Comment: bah, khub sundor lagche\n",
            "Tokenized Sequence: [327, 51, 66, 299]\n",
            "\n",
            "\n",
            "Original Comment: vhoda dekbo\n",
            "Tokenized Sequence: [9237, 2034]\n",
            "\n",
            "\n",
            "Original Comment: medha nai bole eivabe jibon jibika, opare kintu esob dekhaya par paoa jbe na bacha...\n",
            "Tokenized Sequence: [3660, 5, 54, 2046, 559, 9238, 9239, 68, 369, 3413, 969, 9240, 1765, 1, 1349]\n",
            "\n",
            "\n",
            "Original Comment: owo sundor. vaaj dekhar jonno manusher koto opekkha khub sundor\n",
            "Tokenized Sequence: [3872, 66, 9241, 250, 28, 549, 33, 2199, 51, 66]\n",
            "\n",
            "\n",
            "Original Comment: sry bisoy secret share kora possible na\n",
            "Tokenized Sequence: [1270, 1500, 9242, 1491, 39, 1430, 1]\n",
            "\n",
            "\n",
            "Original Comment: onek din por deklam\n",
            "Tokenized Sequence: [56, 35, 72, 1180]\n",
            "\n",
            "\n",
            "Original Comment: apnr kih mone hoi nah apnr gula din din boro hoitase\n",
            "Tokenized Sequence: [222, 1833, 34, 38, 52, 222, 55, 35, 35, 18, 1155]\n",
            "\n",
            "\n",
            "Original Comment: magir bacchar dudh dekhaite shorom kore na\n",
            "Tokenized Sequence: [363, 2037, 119, 9243, 1280, 2, 1]\n",
            "\n",
            "\n",
            "Original Comment: tumar dudh gula tipte diba\n",
            "Tokenized Sequence: [281, 119, 55, 1755, 480]\n",
            "\n",
            "\n",
            "Original Comment: looking beautiful\n",
            "Tokenized Sequence: [9244, 2275]\n",
            "\n",
            "\n",
            "Original Comment: purai sexxy\n",
            "Tokenized Sequence: [291, 3873]\n",
            "\n",
            "\n",
            "Original Comment: apu brazzers apnake khujteche\n",
            "Tokenized Sequence: [19, 3430, 192, 9245]\n",
            "\n",
            "\n",
            "Original Comment: tmr inbox check koro\n",
            "Tokenized Sequence: [32, 308, 3650, 78]\n",
            "\n",
            "\n",
            "Original Comment: ahaaa babe\n",
            "Tokenized Sequence: [9246, 1174]\n",
            "\n",
            "\n",
            "Original Comment: pura khuila cobi ditay paro?\n",
            "Tokenized Sequence: [384, 1203, 2358, 9247, 595]\n",
            "\n",
            "\n",
            "Original Comment: apumoni boobs kotay tekay modified korsen\n",
            "Tokenized Sequence: [3874, 1166, 3773, 9248, 9249, 1037]\n",
            "\n",
            "\n",
            "Original Comment: ibox deowa jabe vai\n",
            "Tokenized Sequence: [9250, 2905, 126, 3]\n",
            "\n",
            "\n",
            "Original Comment: amne search korsili na?\n",
            "Tokenized Sequence: [1249, 9251, 9252, 1]\n",
            "\n",
            "\n",
            "Original Comment: sotti nam go amio khuje paina ??\n",
            "Tokenized Sequence: [555, 144, 137, 238, 1054, 1886]\n",
            "\n",
            "\n",
            "Original Comment: vaire vai shazam use korlei hoy\n",
            "Tokenized Sequence: [1729, 3, 9253, 403, 2204, 14]\n",
            "\n",
            "\n",
            "Original Comment: moja payse moja payse\n",
            "Tokenized Sequence: [224, 3875, 224, 3875]\n",
            "\n",
            "\n",
            "Original Comment: video gula dekhle depression kete jay\n",
            "Tokenized Sequence: [24, 55, 332, 9254, 910, 92]\n",
            "\n",
            "\n",
            "Original Comment: vai 3 nambar videor gantar nam\n",
            "Tokenized Sequence: [3, 402, 9255, 2455, 3011, 144]\n",
            "\n",
            "\n",
            "Original Comment: pran souch din ses\n",
            "Tokenized Sequence: [1808, 9256, 35, 225]\n",
            "\n",
            "\n",
            "Original Comment: ajo single aci\n",
            "Tokenized Sequence: [3802, 609, 960]\n",
            "\n",
            "\n",
            "Original Comment: ahh sona go amar khub kosto peye so go bolo\n",
            "Tokenized Sequence: [944, 387, 137, 9, 51, 293, 1072, 315, 137, 526]\n",
            "\n",
            "\n",
            "Original Comment: especial vedio dekhte chayle inbox\n",
            "Tokenized Sequence: [9257, 347, 112, 9258, 308]\n",
            "\n",
            "\n",
            "Original Comment: jitte na parle eta dekhe valo lagche\n",
            "Tokenized Sequence: [9259, 1, 464, 95, 73, 6, 299]\n",
            "\n",
            "\n",
            "Original Comment: last ball jei kajta korse oita thik hoinai\n",
            "Tokenized Sequence: [426, 1088, 380, 9260, 202, 311, 61, 3876]\n",
            "\n",
            "\n",
            "Original Comment: pakistan madarchod\n",
            "Tokenized Sequence: [1565, 377]\n",
            "\n",
            "\n",
            "Original Comment: uni amader college boshe ache\n",
            "Tokenized Sequence: [226, 132, 2430, 1263, 74]\n",
            "\n",
            "\n",
            "Original Comment: koste vora jibon\n",
            "Tokenized Sequence: [3202, 1039, 559]\n",
            "\n",
            "\n",
            "Original Comment: acting na kore.. original try koren .. bro\n",
            "Tokenized Sequence: [2472, 1, 2, 2248, 934, 83, 406]\n",
            "\n",
            "\n",
            "Original Comment: ora obhinoi bhalobasha name dei\n",
            "Tokenized Sequence: [158, 9261, 9262, 236, 330]\n",
            "\n",
            "\n",
            "Original Comment: vai amader mohain college ene dekhtesi\n",
            "Tokenized Sequence: [3, 132, 9263, 2430, 3831, 3680]\n",
            "\n",
            "\n",
            "Original Comment: tui valo hobe na sela\n",
            "Tokenized Sequence: [23, 6, 11, 1, 9264]\n",
            "\n",
            "\n",
            "Original Comment: vai abul basar niye akta koren plz plz plz\n",
            "Tokenized Sequence: [3, 1608, 2022, 65, 37, 83, 234, 234, 234]\n",
            "\n",
            "\n",
            "Original Comment: bhai bhai hero alom fan asy\n",
            "Tokenized Sequence: [53, 53, 614, 1416, 656, 2581]\n",
            "\n",
            "\n",
            "Original Comment: ananta jolil chai\n",
            "Tokenized Sequence: [9265, 9266, 124]\n",
            "\n",
            "\n",
            "Original Comment: vaia apnr nmbr diyen plzz plzz plzz plzz plzz plzz\n",
            "Tokenized Sequence: [455, 222, 9267, 837, 888, 888, 888, 888, 888, 888]\n",
            "\n",
            "\n",
            "Original Comment: full dekh moja pabi\n",
            "Tokenized Sequence: [811, 503, 224, 1802]\n",
            "\n",
            "\n",
            "Original Comment: borda arar mohsin clg ot jaiyene prank call\n",
            "Tokenized Sequence: [9268, 9269, 9270, 3877, 9271, 9272, 3878, 3772]\n",
            "\n",
            "\n",
            "Original Comment: tumi amake fele vedio dekho\n",
            "Tokenized Sequence: [13, 823, 832, 347, 772]\n",
            "\n",
            "\n",
            "Original Comment: ore magi tor kholer dosh\n",
            "Tokenized Sequence: [91, 96, 17, 9273, 1439]\n",
            "\n",
            "\n",
            "Original Comment: buker jomano betha, hero alam kalo pasa\n",
            "Tokenized Sequence: [3270, 9274, 1181, 614, 1935, 212, 472]\n",
            "\n",
            "\n",
            "Original Comment: ekhon tui kanna korbi?\n",
            "Tokenized Sequence: [185, 23, 1441, 826]\n",
            "\n",
            "\n",
            "Original Comment: shosta publicity\n",
            "Tokenized Sequence: [3879, 712]\n",
            "\n",
            "\n",
            "Original Comment: makeup girl gorib naki gram theke uthe asha meyeder dress up kharap ?\n",
            "Tokenized Sequence: [368, 1775, 833, 29, 9275, 21, 492, 727, 431, 164, 261, 79]\n",
            "\n",
            "\n",
            "Original Comment: manush choto toh apni kortesen\n",
            "Tokenized Sequence: [67, 129, 88, 15, 1019]\n",
            "\n",
            "\n",
            "Original Comment: amar sir ekta kotha bole..\"chodai muri khaw jaw\"\n",
            "Tokenized Sequence: [9, 994, 36, 10, 54, 3706, 9276, 1812, 597]\n",
            "\n",
            "\n",
            "Original Comment: mohila bolate problem kothay??hudai lafano baad diye have some pani\n",
            "Tokenized Sequence: [181, 9277, 433, 528, 746, 9278, 745, 49, 9279, 9280, 394]\n",
            "\n",
            "\n",
            "Original Comment: khaled kay daksi bhai alia bhatt cinse na tai kila cinbo..\n",
            "Tokenized Sequence: [9281, 3200, 9282, 53, 3880, 9283, 9284, 1, 40, 9285, 9286]\n",
            "\n",
            "\n",
            "Original Comment: ekebare hacca kota koichen vai\n",
            "Tokenized Sequence: [2270, 9287, 731, 9288, 3]\n",
            "\n",
            "\n",
            "Original Comment: vai ekn apnar pise porbo maia\n",
            "Tokenized Sequence: [3, 691, 22, 2227, 9289, 1205]\n",
            "\n",
            "\n",
            "Original Comment: ji api bujhlam taal til banailen ken\n",
            "Tokenized Sequence: [1873, 681, 502, 3812, 3333, 3758, 146]\n",
            "\n",
            "\n",
            "Original Comment: arr football khela miss universe diye hoy nah. sharadin make up pore boshe thaka arr mathar ghaam paye fele desh shunam barano arek jish. chenel i toh dekhlam answer hobe oitao script leikha dey kintu tara bolte pare nah\n",
            "Tokenized Sequence: [1367, 583, 130, 30, 180, 49, 14, 52, 2583, 792, 261, 62, 1263, 292, 1367, 1542, 9290, 1999, 832, 97, 9291, 9292, 1708, 9293, 9294, 171, 88, 278, 2473, 11, 9295, 3760, 9296, 264, 68, 287, 163, 81, 52]\n",
            "\n",
            "\n",
            "Original Comment: judi 30 min football khelen taile apner mathay taak porbe 100% sure.\n",
            "Tokenized Sequence: [2755, 1516, 1685, 583, 2719, 312, 290, 780, 9297, 2196, 989, 1911]\n",
            "\n",
            "\n",
            "Original Comment: apu fataia desen akdom\n",
            "Tokenized Sequence: [19, 9298, 9299, 679]\n",
            "\n",
            "\n",
            "Original Comment: maya kosom allahr first name sonce and maya dakce\n",
            "Tokenized Sequence: [705, 2655, 2195, 449, 236, 9300, 200, 705, 9301]\n",
            "\n",
            "\n",
            "Original Comment: ami aj dekhlam aida kothakar model kao janle janan plz?\n",
            "Tokenized Sequence: [4, 123, 278, 899, 735, 791, 3524, 1677, 2474, 234]\n",
            "\n",
            "\n",
            "Original Comment: ami miss universe bangladesh.........ka aj cinlam..\n",
            "Tokenized Sequence: [4, 30, 180, 12, 476, 123, 1473]\n",
            "\n",
            "\n",
            "Original Comment: make up artist der karonei tmi miss bangladesh hoiso...apu... noyto cheharay miss alaka hoita na\n",
            "Tokenized Sequence: [792, 261, 3881, 44, 1725, 69, 30, 12, 2475, 19, 3383, 9302, 30, 9303, 3158, 1]\n",
            "\n",
            "\n",
            "Original Comment: onara abar answer dey manusher pashe thakbo amra,goribder sahajjo korbo bla bla.otocho enar kotha shuina mone hoy kivabe arekjonke respect dite hoy uni janen na\n",
            "Tokenized Sequence: [9304, 86, 2473, 264, 549, 699, 2028, 85, 3171, 2106, 186, 2418, 2418, 9305, 9306, 10, 3882, 34, 14, 392, 9307, 784, 117, 14, 226, 688, 1]\n",
            "\n",
            "\n",
            "Original Comment: nijerei nije choto kortesen... na \"mohila\" kono kharap word na \"makeup girl\" kono disrespectful term.... 2 tar konotai jodi apnar offensive monehoy,\n",
            "Tokenized Sequence: [3361, 203, 129, 1019, 1, 181, 27, 79, 1535, 1, 368, 1775, 27, 9308, 9309, 166, 31, 9310, 98, 22, 3883, 2457]\n",
            "\n",
            "\n",
            "Original Comment: apnake makeup korleo arokom lage\n",
            "Tokenized Sequence: [192, 368, 9311, 1258, 47]\n",
            "\n",
            "\n",
            "Original Comment: nije toh purai ekta drum nijer fitness dekhchen? purai alu\n",
            "Tokenized Sequence: [203, 88, 291, 36, 9312, 147, 3533, 9313, 291, 3884]\n",
            "\n",
            "\n",
            "Original Comment: apnara onek lokjon chinse jamal bhuyan video maddome..\n",
            "Tokenized Sequence: [280, 56, 9314, 1853, 103, 797, 24, 2153]\n",
            "\n",
            "\n",
            "Original Comment: thanks jamal vai.. tar jonno apnake chinlam ajke\n",
            "Tokenized Sequence: [673, 103, 3, 31, 28, 192, 1474, 397]\n",
            "\n",
            "\n",
            "Original Comment: shauwar miss universe bangladesh tumi\n",
            "Tokenized Sequence: [9315, 30, 180, 12, 13]\n",
            "\n",
            "\n",
            "Original Comment: jb6 jonno ajke public tomare chinlo. bangladesh miss universe miss world miss mars egular level koto nimno maner sobai jane.. aise amar miss universe alien.\n",
            "Tokenized Sequence: [9316, 28, 397, 354, 819, 3885, 12, 30, 180, 30, 391, 30, 9317, 9318, 909, 33, 3638, 2048, 104, 275, 1568, 9, 30, 180, 3850]\n",
            "\n",
            "\n",
            "Original Comment: sorry not sorry apnake amio chini na j jamal bhai apaner nia kisu ekta bollo apni ekta puchka video kore nekami korlen karone ajk apnake chinlam jamal bhai apnar career banai dilo afa!\n",
            "Tokenized Sequence: [896, 757, 896, 192, 238, 1204, 1, 42, 103, 53, 9319, 228, 106, 36, 952, 15, 36, 9320, 24, 2, 9321, 905, 1160, 557, 192, 1474, 103, 53, 22, 3604, 1169, 321, 708]\n",
            "\n",
            "\n",
            "Original Comment: na chinte pare. shobai shobai chine naki? oneke nijer shob relative der chine na. karo biyer dawate 1 st time meet kore\n",
            "Tokenized Sequence: [1, 1854, 81, 434, 434, 2476, 29, 2477, 147, 127, 3574, 44, 2476, 1, 446, 879, 3212, 297, 9322, 371, 9323, 2]\n",
            "\n",
            "\n",
            "Original Comment: apni miss bangladesh? apnar post ager post gulay toh 1k reach nai omma :3 dekhsen eitai gebon xd\n",
            "Tokenized Sequence: [15, 30, 12, 22, 110, 561, 110, 9324, 88, 2469, 2317, 5, 9325, 402, 2417, 3724, 9326, 1567]\n",
            "\n",
            "\n",
            "Original Comment: apner post porena 1k likes apni hoilen miss bangladesh ... jibone first time eto likes paisen ekta video te tao jonne\n",
            "Tokenized Sequence: [290, 110, 3886, 2469, 3887, 15, 2375, 30, 12, 543, 449, 371, 60, 3887, 3001, 36, 24, 25, 302, 655]\n",
            "\n",
            "\n",
            "Original Comment: btw boin jamal bhuiyar karonei jante parlm j apni miss bangladeshu should be thankful him\n",
            "Tokenized Sequence: [1429, 335, 103, 3888, 1725, 533, 3350, 42, 15, 30, 9327, 1855, 1149, 2478, 1856]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuyan jonno tore cinlam ami tui\n",
            "Tokenized Sequence: [103, 797, 28, 216, 1473, 4, 23]\n",
            "\n",
            "\n",
            "Original Comment: tumi amr ched bal\n",
            "Tokenized Sequence: [13, 7, 3889, 48]\n",
            "\n",
            "\n",
            "Original Comment: jibone dekhio nai tomare miss bangladesh\n",
            "Tokenized Sequence: [543, 9328, 5, 819, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: kmne hoiso miss bangladesh oita shobai jane. mia tomar theke amr frnd page like beshi\n",
            "Tokenized Sequence: [296, 2475, 30, 12, 311, 434, 275, 554, 26, 21, 7, 1624, 1723, 381, 120]\n",
            "\n",
            "\n",
            "Original Comment: be thankful jamal bhai tomake mention krse nahoi tumi kon ched bal tomake manush chinto\n",
            "Tokenized Sequence: [1149, 2478, 103, 53, 339, 1843, 2440, 9329, 13, 145, 3889, 48, 339, 67, 1857]\n",
            "\n",
            "\n",
            "Original Comment: apu apne make up koren jan plz\n",
            "Tokenized Sequence: [19, 638, 792, 261, 83, 378, 234]\n",
            "\n",
            "\n",
            "Original Comment: kire tui bolos\n",
            "Tokenized Sequence: [552, 23, 3598]\n",
            "\n",
            "\n",
            "Original Comment: bolar por jansi apni miss world bangladesh\n",
            "Tokenized Sequence: [573, 72, 9330, 15, 30, 391, 12]\n",
            "\n",
            "\n",
            "Original Comment: tmi jamal vaire chino nh eta abar proudly bolteso ceh mis bd without brain no general knowledge\n",
            "Tokenized Sequence: [69, 103, 1729, 1858, 135, 95, 86, 9331, 9332, 9333, 1466, 344, 2316, 1563, 447, 9334, 9335]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuiyan alia bhat chinlo na tomare chinte ashbo atleast jamal bhuiyan oi interview jonno apanake ajk oneke chinte parse\n",
            "Tokenized Sequence: [103, 585, 3880, 9336, 3885, 1, 819, 1854, 3222, 3890, 103, 585, 57, 902, 28, 9337, 557, 2477, 1854, 1995]\n",
            "\n",
            "\n",
            "Original Comment: biswas korean rasel bhai theka amar ex oo besi sundor\n",
            "Tokenized Sequence: [1447, 2479, 9338, 53, 953, 9, 474, 693, 176, 66]\n",
            "\n",
            "\n",
            "Original Comment: ego te lagse maiyar really thanks him bcz tmi kokhonoi jantam na bd te arekta lame ase nijeke viral korar jonne nice\n",
            "Tokenized Sequence: [3891, 25, 435, 2205, 3504, 673, 1856, 9339, 69, 3605, 788, 1, 344, 25, 9340, 2310, 45, 1424, 646, 101, 655, 529]\n",
            "\n",
            "\n",
            "Original Comment: apni amar kon bal je toi jaman bhuiyan position niya kotha bolen.apnar position je onner position niya kotha bolen.are apni toh apnar nijer publicity korar jonno video make korlen.falto mohila. abar ms world maray.\n",
            "Tokenized Sequence: [15, 9, 145, 48, 46, 388, 9341, 585, 649, 211, 10, 341, 22, 649, 46, 707, 649, 211, 10, 341, 177, 15, 88, 22, 147, 712, 101, 28, 24, 792, 905, 1736, 181, 86, 3657, 391, 3892]\n",
            "\n",
            "\n",
            "Original Comment: uni khrp emn bolse apu?\n",
            "Tokenized Sequence: [226, 3156, 246, 413, 19]\n",
            "\n",
            "\n",
            "Original Comment: unar jnnne apnk onkei chinbe\n",
            "Tokenized Sequence: [527, 9342, 438, 9343, 3893]\n",
            "\n",
            "\n",
            "Original Comment: apu ami 1st dekhlam jamal bhuiyan interview por\n",
            "Tokenized Sequence: [19, 4, 453, 278, 103, 585, 902, 72]\n",
            "\n",
            "\n",
            "Original Comment: betire chinos?\n",
            "Tokenized Sequence: [9344, 3894]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuiyan video na dekhle jantam na je apni desh kicu hoichen..... hudai nijer ijjot 12 bajaien na....ar onar theka porche apnare nia video banaile uni eigula dekhbe....vaire vai apne nijere mone koren asole!!!!\n",
            "Tokenized Sequence: [103, 585, 24, 1, 332, 788, 1, 46, 15, 97, 270, 3402, 746, 147, 1224, 618, 9345, 1, 445, 564, 953, 895, 355, 228, 24, 9346, 226, 971, 3895, 1729, 3, 638, 1836, 34, 83, 407]\n",
            "\n",
            "\n",
            "Original Comment: amar baal miss world\n",
            "Tokenized Sequence: [9, 410, 30, 391]\n",
            "\n",
            "\n",
            "Original Comment: amon kno hoise thik kora jai na\n",
            "Tokenized Sequence: [133, 64, 188, 61, 39, 90, 1]\n",
            "\n",
            "\n",
            "Original Comment: meye bole miss bangladesh theke nasir bow bhalo jamal bhuiyan payer soman howar joggota nai abar bole doubt jamal bhuiya kapor khuila star hoy nai toder moto\n",
            "Tokenized Sequence: [50, 54, 30, 12, 21, 2835, 141, 198, 103, 585, 3896, 2116, 645, 1464, 5, 86, 54, 2480, 103, 1859, 201, 1203, 798, 14, 5, 209, 16]\n",
            "\n",
            "\n",
            "Original Comment: jamal na dekhle apnare chintam na vai tumi shirin akter shila? anyway thank you as football fan apex branding aro good holo\n",
            "Tokenized Sequence: [103, 1, 332, 355, 1860, 1, 3, 13, 3897, 3898, 9347, 3628, 1700, 313, 3651, 583, 656, 9348, 9349, 131, 868, 170]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuiyar video na dekle tore chintm nah tui keda tui abr miss bangladesh..\n",
            "Tokenized Sequence: [103, 3888, 24, 1, 642, 216, 9350, 52, 23, 1825, 23, 169, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: maiya miss bangladesh?eidike judge dekhte chaoya amr mon\n",
            "Tokenized Sequence: [150, 30, 12, 3367, 1830, 112, 9351, 7, 84]\n",
            "\n",
            "\n",
            "Original Comment: tomar moto dhon keu sodeeeeo nah..\n",
            "Tokenized Sequence: [26, 16, 537, 390, 9352, 52]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuiyan publicity lagbe apnar moto heda diya?\n",
            "Tokenized Sequence: [103, 585, 712, 323, 22, 16, 488, 76]\n",
            "\n",
            "\n",
            "Original Comment: sister bokachoda sister know your level at first\n",
            "Tokenized Sequence: [1809, 372, 1809, 1840, 1795, 909, 1582, 449]\n",
            "\n",
            "\n",
            "Original Comment: oree attention seeker\n",
            "Tokenized Sequence: [3411, 1063, 3899]\n",
            "\n",
            "\n",
            "Original Comment: amr fb te joto gula frnd ase....shobai hahaa dise...ami eto kosto paisi apnr kotha shuina....tao haha dite hoilo...sry\n",
            "Tokenized Sequence: [7, 358, 25, 337, 55, 1624, 45, 434, 9353, 205, 4, 60, 293, 2014, 222, 10, 3882, 302, 640, 117, 249, 1270]\n",
            "\n",
            "\n",
            "Original Comment: actual fault hoitese amader. khai dai kaj nai hudai manush troll kore\n",
            "Tokenized Sequence: [3572, 9354, 1676, 132, 256, 1202, 109, 5, 746, 67, 2381, 2]\n",
            "\n",
            "\n",
            "Original Comment: \"mohila\" bolay kheippa gelo lmao\n",
            "Tokenized Sequence: [181, 9355, 9356, 105, 9357]\n",
            "\n",
            "\n",
            "Original Comment: dhet amar cheter bal\n",
            "Tokenized Sequence: [9358, 9, 1861, 48]\n",
            "\n",
            "\n",
            "Original Comment: togore keo chude na\n",
            "Tokenized Sequence: [9359, 489, 771, 1]\n",
            "\n",
            "\n",
            "Original Comment: ami nijew ajke 1st janlam face dekhlam miss bangladesh 2009\n",
            "Tokenized Sequence: [4, 9360, 397, 453, 1207, 456, 278, 30, 12, 9361]\n",
            "\n",
            "\n",
            "Original Comment: afa shundor koira apnare uposthapon korlo vaye\n",
            "Tokenized Sequence: [708, 303, 99, 355, 9362, 343, 9363]\n",
            "\n",
            "\n",
            "Original Comment: apnare chintam na,,tar personality niye kotha bolar age,\n",
            "Tokenized Sequence: [355, 1860, 1, 31, 1748, 65, 10, 573, 71]\n",
            "\n",
            "\n",
            "Original Comment: apnar personality iktu deikhen.\n",
            "Tokenized Sequence: [22, 1748, 9364, 9365]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhai jonno ajke cinlam apnare\n",
            "Tokenized Sequence: [103, 53, 28, 397, 1473, 355]\n",
            "\n",
            "\n",
            "Original Comment: well api, tumi du applied physics student\n",
            "Tokenized Sequence: [9366, 681, 13, 893, 9367, 9368, 2144]\n",
            "\n",
            "\n",
            "Original Comment: 1st miss bangladesh public figure hisebe eto khani tumi reknowned na je sobai chinbe.\n",
            "Tokenized Sequence: [453, 30, 12, 354, 1360, 1342, 60, 9369, 13, 9370, 1, 46, 104, 3893]\n",
            "\n",
            "\n",
            "Original Comment: jb tomake niyei baniye bolte jabe!\n",
            "Tokenized Sequence: [2481, 339, 9371, 1332, 163, 126]\n",
            "\n",
            "\n",
            "Original Comment: famous hote chole ashche nice!\n",
            "Tokenized Sequence: [789, 184, 385, 3900, 529]\n",
            "\n",
            "\n",
            "Original Comment: footage khacchen bhalo kotha apnar jonno asholei ata drkr chilo.\n",
            "Tokenized Sequence: [9372, 9373, 198, 10, 22, 28, 3595, 102, 995, 94]\n",
            "\n",
            "\n",
            "Original Comment: eshob bole market paowa jabe?\n",
            "Tokenized Sequence: [764, 54, 1382, 9374, 126]\n",
            "\n",
            "\n",
            "Original Comment: market jamal bhai uthaiche. unar karonei cinchi ekhn aro highlights hote caiteche.\n",
            "Tokenized Sequence: [1382, 103, 53, 9375, 527, 1725, 9376, 716, 131, 9377, 184, 9378]\n",
            "\n",
            "\n",
            "Original Comment: ami chini nainterview & unar post dekhei chinlami mean janlam arki\n",
            "Tokenized Sequence: [4, 1204, 9379, 527, 110, 580, 9380, 1787, 1207, 1596]\n",
            "\n",
            "\n",
            "Original Comment: nijer mukhe nah bolle jati jantoi nah uni miss bangladesh!!!!!\n",
            "Tokenized Sequence: [147, 259, 52, 785, 1718, 9381, 52, 226, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: aunty dake nai dekhe raag korlo mone hoi apumoni\n",
            "Tokenized Sequence: [1198, 1558, 5, 73, 9382, 343, 34, 38, 3874]\n",
            "\n",
            "\n",
            "Original Comment: apu shudhu jamal bhai nh amio ajke janlam j apni miss world\n",
            "Tokenized Sequence: [19, 698, 103, 53, 135, 238, 397, 1207, 42, 15, 30, 391]\n",
            "\n",
            "\n",
            "Original Comment: meyetato shabolil vashatei kotha bolse, shobai niye hashahashi korean kno.\n",
            "Tokenized Sequence: [9383, 9384, 9385, 10, 413, 434, 65, 9386, 2479, 64]\n",
            "\n",
            "\n",
            "Original Comment: vai eda abar kober miss bangladesh...! amio chintam nah age\n",
            "Tokenized Sequence: [3, 9387, 86, 9388, 30, 12, 238, 1860, 52, 71]\n",
            "\n",
            "\n",
            "Original Comment: jak valoi hoilo jamal bhuyan maddhome apnk chinlm.\n",
            "Tokenized Sequence: [758, 486, 249, 103, 797, 3901, 438, 3902]\n",
            "\n",
            "\n",
            "Original Comment: miss bangladesh hoyeo mone hoy na eto attention paisilen kokhono\n",
            "Tokenized Sequence: [30, 12, 1651, 34, 14, 1, 60, 1063, 9389, 504]\n",
            "\n",
            "\n",
            "Original Comment: even kotojon apnay chinto agee etao doubt ache.\n",
            "Tokenized Sequence: [1822, 9390, 9391, 1857, 1848, 1891, 2480, 74]\n",
            "\n",
            "\n",
            "Original Comment: ekhon miss bangladesh sobai chinse jamal jonno. you should thankful him.\n",
            "Tokenized Sequence: [185, 30, 12, 104, 1853, 103, 28, 313, 1855, 2478, 1856]\n",
            "\n",
            "\n",
            "Original Comment: ore chodon tmi keda boin?\n",
            "Tokenized Sequence: [91, 1049, 69, 1825, 335]\n",
            "\n",
            "\n",
            "Original Comment: ajk first miss universe bangladesh cinlm.....\n",
            "Tokenized Sequence: [557, 449, 30, 180, 12, 3903]\n",
            "\n",
            "\n",
            "Original Comment: kharap kichu bolse naki! makeup artist holei j gramer meye hobe eta bolse\n",
            "Tokenized Sequence: [79, 80, 413, 29, 368, 3881, 2569, 42, 3752, 50, 11, 95, 413]\n",
            "\n",
            "\n",
            "Original Comment: shosta publicity holo tmr video unar publicity proyojon porena sis\n",
            "Tokenized Sequence: [3879, 712, 170, 32, 24, 527, 712, 1619, 3886, 3871]\n",
            "\n",
            "\n",
            "Original Comment: seriously, apnadr conversation tah cilo tah jani nh.\n",
            "Tokenized Sequence: [3624, 9392, 9393, 1164, 516, 1164, 160, 135]\n",
            "\n",
            "\n",
            "Original Comment: ato toko jani apu apnake ami jamal vai maddome cinlam.\n",
            "Tokenized Sequence: [43, 9394, 160, 19, 192, 4, 103, 3, 2153, 1473]\n",
            "\n",
            "\n",
            "Original Comment: taw still apnar nam jani nh.\n",
            "Tokenized Sequence: [955, 9395, 22, 144, 160, 135]\n",
            "\n",
            "\n",
            "Original Comment: oi oi salarput tumi abr miss bangladesh 2019 bolo knu\n",
            "Tokenized Sequence: [57, 57, 9396, 13, 169, 30, 12, 2482, 526, 9397]\n",
            "\n",
            "\n",
            "Original Comment: chagol mohila\n",
            "Tokenized Sequence: [605, 181]\n",
            "\n",
            "\n",
            "Original Comment: jaak apnar kisu follower barbe, uchilay\n",
            "Tokenized Sequence: [9398, 22, 106, 1455, 9399, 9400]\n",
            "\n",
            "\n",
            "Original Comment: miss bangladesh hoisen erokom choto khato bepar niye pinched hoile kemne ki!abar reaction video kortesen!\n",
            "Tokenized Sequence: [30, 12, 1446, 835, 129, 2445, 684, 65, 9401, 398, 602, 175, 86, 2406, 24, 1019]\n",
            "\n",
            "\n",
            "Original Comment: apni vlo educated h20 mane ki?\n",
            "Tokenized Sequence: [15, 75, 2415, 9402, 155, 175]\n",
            "\n",
            "\n",
            "Original Comment: lol kobe kar miss bangladesh theke amar ex better\n",
            "Tokenized Sequence: [794, 423, 340, 30, 12, 21, 9, 474, 1253]\n",
            "\n",
            "\n",
            "Original Comment: pov: nine fail meye zokhn celebrity hoye zay\n",
            "Tokenized Sequence: [9403, 9404, 9405, 50, 9406, 937, 20, 9407]\n",
            "\n",
            "\n",
            "Original Comment: controversy kore shobai famous hoite chay\n",
            "Tokenized Sequence: [3629, 2, 434, 789, 428, 300]\n",
            "\n",
            "\n",
            "Original Comment: btw ajkei prothom dekhlam apnake miss bangladesh\n",
            "Tokenized Sequence: [1429, 3733, 1030, 278, 192, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: ohw apni miss bangladesh apnar theke amar bodhur ex oo sundor asetaka diya miss bangladeshi howya jay..amar bondhur ex moto howya jay na\n",
            "Tokenized Sequence: [9408, 15, 30, 12, 22, 21, 9, 9409, 474, 693, 66, 9410, 76, 30, 920, 3904, 92, 9, 9411, 474, 16, 3904, 92, 1]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuiyan cmnt korse boilai chinlam apnare apajan...you should thank him\n",
            "Tokenized Sequence: [103, 585, 1773, 202, 9412, 1474, 355, 3654, 313, 1855, 1700, 1856]\n",
            "\n",
            "\n",
            "Original Comment: tornanirheda\n",
            "Tokenized Sequence: [9413]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhaiyar interview na dekhle apnar chehara naam jantam na miss bangladesh 2019 hoise naki miss bangladesh rr por vabtei obak lage\n",
            "Tokenized Sequence: [103, 9414, 902, 1, 332, 22, 667, 915, 788, 1, 30, 12, 2482, 188, 29, 30, 12, 9415, 72, 3247, 1967, 47]\n",
            "\n",
            "\n",
            "Original Comment: oni bangla properly bolte pare nah tai\"mohila \" bolse..tahole nibbi bolle khusi hoten?\n",
            "Tokenized Sequence: [1289, 396, 3652, 163, 81, 52, 40, 181, 413, 113, 3290, 785, 1503, 9416]\n",
            "\n",
            "\n",
            "Original Comment: onar jonnoi miss universe ekjon shela nam achen..eta jante parlam\n",
            "Tokenized Sequence: [564, 839, 30, 180, 882, 1862, 144, 1400, 95, 533, 400]\n",
            "\n",
            "\n",
            "Original Comment: apnar aro onake thanks bola ucit.. onar kono kotha tei offensive kicu mone hoy ni..\n",
            "Tokenized Sequence: [22, 131, 9417, 673, 514, 1057, 564, 27, 10, 763, 3883, 270, 34, 14, 1494]\n",
            "\n",
            "\n",
            "Original Comment: go boin tumi...jamal bhuiyan thanks dew... coz tar karone akon kotho jon tumare ciner\n",
            "Tokenized Sequence: [137, 335, 13, 103, 585, 673, 1303, 9418, 31, 1160, 523, 3664, 430, 1797, 9419]\n",
            "\n",
            "\n",
            "Original Comment: lol vai apni koekjon bade mone hoy keo apnake chinto na tai viral howar jonno kotto natok dekhte hoibo\n",
            "Tokenized Sequence: [794, 3, 15, 3695, 3500, 34, 14, 489, 192, 1857, 1, 40, 646, 645, 28, 3562, 409, 112, 454]\n",
            "\n",
            "\n",
            "Original Comment: jottoshokol brain dead manush mohila bolse tai moron bole dilo\n",
            "Tokenized Sequence: [9420, 1563, 9421, 67, 181, 413, 40, 9422, 54, 321]\n",
            "\n",
            "\n",
            "Original Comment: whatever congratulation akhn oneke jane apni miss bd viral hoisen celebrate koren korben\n",
            "Tokenized Sequence: [9423, 3519, 151, 2477, 275, 15, 30, 344, 646, 1446, 1312, 83, 306]\n",
            "\n",
            "\n",
            "Original Comment: video deikha ajke miss world 2019 cinlm.. shate video kre nijeke nije advertise korse\n",
            "Tokenized Sequence: [24, 482, 397, 30, 391, 2482, 3903, 1352, 24, 432, 1424, 203, 3707, 202]\n",
            "\n",
            "\n",
            "Original Comment: apnare onkjok chinse onar maddhome ebar thanks den onare free te follower baray dilo..\n",
            "Tokenized Sequence: [355, 9424, 1853, 564, 3901, 1385, 673, 148, 9425, 364, 25, 1455, 9426, 321]\n",
            "\n",
            "\n",
            "Original Comment: bhai tmke keo chintoi na.. 80% people doesn't know you.. jamal bhai jonno ektu chinse manush you should appreciate.\n",
            "Tokenized Sequence: [53, 2308, 489, 9427, 1, 3675, 3905, 9428, 1840, 313, 103, 53, 28, 154, 1853, 67, 313, 1855, 3576]\n",
            "\n",
            "\n",
            "Original Comment: eta hocche \"opu bye\" hariye jawa bon.\n",
            "Tokenized Sequence: [95, 465, 483, 3501, 9429, 1450, 322]\n",
            "\n",
            "\n",
            "Original Comment: blv koren amiii apnre age kono din deksi kina mone pore na ami jamal bhuyan vai jnno apnk ajke dheklam & janlam apni mis bangladesh...\n",
            "Tokenized Sequence: [3708, 83, 9430, 3799, 71, 27, 35, 2378, 1435, 34, 62, 1, 4, 103, 797, 3, 854, 438, 397, 9431, 1207, 15, 1466, 12]\n",
            "\n",
            "\n",
            "Original Comment: jani bollen jamal vai ay jaiga aslo kore? apnke football math dawat roilo somoy hole ghure asben.....\n",
            "Tokenized Sequence: [160, 820, 103, 3, 229, 556, 1302, 2, 3906, 583, 3584, 898, 1452, 210, 121, 906, 3523]\n",
            "\n",
            "\n",
            "Original Comment: tor nanir heda shali tui kemne jamal bhuyan chinos nai seta bol agee\n",
            "Tokenized Sequence: [17, 1112, 488, 2795, 23, 602, 103, 797, 3894, 5, 220, 779, 1848]\n",
            "\n",
            "\n",
            "Original Comment: baal nai cheter bondhuk kande. tore chinto ???\n",
            "Tokenized Sequence: [410, 5, 1861, 9432, 9433, 216, 1857]\n",
            "\n",
            "\n",
            "Original Comment: amio apnake chintam na etodin\n",
            "Tokenized Sequence: [238, 192, 1860, 1, 1003]\n",
            "\n",
            "\n",
            "Original Comment: shela apu date over ganja khite khite thot kalo kore felso nki\n",
            "Tokenized Sequence: [1862, 19, 1415, 2335, 710, 3907, 3907, 3705, 212, 2, 3734, 282]\n",
            "\n",
            "\n",
            "Original Comment: areehh photo comment off koira rakhse baaaaal\n",
            "Tokenized Sequence: [9434, 845, 197, 619, 99, 2348, 9435]\n",
            "\n",
            "\n",
            "Original Comment: ha apni miss bokachoda\n",
            "Tokenized Sequence: [352, 15, 30, 372]\n",
            "\n",
            "\n",
            "Original Comment: temon kisu na use kore just ektu follower baranor dhanda arki\n",
            "Tokenized Sequence: [1461, 106, 1, 403, 2, 522, 154, 1455, 9436, 1777, 1596]\n",
            "\n",
            "\n",
            "Original Comment: chinen na ?uni ajker position ashar joggota uni easily toiri korsen unar chaite far better option silo seita bad dia desher football unnotir jonno ascen ha sosta publicity kotha bollen apni janen na uni la liga te commentary koresen desh bideshe unar koto fan follower\n",
            "Tokenized Sequence: [3726, 1, 226, 1973, 649, 3193, 1464, 226, 9437, 9438, 1037, 527, 2065, 9439, 1253, 9440, 518, 1353, 174, 252, 632, 583, 9441, 28, 9442, 352, 3908, 712, 10, 820, 15, 688, 1, 226, 3868, 2483, 25, 9443, 9444, 97, 9445, 527, 33, 656, 1455]\n",
            "\n",
            "\n",
            "Original Comment: miss bangladesh ase ?o my god,bhai jonno apnar free publicity hoye gese\n",
            "Tokenized Sequence: [30, 12, 45, 946, 1699, 1351, 53, 28, 22, 364, 712, 20, 87]\n",
            "\n",
            "\n",
            "Original Comment: mohila abr aj prothom dekhlm clown\n",
            "Tokenized Sequence: [181, 169, 123, 1030, 9446, 9447]\n",
            "\n",
            "\n",
            "Original Comment: jamal vai apnar nam nesa atai onek apnar jonno abar gan den\n",
            "Tokenized Sequence: [103, 3, 22, 144, 2213, 741, 56, 22, 28, 86, 539, 148]\n",
            "\n",
            "\n",
            "Original Comment: odi gum jaguii tui\n",
            "Tokenized Sequence: [1618, 2453, 9448, 23]\n",
            "\n",
            "\n",
            "Original Comment: hogar mich bangladesh\n",
            "Tokenized Sequence: [1250, 9449, 12]\n",
            "\n",
            "\n",
            "Original Comment: tmi miss bangladesh.r tmi national football captain chino na. abr ven ven kortiso\n",
            "Tokenized Sequence: [69, 30, 12, 162, 69, 1489, 583, 1374, 1858, 1, 169, 3909, 3909, 9450]\n",
            "\n",
            "\n",
            "Original Comment: bal abr ?? j jamal bhuiyan niye kotha bole ?\n",
            "Tokenized Sequence: [48, 169, 42, 103, 585, 65, 10, 54]\n",
            "\n",
            "\n",
            "Original Comment: tore miss bangladesh banaise\n",
            "Tokenized Sequence: [216, 30, 12, 1831]\n",
            "\n",
            "\n",
            "Original Comment: free te famous kore dise tar jonno tnx na diye abar bahaduri dekhaitese hayre bangali\n",
            "Tokenized Sequence: [364, 25, 789, 2, 205, 31, 28, 9451, 1, 49, 86, 9452, 9453, 1139, 756]\n",
            "\n",
            "\n",
            "Original Comment: shawwar moton attitude\n",
            "Tokenized Sequence: [2654, 490, 1751]\n",
            "\n",
            "\n",
            "Original Comment: bal miss bangladesh\n",
            "Tokenized Sequence: [48, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: sob kisu tik ase kintu! fuck ur motamot!!!\n",
            "Tokenized Sequence: [8, 106, 269, 45, 68, 1305, 3321, 2900]\n",
            "\n",
            "\n",
            "Original Comment: apu uni position field khele earn korechen. uni onar field performance diyesen\n",
            "Tokenized Sequence: [19, 226, 649, 3910, 441, 9454, 2119, 226, 564, 3910, 1328, 9455]\n",
            "\n",
            "\n",
            "Original Comment: apni apnar sector kore jan. tahole hobe, esob niye dat ber kore video korle position paben na. happy apur line baad den.\n",
            "Tokenized Sequence: [15, 22, 3384, 2, 378, 113, 11, 369, 65, 1653, 139, 2, 24, 183, 649, 1502, 1, 9456, 1436, 730, 745, 148]\n",
            "\n",
            "\n",
            "Original Comment: sor magini\n",
            "Tokenized Sequence: [9457, 9458]\n",
            "\n",
            "\n",
            "Original Comment: bah didi bah\n",
            "Tokenized Sequence: [327, 647, 327]\n",
            "\n",
            "\n",
            "Original Comment: tar jonno publicity pailen ekhn eita diyaobhoilo na\n",
            "Tokenized Sequence: [31, 28, 712, 9459, 716, 289, 9460, 1]\n",
            "\n",
            "\n",
            "Original Comment: tai aro publicity paoar khuday decide korlen j tare nia roasting video banaben\n",
            "Tokenized Sequence: [40, 131, 712, 9461, 9462, 9463, 905, 42, 721, 228, 1031, 24, 2117]\n",
            "\n",
            "\n",
            "Original Comment: then kisu sosta sympathy niben\n",
            "Tokenized Sequence: [639, 106, 3908, 3554, 3911]\n",
            "\n",
            "\n",
            "Original Comment: apnr nam manus janto na so vai thnx janan j apne famous hoisen\n",
            "Tokenized Sequence: [222, 144, 140, 2407, 1, 315, 3, 9464, 2474, 42, 638, 789, 1446]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuaiya thanks din, tar jonno apnake cinta parlam.\n",
            "Tokenized Sequence: [103, 9465, 673, 35, 31, 28, 192, 1794, 400]\n",
            "\n",
            "\n",
            "Original Comment: tui educated hoyle jaa giya bcs cadre hoo...media te bal 1ta t-shirt poira ajaira pachal partasos kaa???\n",
            "Tokenized Sequence: [23, 2415, 9466, 2392, 866, 3599, 3600, 951, 460, 25, 48, 2710, 610, 923, 548, 1157, 9467, 9468, 9469]\n",
            "\n",
            "\n",
            "Original Comment: oppps kossa hoice mone hoi\n",
            "Tokenized Sequence: [9470, 9471, 356, 34, 38]\n",
            "\n",
            "\n",
            "Original Comment: 1st of all who are you??miss universe bangladesh hoie apni ultaisen seta jante iccha kortese???\n",
            "Tokenized Sequence: [453, 1627, 1333, 9472, 177, 313, 30, 180, 12, 9473, 15, 9474, 220, 533, 1201, 1402]\n",
            "\n",
            "\n",
            "Original Comment: apni kivabe miss universe hoilen seta niya amader doubt ache..\n",
            "Tokenized Sequence: [15, 392, 30, 180, 2375, 220, 211, 132, 2480, 74]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuyan jonno apnaka aj chinlam\n",
            "Tokenized Sequence: [103, 797, 28, 2436, 123, 1474]\n",
            "\n",
            "\n",
            "Original Comment: mohila bolse tai amon hoay gese\n",
            "Tokenized Sequence: [181, 413, 40, 133, 9475, 87]\n",
            "\n",
            "\n",
            "Original Comment: dur bal 3 min nosto\n",
            "Tokenized Sequence: [422, 48, 402, 1685, 215]\n",
            "\n",
            "\n",
            "Original Comment: apu jamal bhai banglae pblm ache beti bole nai aitai onk\n",
            "Tokenized Sequence: [19, 103, 53, 9476, 830, 74, 787, 54, 5, 9477, 58]\n",
            "\n",
            "\n",
            "Original Comment: tumi go, akta dori kuai taki forlay, agee kunu din deklam nah, name hunlam nah. akta dori aiya baal upload korillay video ekta.\n",
            "Tokenized Sequence: [13, 137, 37, 3912, 9478, 1092, 9479, 1848, 2366, 35, 1180, 52, 236, 9480, 52, 37, 3912, 2650, 410, 644, 9481, 24, 36]\n",
            "\n",
            "\n",
            "Original Comment: ami ajke chin lam\n",
            "Tokenized Sequence: [4, 397, 9482, 3684]\n",
            "\n",
            "\n",
            "Original Comment: aj prothom ami apnak chinlam.jamal bhuiyan jonno apnar porichiti barlo..tar kase krittogota sikar kora uchit apnar.\n",
            "Tokenized Sequence: [123, 1030, 4, 1438, 1474, 103, 585, 28, 22, 9483, 3913, 31, 668, 9484, 9485, 39, 168, 22]\n",
            "\n",
            "\n",
            "Original Comment: tumi miss heda\n",
            "Tokenized Sequence: [13, 30, 488]\n",
            "\n",
            "\n",
            "Original Comment: kharap , akta promote paiya gelen jamal vai kase theke\n",
            "Tokenized Sequence: [79, 37, 9486, 3465, 1425, 103, 3, 668, 21]\n",
            "\n",
            "\n",
            "Original Comment: kono chintaa koironah amito achi tmr pasee\n",
            "Tokenized Sequence: [27, 9487, 9488, 3678, 3914, 32, 9489]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhai dhonnobad den je ami age apnake jantam nh tar jonno janlam apnake now apni fmz\n",
            "Tokenized Sequence: [103, 53, 1819, 148, 46, 4, 71, 192, 788, 135, 31, 28, 1207, 192, 9490, 15, 9491]\n",
            "\n",
            "\n",
            "Original Comment: abalchdoa tui k?\n",
            "Tokenized Sequence: [9492, 23, 806]\n",
            "\n",
            "\n",
            "Original Comment: miss bangladesh maia gular brain capacity eto kharap, ja kichu kichu viral video te dekha jay. jamal bhuiya ghotona normally describe korche, even bolchew j oita awkward situation chilo. taile ehon eidare niya emon kanda kandi jonne!\n",
            "Tokenized Sequence: [30, 12, 1205, 1522, 1563, 9493, 60, 79, 70, 80, 80, 646, 24, 25, 122, 92, 103, 1859, 1905, 2419, 9494, 334, 1822, 9495, 42, 311, 9496, 9497, 94, 312, 9498, 3235, 211, 156, 9499, 9500, 655]\n",
            "\n",
            "\n",
            "Original Comment: jei na bal.....tmi.....jamal bhuiya vi...nam....mukhe nise tate dhonno thako...bonno!\n",
            "Tokenized Sequence: [380, 1, 48, 69, 103, 1859, 641, 144, 259, 1324, 907, 2382, 697, 9501]\n",
            "\n",
            "\n",
            "Original Comment: jamal jonno tore cinlam boin\n",
            "Tokenized Sequence: [103, 28, 216, 1473, 335]\n",
            "\n",
            "\n",
            "Original Comment: 1st time deklam apnare chachi....\n",
            "Tokenized Sequence: [453, 371, 1180, 355, 9502]\n",
            "\n",
            "\n",
            "Original Comment: choto kry ktha bolar korlo dnt knw. amio apnk chini na.\n",
            "Tokenized Sequence: [129, 9503, 520, 573, 343, 9504, 9505, 238, 438, 1204, 1]\n",
            "\n",
            "\n",
            "Original Comment: onk karon celebrity j shob place jan salon oi khane amr jaoya hy shay kahne apndr behave attitude rokom thake. like ami tmi chino\n",
            "Tokenized Sequence: [58, 329, 937, 42, 127, 3418, 378, 9506, 57, 1560, 7, 9507, 883, 9508, 9509, 3915, 9510, 1751, 251, 114, 381, 4, 69, 1858]\n",
            "\n",
            "\n",
            "Original Comment: mane others civilian people der shamne apnara ektu extra vab nen na onno der kintu insult kora hoy\n",
            "Tokenized Sequence: [155, 1758, 9511, 3905, 44, 3192, 280, 154, 9512, 525, 1264, 1, 242, 44, 68, 1835, 39, 14]\n",
            "\n",
            "\n",
            "Original Comment: apni sotti miss bangladesh?\n",
            "Tokenized Sequence: [15, 555, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: reach barlo na thikase .\n",
            "Tokenized Sequence: [2317, 3913, 1, 3845]\n",
            "\n",
            "\n",
            "Original Comment: moja pailam na\n",
            "Tokenized Sequence: [224, 1219, 1]\n",
            "\n",
            "\n",
            "Original Comment: apni attention seeker lol\n",
            "Tokenized Sequence: [15, 1063, 3899, 794]\n",
            "\n",
            "\n",
            "Original Comment: maiya pagol hoiya gese.... tomi bangladesh football team captain chino na....... tomi miss bangladesh .............. tomi je kemne miss bangladesh hoiso bojha hoiya gese.........amar nani miss bangladesh\n",
            "Tokenized Sequence: [150, 108, 232, 87, 569, 12, 583, 263, 1374, 1858, 1, 569, 30, 12, 569, 46, 602, 30, 12, 2475, 992, 232, 87, 9, 1734, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuiyan and shela apur biye chai\n",
            "Tokenized Sequence: [103, 585, 200, 1862, 1436, 267, 124]\n",
            "\n",
            "\n",
            "Original Comment: bangladesh ekhon j she miss universe hoye jay ekta obostha\n",
            "Tokenized Sequence: [12, 185, 42, 795, 30, 180, 20, 92, 36, 383]\n",
            "\n",
            "\n",
            "Original Comment: apnake ajk 1st time dekhlam apa\n",
            "Tokenized Sequence: [192, 557, 453, 371, 278, 603]\n",
            "\n",
            "\n",
            "Original Comment: age video te 12 views.. akhn 2m sob viral hoar danda\n",
            "Tokenized Sequence: [71, 24, 25, 618, 9513, 151, 9514, 8, 646, 3916, 2499]\n",
            "\n",
            "\n",
            "Original Comment: famous hoar try krse and hye gese already\n",
            "Tokenized Sequence: [789, 3916, 934, 2440, 200, 1186, 87, 1607]\n",
            "\n",
            "\n",
            "Original Comment: halar pagol chagol diya bangladesh voira geche, meye naki miss bangladesh chini na koi theka asche allah malum, miss bangladesh konta jeikhane h2o mane restaurant bujhe oita, sob aul foul jinis utpadon bangladesh possible, chillaiya market paon jaibo???\n",
            "Tokenized Sequence: [563, 108, 605, 76, 12, 1635, 635, 50, 29, 30, 12, 1204, 1, 93, 953, 1113, 59, 9515, 30, 12, 1047, 9516, 3917, 155, 3634, 843, 311, 8, 9517, 2423, 467, 9518, 12, 1430, 9519, 1382, 9520, 874]\n",
            "\n",
            "\n",
            "Original Comment: uni kobe theke abar miss bangladesh!! jamal bhuiya apnar nam mantion kore nai. sobi viral howar dhanda\n",
            "Tokenized Sequence: [226, 423, 21, 86, 30, 12, 103, 1859, 22, 144, 9521, 2, 5, 1045, 646, 645, 1777]\n",
            "\n",
            "\n",
            "Original Comment: video samne na asle toh jantam i na apni kono ek din bangladeshe etc hoisen\n",
            "Tokenized Sequence: [24, 389, 1, 1458, 88, 788, 171, 1, 15, 27, 125, 35, 3834, 9522, 1446]\n",
            "\n",
            "\n",
            "Original Comment: ohe tumi kon cheter bal\n",
            "Tokenized Sequence: [9523, 13, 145, 1861, 48]\n",
            "\n",
            "\n",
            "Original Comment: jamal bhuyan thanks bhai 19 miss bangladesh mohila porichoi koriye deoar jnno\n",
            "Tokenized Sequence: [103, 797, 673, 53, 2263, 30, 12, 181, 3918, 2254, 3919, 854]\n",
            "\n",
            "\n",
            "Original Comment: aida miss bangladesh lol ajky 1st dekhlam... btw show tar judge silo kara many apnaky award dilo\n",
            "Tokenized Sequence: [899, 30, 12, 794, 9524, 453, 278, 1429, 1194, 31, 1830, 518, 571, 9525, 9526, 3920, 321]\n",
            "\n",
            "\n",
            "Original Comment: onar karone apnk chinlm ageh kono somoy dekhi nai jamal bhuyan dhonnobad janan\n",
            "Tokenized Sequence: [564, 1160, 438, 3902, 9527, 27, 210, 157, 5, 103, 797, 1819, 2474]\n",
            "\n",
            "\n",
            "Original Comment: hayre naki miss bangladesh\n",
            "Tokenized Sequence: [1139, 29, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: uni mitta bolar manush na.shudu shudu aise public attention nite.unu na bolle public jantao je miss bangladesh\n",
            "Tokenized Sequence: [226, 2327, 573, 67, 1, 1427, 1427, 1568, 354, 1063, 653, 9528, 1, 785, 354, 9529, 46, 30, 12]\n",
            "\n",
            "\n",
            "Original Comment: miss bangladesh.. chini nah xdar shey eshe bole jamal bhuyan kmne position ashche\n",
            "Tokenized Sequence: [30, 12, 1204, 52, 9530, 3389, 2446, 54, 103, 797, 296, 649, 3900]\n",
            "\n",
            "\n",
            "Original Comment: khanki magi chine?\n",
            "Tokenized Sequence: [285, 96, 2476]\n",
            "\n",
            "\n",
            "Original Comment: amar hogar bal ja bhag\n",
            "Tokenized Sequence: [9, 1250, 48, 70, 9531]\n",
            "\n",
            "\n",
            "Original Comment: miss bangladesh bole ego diya porichoy dilen keno\n",
            "Tokenized Sequence: [30, 12, 54, 3891, 76, 1285, 908, 111]\n",
            "\n",
            "\n",
            "Original Comment: koto taka niso rat thakte tumi jamal vuia cheno na\n",
            "Tokenized Sequence: [33, 172, 9532, 719, 538, 13, 103, 9533, 9534, 1]\n",
            "\n",
            "\n",
            "Original Comment: eh bhai tumi,,, jb na blle toh tmr face tai chntm nah,,,aj jb jnno famous hoye gelen\n",
            "Tokenized Sequence: [3921, 53, 13, 2481, 1, 9535, 88, 32, 456, 40, 9536, 52, 123, 2481, 854, 789, 20, 1425]\n",
            "\n",
            "\n",
            "Original Comment: hudai publicity neaor chesta krtecen lav nai kar loge nejak ceompear krtecen\n",
            "Tokenized Sequence: [746, 712, 9537, 1336, 3922, 517, 5, 340, 615, 9538, 9539, 3922]\n",
            "\n",
            "\n",
            "Original Comment: husband wife maramari\n",
            "Tokenized Sequence: [1890, 3054, 9540]\n",
            "\n",
            "\n",
            "Original Comment: aita nam toh sunlam na jibone\n",
            "Tokenized Sequence: [149, 144, 88, 9541, 1, 543]\n",
            "\n",
            "\n",
            "Original Comment: apnk dhonnobad...nijer porichoi nijei die dilen\n",
            "Tokenized Sequence: [438, 1819, 147, 3918, 592, 917, 908]\n",
            "\n",
            "\n",
            "Original Comment: tumi unar position niye kotha bolo koitte tumi uitha ashcho h2o marka show thika tumi abar position niye bolo ajob\n",
            "Tokenized Sequence: [13, 527, 649, 65, 10, 526, 2466, 13, 1986, 9542, 3917, 325, 1194, 1919, 13, 86, 649, 65, 526, 662]\n",
            "\n",
            "\n",
            "Original Comment: dhur chat bal\n",
            "Tokenized Sequence: [737, 2267, 48]\n",
            "\n",
            "\n",
            "Original Comment: etto lame issue te ......cote gelo\n",
            "Tokenized Sequence: [1235, 2310, 9543, 25, 9544, 105]\n",
            "\n",
            "\n",
            "Original Comment: tomal tota teo tode na\n",
            "Tokenized Sequence: [9545, 9546, 3728, 9547, 1]\n",
            "\n",
            "\n",
            "Original Comment: apa annne mela sunduri apa\n",
            "Tokenized Sequence: [603, 9548, 957, 9549, 603]\n",
            "\n",
            "\n",
            "Original Comment: abal kotha\n",
            "Tokenized Sequence: [235, 10]\n",
            "\n",
            "\n",
            "Original Comment: tumi howkkranni...lager wuu ola...jamal vaiyeto hasaw koise...\n",
            "Tokenized Sequence: [13, 9550, 2452, 9551, 9552, 103, 9553, 9554, 3779]\n",
            "\n",
            "\n",
            "Original Comment: tore miss bangladesh banaise kedai dhurr ajaira jottoshob\n",
            "Tokenized Sequence: [216, 30, 12, 1831, 9555, 9556, 1157, 9557]\n",
            "\n",
            "\n",
            "Original Comment: aikane kono disrespect bepar dekrticii na apnr nam neinai. uni aro aita bollo je ami aita korlam! aikane apnke choto korar kotha aslo kottheke\n",
            "Tokenized Sequence: [3923, 27, 9558, 684, 9559, 1, 222, 144, 9560, 226, 131, 149, 952, 46, 4, 149, 1097, 3923, 3906, 129, 101, 10, 1302, 9561]\n",
            "\n",
            "\n",
            "Original Comment: shirin akter shela my god miss banggali\n",
            "Tokenized Sequence: [3897, 3898, 1862, 1699, 1351, 30, 9562]\n",
            "\n",
            "\n",
            "Original Comment: khusi hoisilam karon vabsilam t-20 theke retire korse.ashay gurobali.\n",
            "Tokenized Sequence: [1503, 9563, 329, 1234, 610, 623, 21, 9564, 202, 9565, 9566]\n",
            "\n",
            "\n",
            "Original Comment: kapurush... team kharap shomoy team support nah diye nijeke save position niye jacche...such shame.\n",
            "Tokenized Sequence: [9567, 263, 79, 591, 263, 1103, 52, 49, 1424, 2937, 649, 65, 515, 2853, 9568]\n",
            "\n",
            "\n",
            "Original Comment: valo hobe sob doroner khela theke nile amin\n",
            "Tokenized Sequence: [6, 11, 8, 3766, 130, 21, 3556, 1588]\n",
            "\n",
            "\n",
            "Original Comment: t20 theke nae na ka\n",
            "Tokenized Sequence: [767, 21, 2194, 1, 476]\n",
            "\n",
            "\n",
            "Original Comment: pagoler dolera dite thak react\n",
            "Tokenized Sequence: [2207, 9569, 117, 550, 437]\n",
            "\n",
            "\n",
            "Original Comment: madarboard\n",
            "Tokenized Sequence: [9570]\n",
            "\n",
            "\n",
            "Original Comment: tahole jagay tmi khalte parba\n",
            "Tokenized Sequence: [113, 3800, 69, 9571, 1656]\n",
            "\n",
            "\n",
            "Original Comment: dui rakat nafal namaz pora uchit je desh atleast jonmai nai\n",
            "Tokenized Sequence: [382, 9572, 9573, 977, 244, 168, 46, 97, 3890, 9574, 5]\n",
            "\n",
            "\n",
            "Original Comment: bd boshundaray ekta proyojon emn ekjon\n",
            "Tokenized Sequence: [344, 9575, 36, 1619, 246, 882]\n",
            "\n",
            "\n",
            "Original Comment: eida tui....ar hea ekta sotti kotha koi hea rag koris na\n",
            "Tokenized Sequence: [1488, 23, 445, 2305, 36, 555, 10, 93, 2305, 718, 961, 1]\n",
            "\n",
            "\n",
            "Original Comment: umbrella kahini tao fatafati chilo\n",
            "Tokenized Sequence: [9576, 932, 302, 9577, 94]\n",
            "\n",
            "\n",
            "Original Comment: nach kintu sei chilo\n",
            "Tokenized Sequence: [919, 68, 115, 94]\n",
            "\n",
            "\n",
            "Original Comment: sotti bolte kano jani amar aktu hashi pelo na, amnite kintu ami prochur hashi. aita dekhe aktu hashi ashlo na.\n",
            "Tokenized Sequence: [555, 163, 361, 160, 9, 178, 1024, 9578, 1, 9579, 68, 4, 3005, 1024, 149, 73, 178, 1024, 9580, 1]\n",
            "\n",
            "\n",
            "Original Comment: cheleta mone hoy meye mone korche je... dance step gulo ladies ladies lagteche..\n",
            "Tokenized Sequence: [2454, 34, 14, 50, 34, 334, 46, 393, 1456, 107, 2471, 2471, 3924]\n",
            "\n",
            "\n",
            "Original Comment: tedy bear sob video amer onek valo lage onek cute\n",
            "Tokenized Sequence: [9581, 9582, 8, 24, 742, 56, 6, 47, 56, 348]\n",
            "\n",
            "\n",
            "Original Comment: video dekhar age kanna krte cilam phn tipte cilam hotath samne aslo kanna rekhe hasa suru krlam ammu vabce ami pagol hoye geci\n",
            "Tokenized Sequence: [24, 250, 71, 1441, 566, 959, 1356, 1755, 959, 9583, 389, 1302, 1441, 604, 9584, 272, 9585, 2788, 9586, 4, 108, 20, 2712]\n",
            "\n",
            "\n",
            "Original Comment: amare kew emn dress dere vaia . pran khuila nachi\n",
            "Tokenized Sequence: [408, 142, 246, 164, 9587, 455, 1808, 1203, 2834]\n",
            "\n",
            "\n",
            "Original Comment: dress pore amr erokom dance korte mon cay\n",
            "Tokenized Sequence: [164, 62, 7, 835, 393, 41, 84, 1132]\n",
            "\n",
            "\n",
            "Original Comment: tik tok gulo onk fun..vloi lage..ami sob gulo dekhsi tik tok\n",
            "Tokenized Sequence: [269, 778, 107, 58, 9588, 3498, 47, 4, 8, 107, 1177, 269, 778]\n",
            "\n",
            "\n",
            "Original Comment: baler sound na dile manush hastona\n",
            "Tokenized Sequence: [194, 878, 1, 254, 67, 9589]\n",
            "\n",
            "\n",
            "Original Comment: jak onnorokom ekta dance step pelam gaan\n",
            "Tokenized Sequence: [758, 9590, 36, 393, 1456, 760, 723]\n",
            "\n",
            "\n",
            "Original Comment: sotii bolte gele khub akta amar hasi payni\n",
            "Tokenized Sequence: [9591, 163, 470, 51, 37, 9, 628, 9592]\n",
            "\n",
            "\n",
            "Original Comment: others prank video theke onek valo.. kichu loker mukhe hasi fota no khub valo..\n",
            "Tokenized Sequence: [1758, 3878, 24, 21, 56, 6, 80, 1151, 259, 628, 2299, 447, 51, 6]\n",
            "\n",
            "\n",
            "Original Comment: eta pura chaina-korean der moto hoice\n",
            "Tokenized Sequence: [95, 384, 3405, 2479, 44, 16, 356]\n",
            "\n",
            "\n",
            "Original Comment: uff vhi sei pani pani gan tar proti amk nafrat koriye dili\n",
            "Tokenized Sequence: [424, 1230, 115, 394, 394, 539, 31, 1059, 429, 9593, 2254, 2314]\n",
            "\n",
            "\n",
            "Original Comment: pani pani gan best dance chilo\n",
            "Tokenized Sequence: [394, 394, 539, 468, 393, 94]\n",
            "\n",
            "\n",
            "Original Comment: onek valo theko tume atota anondo sobaike deoar jonno\n",
            "Tokenized Sequence: [56, 6, 2266, 1578, 1634, 2357, 1457, 3919, 28]\n",
            "\n",
            "\n",
            "Original Comment: allah go...amk kew doro..hasta hasta pora galam j\n",
            "Tokenized Sequence: [59, 137, 429, 142, 2484, 3925, 3925, 244, 9594, 42]\n",
            "\n",
            "\n",
            "Original Comment: school jawyar por amago obostha hoibo\n",
            "Tokenized Sequence: [821, 3632, 72, 2783, 383, 454]\n",
            "\n",
            "\n",
            "Original Comment: ami muchki hasi chara kisui dite parlam\n",
            "Tokenized Sequence: [4, 9595, 628, 233, 1467, 117, 400]\n",
            "\n",
            "\n",
            "Original Comment: joto bar dekhi toto bari hashi thamate pari na\n",
            "Tokenized Sequence: [337, 134, 157, 1014, 751, 1024, 9596, 138, 1]\n",
            "\n",
            "\n",
            "Original Comment: amare aktu khobor dilay hoito ami company ditam\n",
            "Tokenized Sequence: [408, 178, 861, 9597, 307, 4, 1527, 1120]\n",
            "\n",
            "\n",
            "Original Comment: eta dekhlei tor kotha mone hy amr allah janen l\n",
            "Tokenized Sequence: [95, 461, 17, 10, 34, 883, 7, 59, 688, 897]\n",
            "\n",
            "\n",
            "Original Comment: por vidio te aapni manush dekhte chai. .\n",
            "Tokenized Sequence: [72, 2432, 25, 9598, 67, 112, 124]\n",
            "\n",
            "\n",
            "Original Comment: dosto pani pani song best dancer\n",
            "Tokenized Sequence: [3926, 394, 394, 1058, 468, 3927]\n",
            "\n",
            "\n",
            "Original Comment: sob thik chilo background hasir sound na dileo hoto.hasir sound diye video cringe hoye gese\n",
            "Tokenized Sequence: [8, 61, 94, 9599, 3928, 878, 1, 1288, 257, 3928, 878, 49, 24, 1256, 20, 87]\n",
            "\n",
            "\n",
            "Original Comment: dost tui kin2 joss dance koros.onk khuja khuji korar por paise\n",
            "Tokenized Sequence: [1692, 23, 9600, 338, 393, 669, 58, 9601, 9602, 101, 72, 1327]\n",
            "\n",
            "\n",
            "Original Comment: vidio dakla pata khil laga jai amar\n",
            "Tokenized Sequence: [2432, 3929, 1863, 9603, 427, 90, 9]\n",
            "\n",
            "\n",
            "Original Comment: kader sathe panta bathe geekhotai gopal , mr bin khotai teady comdey\n",
            "Tokenized Sequence: [1682, 77, 9604, 9605, 9606, 9607, 3930, 9608, 9609, 9610, 9611]\n",
            "\n",
            "\n",
            "Original Comment: amar akto hashi pay\n",
            "Tokenized Sequence: [9, 777, 1024, 738]\n",
            "\n",
            "\n",
            "Original Comment: amader desh amn khub kom dekha jay othocho bahirer desh gula te park je kono jaygay amn binodon deyar moto onk tgakr!\n",
            "Tokenized Sequence: [132, 97, 213, 51, 248, 122, 92, 3931, 9612, 97, 55, 25, 9613, 46, 27, 975, 213, 1041, 1579, 16, 58, 9614]\n",
            "\n",
            "\n",
            "Original Comment: bah bah marattok dancer ,sei hoise,purai josss. sei vabe komor dulaise\n",
            "Tokenized Sequence: [327, 327, 9615, 3927, 115, 188, 291, 2485, 115, 301, 2184, 9616]\n",
            "\n",
            "\n",
            "Original Comment: marsafe ekta kotar bassa.\n",
            "Tokenized Sequence: [9617, 36, 3049, 1167]\n",
            "\n",
            "\n",
            "Original Comment: onek mojar. manus take dhekta dhawya amr nispap mon.\n",
            "Tokenized Sequence: [56, 9618, 140, 223, 9619, 9620, 7, 2390, 84]\n",
            "\n",
            "\n",
            "Original Comment: first ami kono video dakia hassi mon kuly\n",
            "Tokenized Sequence: [449, 4, 27, 24, 9621, 9622, 84, 9623]\n",
            "\n",
            "\n",
            "Original Comment: ami onek share koreci\n",
            "Tokenized Sequence: [4, 56, 1491, 9624]\n",
            "\n",
            "\n",
            "Original Comment: amr fvrt vdo mddy akth\n",
            "Tokenized Sequence: [7, 9625, 703, 9626, 9627]\n",
            "\n",
            "\n",
            "Original Comment: halarput last lathi sei hoica gura kimri bair koira dise\n",
            "Tokenized Sequence: [9628, 426, 1130, 115, 3426, 1982, 9629, 671, 99, 205]\n",
            "\n",
            "\n",
            "Original Comment: oi gula tato ami akdin vedio daka banaisilam kauha jaina amr ammue voia kub kosto kora kaisiam\n",
            "Tokenized Sequence: [57, 55, 1810, 4, 1199, 347, 1756, 9630, 9631, 1076, 7, 9632, 9633, 575, 293, 39, 9634]\n",
            "\n",
            "\n",
            "Original Comment: xm diye amr chokh nosto hye gese\n",
            "Tokenized Sequence: [9635, 49, 7, 1091, 215, 1186, 87]\n",
            "\n",
            "\n",
            "Original Comment: asole din din kharap hoia jaytase, korbo koo na mind valo korber kano pari na\n",
            "Tokenized Sequence: [407, 35, 35, 79, 295, 9636, 186, 9637, 1, 3396, 6, 9638, 361, 138, 1]\n",
            "\n",
            "\n",
            "Original Comment: condom vaji\n",
            "Tokenized Sequence: [1344, 9639]\n",
            "\n",
            "\n",
            "Original Comment: alu emn hoile belun kmn vai\n",
            "Tokenized Sequence: [3884, 246, 398, 9640, 497, 3]\n",
            "\n",
            "\n",
            "Original Comment: hoice kara ara\n",
            "Tokenized Sequence: [356, 571, 342]\n",
            "\n",
            "\n",
            "Original Comment: meye pornstar chilo\n",
            "Tokenized Sequence: [50, 1483, 94]\n",
            "\n",
            "\n",
            "Original Comment: asole ara kara?kew janle aktw bolio\n",
            "Tokenized Sequence: [407, 342, 571, 142, 1677, 9641, 9642]\n",
            "\n",
            "\n",
            "Original Comment: ekta video kore sarajibon vangiye khabi....new video kore 6arlei hoi...\n",
            "Tokenized Sequence: [36, 24, 2, 1842, 9643, 1363, 754, 24, 2, 9644, 38]\n",
            "\n",
            "\n",
            "Original Comment: kon natok spot\n",
            "Tokenized Sequence: [145, 409, 9645]\n",
            "\n",
            "\n",
            "Original Comment: bisnar chador shei chilo\n",
            "Tokenized Sequence: [9646, 3392, 3858, 94]\n",
            "\n",
            "\n",
            "Original Comment: natok dekea chuke jol chole asca...\n",
            "Tokenized Sequence: [409, 9647, 9648, 664, 385, 3335]\n",
            "\n",
            "\n",
            "Original Comment: are ara kara kotthe alo ara????\n",
            "Tokenized Sequence: [177, 342, 571, 9649, 9650, 342]\n",
            "\n",
            "\n",
            "Original Comment: ami aktu klanto hoye gelam\n",
            "Tokenized Sequence: [4, 178, 9651, 20, 439]\n",
            "\n",
            "\n",
            "Original Comment: akn porjonto na cina ami\n",
            "Tokenized Sequence: [685, 599, 1, 2379, 4]\n",
            "\n",
            "\n",
            "Original Comment: meye same same aranee ammur moto lage\n",
            "Tokenized Sequence: [50, 1459, 1459, 9652, 9653, 16, 47]\n",
            "\n",
            "\n",
            "Original Comment: assa ayra kara maje majei ayder niya post dekhi\n",
            "Tokenized Sequence: [997, 9654, 571, 812, 9655, 9656, 211, 110, 157]\n",
            "\n",
            "\n",
            "Original Comment: soto belar kotha mone pore gelo!\n",
            "Tokenized Sequence: [1315, 9657, 10, 34, 62, 105]\n",
            "\n",
            "\n",
            "Original Comment: opo biswas er....biye cara jamao\n",
            "Tokenized Sequence: [9658, 1447, 661, 267, 2006, 9659]\n",
            "\n",
            "\n",
            "Original Comment: madarerxod tr bap gore gari jore calano nia soceton kor\n",
            "Tokenized Sequence: [9660, 304, 404, 1981, 3458, 1443, 9661, 228, 9662, 227]\n",
            "\n",
            "\n",
            "Original Comment: apu tumi joss\n",
            "Tokenized Sequence: [19, 13, 338]\n",
            "\n",
            "\n",
            "Original Comment: apu apni j atto cute ufffffffffff\n",
            "Tokenized Sequence: [19, 15, 42, 608, 348, 9663]\n",
            "\n",
            "\n",
            "Original Comment: ami fast tomar dans dekhlam\n",
            "Tokenized Sequence: [4, 1468, 26, 9664, 278]\n",
            "\n",
            "\n",
            "Original Comment: tmi ato sundor kno\n",
            "Tokenized Sequence: [69, 43, 66, 64]\n",
            "\n",
            "\n",
            "Original Comment: babu tah\n",
            "Tokenized Sequence: [1042, 1164]\n",
            "\n",
            "\n",
            "Original Comment: nich tala vara diya upor tala banaiso?\n",
            "Tokenized Sequence: [2486, 3932, 1170, 76, 253, 3932, 2303]\n",
            "\n",
            "\n",
            "Original Comment: 1st ese emn nach dekhaiya bujhailen\n",
            "Tokenized Sequence: [453, 1121, 246, 919, 2487, 9665]\n",
            "\n",
            "\n",
            "Original Comment: tumi paro deki\n",
            "Tokenized Sequence: [13, 595, 1105]\n",
            "\n",
            "\n",
            "Original Comment: sundor jinish toh agei dekhe felsi\n",
            "Tokenized Sequence: [66, 283, 88, 877, 73, 3081]\n",
            "\n",
            "\n",
            "Original Comment: height kome gelo kmne\n",
            "Tokenized Sequence: [1248, 1338, 105, 296]\n",
            "\n",
            "\n",
            "Original Comment: fast dekhailen eigula\n",
            "Tokenized Sequence: [1468, 9666, 971]\n",
            "\n",
            "\n",
            "Original Comment: apni koto niben 1 gonta 1 lakh dibo\n",
            "Tokenized Sequence: [15, 33, 3911, 297, 1877, 297, 1540, 189]\n",
            "\n",
            "\n",
            "Original Comment: sofia ansarir apon bon\n",
            "Tokenized Sequence: [9667, 9668, 9669, 322]\n",
            "\n",
            "\n",
            "Original Comment: baler phn\n",
            "Tokenized Sequence: [194, 1356]\n",
            "\n",
            "\n",
            "Original Comment: shetaaaa vagaaah dance\n",
            "Tokenized Sequence: [9670, 9671, 393]\n",
            "\n",
            "\n",
            "Original Comment: tomar nanir heda..\n",
            "Tokenized Sequence: [26, 1112, 488]\n",
            "\n",
            "\n",
            "Original Comment: puita felum\n",
            "Tokenized Sequence: [9672, 9673]\n",
            "\n",
            "\n",
            "Original Comment: accha 13500 apni soho?\n",
            "Tokenized Sequence: [1501, 9674, 15, 9675]\n",
            "\n",
            "\n",
            "Original Comment: cute magi\n",
            "Tokenized Sequence: [348, 96]\n",
            "\n",
            "\n",
            "Original Comment: dudh dekhaiya phone beche\n",
            "Tokenized Sequence: [119, 2487, 1844, 728]\n",
            "\n",
            "\n",
            "Original Comment: oto tel marar dorkar nai tumi apple chara kisui janona\n",
            "Tokenized Sequence: [948, 720, 3813, 100, 5, 13, 3933, 233, 1467, 9676]\n",
            "\n",
            "\n",
            "Original Comment: sundor jinic dekabo\n",
            "Tokenized Sequence: [66, 9677, 9678]\n",
            "\n",
            "\n",
            "Original Comment: dudu nach dekhao sundori\n",
            "Tokenized Sequence: [260, 919, 886, 894]\n",
            "\n",
            "\n",
            "Original Comment: api sona sob look bhalo lage\n",
            "Tokenized Sequence: [681, 387, 8, 1200, 198, 47]\n",
            "\n",
            "\n",
            "Original Comment: grame gele mutte jay 3jon loya, abar halloween maray\n",
            "Tokenized Sequence: [9679, 470, 9680, 92, 3727, 3934, 86, 2567, 3892]\n",
            "\n",
            "\n",
            "Original Comment: bangladesh khela dekhar theke japan jhapsa jinis dekhao valo\n",
            "Tokenized Sequence: [12, 130, 250, 21, 9681, 9682, 467, 886, 6]\n",
            "\n",
            "\n",
            "Original Comment: daraz tmk odar kora jabe???\n",
            "Tokenized Sequence: [3790, 273, 2077, 39, 126]\n",
            "\n",
            "\n",
            "Original Comment: mone hoy akono tumi onek cotto kuki fantastic\n",
            "Tokenized Sequence: [34, 14, 2059, 13, 56, 9683, 9684, 9685]\n",
            "\n",
            "\n",
            "Original Comment: bangladesh jitlo kobe??\n",
            "Tokenized Sequence: [12, 9686, 423]\n",
            "\n",
            "\n",
            "Original Comment: hagol akta\n",
            "Tokenized Sequence: [9687, 37]\n",
            "\n",
            "\n",
            "Original Comment: durr jai mor bal vedio koran,sundor vedio korta casta koran\n",
            "Tokenized Sequence: [9688, 90, 1384, 48, 347, 976, 66, 347, 1148, 9689, 976]\n",
            "\n",
            "\n",
            "Original Comment: dhaka guys dhaka tei thake dubai na\n",
            "Tokenized Sequence: [1016, 9690, 1016, 763, 114, 1377, 1]\n",
            "\n",
            "\n",
            "Original Comment: gacher dim ebar putkite vore rakho\n",
            "Tokenized Sequence: [9691, 349, 1385, 3451, 1449, 752]\n",
            "\n",
            "\n",
            "Original Comment: asolei onek boro boro peyara gach\n",
            "Tokenized Sequence: [1686, 56, 18, 18, 2003, 9692]\n",
            "\n",
            "\n",
            "Original Comment: behaya\n",
            "Tokenized Sequence: [1172]\n",
            "\n",
            "\n",
            "Original Comment: baal...\n",
            "Tokenized Sequence: [410]\n",
            "\n",
            "\n",
            "Original Comment: tmr moto boro boro dimm\n",
            "Tokenized Sequence: [32, 16, 18, 18, 9693]\n",
            "\n",
            "\n",
            "Original Comment: baler video koro\n",
            "Tokenized Sequence: [194, 24, 78]\n",
            "\n",
            "\n",
            "Original Comment: sona dekhso kono somoy naki oida ooo tv te dekhso\n",
            "Tokenized Sequence: [387, 2462, 27, 210, 29, 3677, 3242, 872, 25, 2462]\n",
            "\n",
            "\n",
            "Original Comment: dhakaiyara apnar moto abal hoy naki?\n",
            "Tokenized Sequence: [9694, 22, 16, 235, 14, 29]\n",
            "\n",
            "\n",
            "Original Comment: mr absar video copy kore banai rakhse\n",
            "Tokenized Sequence: [3930, 9695, 24, 807, 2, 1169, 2348]\n",
            "\n",
            "\n",
            "Original Comment: porimonir soto bon... banglar sunny leone\n",
            "Tokenized Sequence: [782, 1315, 322, 650, 651, 936]\n",
            "\n",
            "\n",
            "Original Comment: goriber ayesha takia\n",
            "Tokenized Sequence: [1021, 9696, 9697]\n",
            "\n",
            "\n",
            "Original Comment: tora dim par\n",
            "Tokenized Sequence: [152, 349, 969]\n",
            "\n",
            "\n",
            "Original Comment: sandals pore vdo tar sathe adjust hoito. khet\n",
            "Tokenized Sequence: [3860, 62, 703, 31, 77, 9698, 307, 831]\n",
            "\n",
            "\n",
            "Original Comment: baler logic benchod pro\n",
            "Tokenized Sequence: [194, 2165, 9699, 677]\n",
            "\n",
            "\n",
            "Original Comment: shuyar dhong\n",
            "Tokenized Sequence: [9700, 981]\n",
            "\n",
            "\n",
            "Original Comment: meyad urtinno gaja khaila ja hoy\n",
            "Tokenized Sequence: [9701, 9702, 421, 2641, 70, 14]\n",
            "\n",
            "\n",
            "Original Comment: gortu tu tumar sathe ache.\n",
            "Tokenized Sequence: [9703, 1732, 281, 77, 74]\n",
            "\n",
            "\n",
            "Original Comment: valo dress nai?\n",
            "Tokenized Sequence: [6, 164, 5]\n",
            "\n",
            "\n",
            "Original Comment: bal joto bar not interested kori toto bara baler video ase\n",
            "Tokenized Sequence: [48, 337, 134, 757, 9704, 265, 1014, 173, 194, 24, 45]\n",
            "\n",
            "\n",
            "Original Comment: abal jokon notton noton video more..\n",
            "Tokenized Sequence: [235, 1789, 9705, 2188, 24, 534]\n",
            "\n",
            "\n",
            "Original Comment: dhakar public kopale likha bokachoda\n",
            "Tokenized Sequence: [1632, 354, 1630, 2200, 372]\n",
            "\n",
            "\n",
            "Original Comment: akhon apni dim diye baccha futan.\n",
            "Tokenized Sequence: [268, 15, 349, 49, 153, 9706]\n",
            "\n",
            "\n",
            "Original Comment: pagol hoicho j basai jane??\n",
            "Tokenized Sequence: [108, 9707, 42, 2000, 275]\n",
            "\n",
            "\n",
            "Original Comment: apu apnar gacer dim gula onk bro\n",
            "Tokenized Sequence: [19, 22, 9708, 349, 55, 58, 406]\n",
            "\n",
            "\n",
            "Original Comment: apni kun groher manush aunty\n",
            "Tokenized Sequence: [15, 1534, 9709, 67, 1198]\n",
            "\n",
            "\n",
            "Original Comment: gidhor marka\n",
            "Tokenized Sequence: [9710, 325]\n",
            "\n",
            "\n",
            "Original Comment: dudh dekh tomar mukher shoman\n",
            "Tokenized Sequence: [119, 503, 26, 1847, 3935]\n",
            "\n",
            "\n",
            "Original Comment: madarchot taka kmne nosto kore\n",
            "Tokenized Sequence: [9711, 172, 296, 215, 2]\n",
            "\n",
            "\n",
            "Original Comment: oma koto boro\n",
            "Tokenized Sequence: [2754, 33, 18]\n",
            "\n",
            "\n",
            "Original Comment: asol maal\n",
            "Tokenized Sequence: [808, 310]\n",
            "\n",
            "\n",
            "Original Comment: khankir chawal loker khawa hoyna tora kortesos eigula\n",
            "Tokenized Sequence: [318, 9712, 1151, 768, 1387, 152, 9713, 971]\n",
            "\n",
            "\n",
            "Original Comment: abaal chuda shangbadik kono khobor pash na?\n",
            "Tokenized Sequence: [2488, 1354, 484, 27, 861, 9714, 1]\n",
            "\n",
            "\n",
            "Original Comment: besi besi kore felle kintu kew dekhbe na naturally koren\n",
            "Tokenized Sequence: [176, 176, 2, 9715, 68, 142, 3895, 1, 9716, 83]\n",
            "\n",
            "\n",
            "Original Comment: tomader elakar chairman taraa dey na tomake egula korle rastay?\n",
            "Tokenized Sequence: [1125, 3936, 9717, 9718, 264, 1, 339, 540, 183, 890]\n",
            "\n",
            "\n",
            "Original Comment: finishing hoi nai!! ushta khaye pore jawar kotha chilo\n",
            "Tokenized Sequence: [9719, 38, 5, 9720, 9721, 62, 1226, 10, 94]\n",
            "\n",
            "\n",
            "Original Comment: vai vuri joss hoise\n",
            "Tokenized Sequence: [3, 1260, 338, 188]\n",
            "\n",
            "\n",
            "Original Comment: ektu boro hoye geso mone hocche?\n",
            "Tokenized Sequence: [154, 18, 20, 1421, 34, 465]\n",
            "\n",
            "\n",
            "Original Comment: ufff bujhlam nh amaro moja laglo\n",
            "Tokenized Sequence: [652, 502, 135, 1698, 224, 524]\n",
            "\n",
            "\n",
            "Original Comment: eto shundor nach jiboneoooooooo dekhinai\n",
            "Tokenized Sequence: [60, 303, 919, 9722, 3709]\n",
            "\n",
            "\n",
            "Original Comment: hoile btr hoito\n",
            "Tokenized Sequence: [398, 9723, 307]\n",
            "\n",
            "\n",
            "Original Comment: ami korsi,uff\n",
            "Tokenized Sequence: [4, 1403, 424]\n",
            "\n",
            "\n",
            "Original Comment: ato shundor content , ekta bhalo director diya shoot kora hoynai ken ?\n",
            "Tokenized Sequence: [43, 303, 1562, 36, 198, 9724, 76, 9725, 39, 3672, 146]\n",
            "\n",
            "\n",
            "Original Comment: bhalo talent dam nai ken ?\n",
            "Tokenized Sequence: [198, 612, 1102, 5, 146]\n",
            "\n",
            "\n",
            "Original Comment: eto shundor office young creative talent nai ken?\n",
            "Tokenized Sequence: [60, 303, 2027, 1806, 9726, 612, 5, 146]\n",
            "\n",
            "\n",
            "Original Comment: acting thik moto hoi nai ken?\n",
            "Tokenized Sequence: [2472, 61, 16, 38, 5, 146]\n",
            "\n",
            "\n",
            "Original Comment: noise clear koren nai ken\n",
            "Tokenized Sequence: [9727, 3700, 83, 5, 146]\n",
            "\n",
            "\n",
            "Original Comment: opu tmi kbe english sikla\n",
            "Tokenized Sequence: [483, 69, 2261, 750, 9728]\n",
            "\n",
            "\n",
            "Original Comment: chor salay\n",
            "Tokenized Sequence: [1472, 3215]\n",
            "\n",
            "\n",
            "Original Comment: are bukaxuda. seito parbi tui.\n",
            "Tokenized Sequence: [177, 9729, 9730, 2539, 23]\n",
            "\n",
            "\n",
            "Original Comment: tor ma heda\n",
            "Tokenized Sequence: [17, 187, 488]\n",
            "\n",
            "\n",
            "Original Comment: paltu chele akta\n",
            "Tokenized Sequence: [3937, 346, 37]\n",
            "\n",
            "\n",
            "Original Comment: aita kono video holo paltu\n",
            "Tokenized Sequence: [149, 27, 24, 170, 3937]\n",
            "\n",
            "\n",
            "Original Comment: onk sondor\n",
            "Tokenized Sequence: [58, 993]\n",
            "\n",
            "\n",
            "Original Comment: moga\n",
            "Tokenized Sequence: [9731]\n",
            "\n",
            "\n",
            "Original Comment: borishailla khetar gatti\n",
            "Tokenized Sequence: [1774, 9732, 3741]\n",
            "\n",
            "\n",
            "Original Comment: cheleta america ty taki ato valo bangla bolty pare asholy good.....\n",
            "Tokenized Sequence: [2454, 3631, 1778, 1092, 43, 6, 396, 9733, 81, 9734, 868]\n",
            "\n",
            "\n",
            "Original Comment: sei lagse video\n",
            "Tokenized Sequence: [115, 435, 24]\n",
            "\n",
            "\n",
            "Original Comment: kichu kichu abal ase nijera valoh kichu korte parbe nh abr onner valo thaka dekte parbe nh\n",
            "Tokenized Sequence: [80, 80, 235, 45, 2388, 9735, 80, 41, 440, 135, 169, 707, 6, 292, 479, 440, 135]\n",
            "\n",
            "\n",
            "Original Comment: maderchuud is back\n",
            "Tokenized Sequence: [9736, 739, 1845]\n",
            "\n",
            "\n",
            "Original Comment: seta bangga nas dila bondu\n",
            "Tokenized Sequence: [220, 9737, 3643, 519, 9738]\n",
            "\n",
            "\n",
            "Original Comment: smoke machine na paya biri diya kam chalaise\n",
            "Tokenized Sequence: [9739, 1604, 1, 9740, 636, 76, 274, 3555]\n",
            "\n",
            "\n",
            "Original Comment: bacha der tika din noito emn potibondhi hobe\n",
            "Tokenized Sequence: [1349, 44, 9741, 35, 3002, 246, 3938, 11]\n",
            "\n",
            "\n",
            "Original Comment: mother cod\n",
            "Tokenized Sequence: [1394, 9742]\n",
            "\n",
            "\n",
            "Original Comment: hijla pro max\n",
            "Tokenized Sequence: [1404, 677, 1287]\n",
            "\n",
            "\n",
            "Original Comment: abla is back\n",
            "Tokenized Sequence: [9743, 739, 1845]\n",
            "\n",
            "\n",
            "Original Comment: pant ekta amr theke niye jais. sheta bangaa celebrity\n",
            "Tokenized Sequence: [314, 36, 7, 21, 65, 3364, 3832, 9744, 937]\n",
            "\n",
            "\n",
            "Original Comment: hedarpo\n",
            "Tokenized Sequence: [9745]\n",
            "\n",
            "\n",
            "Original Comment: lagtese j toh aita kono furniture showroom a. bed almirahr wrapping akhono khule nai\n",
            "Tokenized Sequence: [1381, 42, 88, 149, 27, 9746, 9747, 1022, 1980, 9748, 9749, 822, 279, 5]\n",
            "\n",
            "\n",
            "Original Comment: tore dhaykha hijra lojja paybo\n",
            "Tokenized Sequence: [216, 9750, 284, 245, 9751]\n",
            "\n",
            "\n",
            "Original Comment: cartoon akta\n",
            "Tokenized Sequence: [9752, 37]\n",
            "\n",
            "\n",
            "Original Comment: vaiya lipstick shade\n",
            "Tokenized Sequence: [544, 1864, 9753]\n",
            "\n",
            "\n",
            "Original Comment: nola khankir pola\n",
            "Tokenized Sequence: [9754, 318, 116]\n",
            "\n",
            "\n",
            "Original Comment: full bc\n",
            "Tokenized Sequence: [811, 9755]\n",
            "\n",
            "\n",
            "Original Comment: bepar hassssokor\n",
            "Tokenized Sequence: [684, 9756]\n",
            "\n",
            "\n",
            "Original Comment: gaja khaiya aisos naki\n",
            "Tokenized Sequence: [421, 776, 2463, 29]\n",
            "\n",
            "\n",
            "Original Comment: abaal\n",
            "Tokenized Sequence: [2488]\n",
            "\n",
            "\n",
            "Original Comment: tokai\n",
            "Tokenized Sequence: [1865]\n",
            "\n",
            "\n",
            "Original Comment: kire vai pant purai chira\n",
            "Tokenized Sequence: [552, 3, 314, 291, 1790]\n",
            "\n",
            "\n",
            "Original Comment: potibondhi\n",
            "Tokenized Sequence: [3938]\n",
            "\n",
            "\n",
            "Original Comment: welcome back bosti\n",
            "Tokenized Sequence: [9757, 1845, 1062]\n",
            "\n",
            "\n",
            "Original Comment: etw taka koi kobor nibi? ekta pant kinte paros na\n",
            "Tokenized Sequence: [9758, 172, 93, 1216, 9759, 36, 314, 2011, 1939, 1]\n",
            "\n",
            "\n",
            "Original Comment: vi tui chera cheri nh soo lipstick aktu kom lagais cz manush chinte problem hoi tui maiya nki pola\n",
            "Tokenized Sequence: [641, 23, 1215, 2399, 135, 3249, 1864, 178, 248, 9760, 921, 67, 1854, 433, 38, 23, 150, 282, 116]\n",
            "\n",
            "\n",
            "Original Comment: dhur sagol\n",
            "Tokenized Sequence: [737, 884]\n",
            "\n",
            "\n",
            "Original Comment: modarchud\n",
            "Tokenized Sequence: [9761]\n",
            "\n",
            "\n",
            "Original Comment: vape dhuya ato kom ken?\n",
            "Tokenized Sequence: [9762, 9763, 43, 248, 146]\n",
            "\n",
            "\n",
            "Original Comment: sala madarbod\n",
            "Tokenized Sequence: [159, 9764]\n",
            "\n",
            "\n",
            "Original Comment: ore protibondi tiktoker\n",
            "Tokenized Sequence: [91, 1660, 2347]\n",
            "\n",
            "\n",
            "Original Comment: pant tho daki sob cera.. sorom nai\n",
            "Tokenized Sequence: [314, 1372, 1599, 8, 2009, 577, 5]\n",
            "\n",
            "\n",
            "Original Comment: bakcod\n",
            "Tokenized Sequence: [9765]\n",
            "\n",
            "\n",
            "Original Comment: abaal jaake bole\n",
            "Tokenized Sequence: [2488, 9766, 54]\n",
            "\n",
            "\n",
            "Original Comment: tomk asty bolcy bal pakna tati\n",
            "Tokenized Sequence: [2274, 9767, 9768, 48, 1933, 9769]\n",
            "\n",
            "\n",
            "Original Comment: aisos abar ja ga\n",
            "Tokenized Sequence: [2463, 86, 70, 1067]\n",
            "\n",
            "\n",
            "Original Comment: pura boshti\n",
            "Tokenized Sequence: [384, 9770]\n",
            "\n",
            "\n",
            "Original Comment: methorer baccha\n",
            "Tokenized Sequence: [9771, 153]\n",
            "\n",
            "\n",
            "Original Comment: sodor ghat gham khor pura\n",
            "Tokenized Sequence: [3939, 3940, 9772, 1007, 384]\n",
            "\n",
            "\n",
            "Original Comment: pagol choda kothakar\n",
            "Tokenized Sequence: [108, 415, 735]\n",
            "\n",
            "\n",
            "Original Comment: ram chagol\n",
            "Tokenized Sequence: [1721, 605]\n",
            "\n",
            "\n",
            "Original Comment: shala ganja khor\n",
            "Tokenized Sequence: [243, 710, 1007]\n",
            "\n",
            "\n",
            "Original Comment: bechara hat marte marte shukai gese\n",
            "Tokenized Sequence: [9773, 379, 704, 704, 9774, 87]\n",
            "\n",
            "\n",
            "Original Comment: amer toilet ghu tor thikka smart maderson\n",
            "Tokenized Sequence: [742, 1073, 984, 17, 9775, 1828, 9776]\n",
            "\n",
            "\n",
            "Original Comment: no 1 pagolchoda\n",
            "Tokenized Sequence: [447, 297, 9777]\n",
            "\n",
            "\n",
            "Original Comment: ac dekaire amr basat ou ase ac ami dekairm na\n",
            "Tokenized Sequence: [3941, 9778, 7, 3567, 9779, 45, 3941, 4, 9780, 1]\n",
            "\n",
            "\n",
            "Original Comment: bts hijra\n",
            "Tokenized Sequence: [9781, 284]\n",
            "\n",
            "\n",
            "Original Comment: gusti *h*di bro\n",
            "Tokenized Sequence: [9782, 9783, 475, 406]\n",
            "\n",
            "\n",
            "Original Comment: vai ganja asa nah tahkle bolis. ha ami tuke vai bollam kano tui,, to,, sudir vai\n",
            "Tokenized Sequence: [3, 710, 570, 52, 9784, 1640, 352, 4, 9785, 3, 840, 361, 23, 506, 1882, 3]\n",
            "\n",
            "\n",
            "Original Comment: chor\n",
            "Tokenized Sequence: [1472]\n",
            "\n",
            "\n",
            "Original Comment: image tar lover ace.....\n",
            "Tokenized Sequence: [9786, 31, 9787, 207]\n",
            "\n",
            "\n",
            "Original Comment: protibondi ultra max pro\n",
            "Tokenized Sequence: [1660, 9788, 1287, 677]\n",
            "\n",
            "\n",
            "Original Comment: boka coda\n",
            "Tokenized Sequence: [986, 1165]\n",
            "\n",
            "\n",
            "Original Comment: binchot dakle mon da chai ore aina 24 hours full dance korai,\n",
            "Tokenized Sequence: [9789, 9790, 84, 351, 124, 91, 2741, 1481, 9791, 811, 393, 9792]\n",
            "\n",
            "\n",
            "Original Comment: ganja khor\n",
            "Tokenized Sequence: [710, 1007]\n",
            "\n",
            "\n",
            "Original Comment: areh era ke?! koi theke elo era! allah tader hedayek dan korun\n",
            "Tokenized Sequence: [2711, 331, 1089, 93, 21, 3183, 331, 59, 231, 9793, 624, 451]\n",
            "\n",
            "\n",
            "Original Comment: sala gajakhor\n",
            "Tokenized Sequence: [159, 1818]\n",
            "\n",
            "\n",
            "Original Comment: protibondhir baccha\n",
            "Tokenized Sequence: [9794, 153]\n",
            "\n",
            "\n",
            "Original Comment: mukh ee kmn beka bara\n",
            "Tokenized Sequence: [676, 584, 497, 3528, 173]\n",
            "\n",
            "\n",
            "Original Comment: tmr bicite current lagse?\n",
            "Tokenized Sequence: [32, 9795, 1358, 435]\n",
            "\n",
            "\n",
            "Original Comment: abal coda\n",
            "Tokenized Sequence: [235, 1165]\n",
            "\n",
            "\n",
            "Original Comment: ajj comment korbo na\n",
            "Tokenized Sequence: [2740, 197, 186, 1]\n",
            "\n",
            "\n",
            "Original Comment: vaii tor kiii taka poyshar atttoi ovab porse attto chira ken pent...ta tor....? maya laglo tor jonno...\n",
            "Tokenized Sequence: [1071, 17, 2397, 172, 9796, 9797, 485, 611, 9798, 1790, 146, 3456, 871, 17, 705, 524, 17, 28]\n",
            "\n",
            "\n",
            "Original Comment: khangkir pola ...amare cenos...samne asle jobo korbo...tui jubo somaj nossto kortecis\n",
            "Tokenized Sequence: [9799, 116, 408, 9800, 389, 1458, 9801, 186, 23, 9802, 1739, 9803, 9804]\n",
            "\n",
            "\n",
            "Original Comment: sob ii rong khela\n",
            "Tokenized Sequence: [8, 3681, 1175, 130]\n",
            "\n",
            "\n",
            "Original Comment: durrrr khankir poth bondho kor shala\n",
            "Tokenized Sequence: [9805, 318, 9806, 469, 227, 243]\n",
            "\n",
            "\n",
            "Original Comment: dandi kor\n",
            "Tokenized Sequence: [1497, 227]\n",
            "\n",
            "\n",
            "Original Comment: condom fete jonmo niche eta\n",
            "Tokenized Sequence: [1344, 1769, 1513, 509, 95]\n",
            "\n",
            "\n",
            "Original Comment: sala lojjao lge bal chal banay banchod\n",
            "Tokenized Sequence: [159, 9807, 793, 48, 1043, 827, 9808]\n",
            "\n",
            "\n",
            "Original Comment: salae sagol\n",
            "Tokenized Sequence: [9809, 884]\n",
            "\n",
            "\n",
            "Original Comment: eto kapakapi korar reason ki?\n",
            "Tokenized Sequence: [60, 3818, 101, 3606, 175]\n",
            "\n",
            "\n",
            "Original Comment: kamla sala\n",
            "Tokenized Sequence: [9810, 159]\n",
            "\n",
            "\n",
            "Original Comment: tokai level\n",
            "Tokenized Sequence: [1865, 909]\n",
            "\n",
            "\n",
            "Original Comment: vag madarchod\n",
            "Tokenized Sequence: [2489, 377]\n",
            "\n",
            "\n",
            "Original Comment: pagol matha karap hoyca\n",
            "Tokenized Sequence: [108, 420, 916, 9811]\n",
            "\n",
            "\n",
            "Original Comment: after long time ami onek hashlam\n",
            "Tokenized Sequence: [3607, 3450, 371, 4, 56, 9812]\n",
            "\n",
            "\n",
            "Original Comment: bokaaaaaaaaacodaaaaaaaa\n",
            "Tokenized Sequence: [9813]\n",
            "\n",
            "\n",
            "Original Comment: aysob pagol.sagol.kon jagar teke je ase.fuk.you..\n",
            "Tokenized Sequence: [3256, 108, 884, 145, 3429, 918, 46, 45, 9814, 313]\n",
            "\n",
            "\n",
            "Original Comment: tik tok koira kicho na parok...koita sondor farnichar joraice\n",
            "Tokenized Sequence: [269, 778, 99, 9815, 1, 9816, 1370, 993, 9817, 9818]\n",
            "\n",
            "\n",
            "Original Comment: dur madarbot\n",
            "Tokenized Sequence: [422, 9819]\n",
            "\n",
            "\n",
            "Original Comment: tokai jokon vab nay\n",
            "Tokenized Sequence: [1865, 1789, 525, 658]\n",
            "\n",
            "\n",
            "Original Comment: kera uthse naki tor\n",
            "Tokenized Sequence: [9820, 3942, 29, 17]\n",
            "\n",
            "\n",
            "Original Comment: bal korlo lafay lufay\n",
            "Tokenized Sequence: [48, 343, 3549, 9821]\n",
            "\n",
            "\n",
            "Original Comment: dudu. matartodd. mor\n",
            "Tokenized Sequence: [260, 9822, 1384]\n",
            "\n",
            "\n",
            "Original Comment: hala hangkirpoyare chorer duuilla lager\n",
            "Tokenized Sequence: [333, 9823, 9824, 9825, 2452]\n",
            "\n",
            "\n",
            "Original Comment: vai tomer bashai jane tumi j 110% psycho hoiya geso\n",
            "Tokenized Sequence: [3, 1225, 9826, 275, 13, 42, 9827, 3626, 232, 1421]\n",
            "\n",
            "\n",
            "Original Comment: oii madarchod tore dekhte issa kre naaaa\n",
            "Tokenized Sequence: [2182, 377, 216, 112, 1347, 432, 2994]\n",
            "\n",
            "\n",
            "Original Comment: dur halar po eta kono entry holo\n",
            "Tokenized Sequence: [422, 563, 2185, 95, 27, 9828, 170]\n",
            "\n",
            "\n",
            "Original Comment: bokachoda ekn vlo howr tym ase tr. sudhere jhh... scl,clg join kor.. manush hbi. tiktok korle goru hbi future\n",
            "Tokenized Sequence: [372, 691, 75, 2652, 2346, 45, 304, 9829, 9830, 2396, 3877, 9831, 227, 67, 3943, 367, 183, 935, 3943, 1265]\n",
            "\n",
            "\n",
            "Original Comment: video dekhe na hese parlam na\n",
            "Tokenized Sequence: [24, 73, 1, 3751, 400, 1]\n",
            "\n",
            "\n",
            "Original Comment: tokai hala\n",
            "Tokenized Sequence: [1865, 333]\n",
            "\n",
            "\n",
            "Original Comment: fatracuda\n",
            "Tokenized Sequence: [9832]\n",
            "\n",
            "\n",
            "Original Comment: banc***d sala dkhlei mejaj kharf hoiya jay\n",
            "Tokenized Sequence: [9833, 1310, 159, 9834, 1706, 9835, 232, 92]\n",
            "\n",
            "\n",
            "Original Comment: hedar vido koros bainxud\n",
            "Tokenized Sequence: [657, 9836, 669, 9837]\n",
            "\n",
            "\n",
            "Original Comment: vai bish kheye more jete iccha kore\n",
            "Tokenized Sequence: [3, 1246, 165, 534, 1271, 1201, 2]\n",
            "\n",
            "\n",
            "Original Comment: ore hijra no. 1 mukhe lips stik lagay\n",
            "Tokenized Sequence: [91, 284, 447, 297, 259, 3322, 9838, 3740]\n",
            "\n",
            "\n",
            "Original Comment: tate amar baal chera gelo\n",
            "Tokenized Sequence: [907, 9, 410, 1215, 105]\n",
            "\n",
            "\n",
            "Original Comment: ora madarcod\n",
            "Tokenized Sequence: [158, 9839]\n",
            "\n",
            "\n",
            "Original Comment: vai tmre dekhle amr mone chay pabnay sit buk kore dite. abal marka pola pain abar mvir kta koy age nije thik ho vai. gaja khur ekn tiktok str.\n",
            "Tokenized Sequence: [3, 2338, 332, 7, 34, 300, 2098, 1514, 1214, 2, 117, 235, 325, 116, 1442, 86, 9840, 9841, 1023, 71, 203, 61, 405, 3, 421, 9842, 691, 367, 9843]\n",
            "\n",
            "\n",
            "Original Comment: kire hijla\n",
            "Tokenized Sequence: [552, 1404]\n",
            "\n",
            "\n",
            "Original Comment: halar baincod... shor\n",
            "Tokenized Sequence: [563, 2130, 2731]\n",
            "\n",
            "\n",
            "Original Comment: dury jaia mor vhi tora kellega amar samny ahos\n",
            "Tokenized Sequence: [9844, 9845, 1384, 1230, 152, 9846, 9, 9847, 9848]\n",
            "\n",
            "\n",
            "Original Comment: ato lipstick keno.purai hizla moto lagse dekte...chagol jani kothakar\n",
            "Tokenized Sequence: [43, 1864, 111, 291, 3944, 16, 435, 479, 605, 160, 735]\n",
            "\n",
            "\n",
            "Original Comment: edit telay kala hoye geso\n",
            "Tokenized Sequence: [722, 9849, 499, 20, 1421]\n",
            "\n",
            "\n",
            "Original Comment: vai bissas kor hothat samne asar por voy paisi\n",
            "Tokenized Sequence: [3, 1080, 227, 9850, 389, 2301, 72, 838, 2014]\n",
            "\n",
            "\n",
            "Original Comment: abal coda\n",
            "Tokenized Sequence: [235, 1165]\n",
            "\n",
            "\n",
            "Original Comment: dur mader cud hala\n",
            "Tokenized Sequence: [422, 3017, 2438, 333]\n",
            "\n",
            "\n",
            "Original Comment: sala m c\n",
            "Tokenized Sequence: [159, 1428, 317]\n",
            "\n",
            "\n",
            "Original Comment: bosti\n",
            "Tokenized Sequence: [1062]\n",
            "\n",
            "\n",
            "Original Comment: bangir put\n",
            "Tokenized Sequence: [9851, 962]\n",
            "\n",
            "\n",
            "Original Comment: gajar jol khaise\n",
            "Tokenized Sequence: [9852, 664, 1357]\n",
            "\n",
            "\n",
            "Original Comment: ture samn paile jota diya pitai tam sotti kotha\n",
            "Tokenized Sequence: [9853, 9854, 1086, 9855, 76, 9856, 9857, 555, 10]\n",
            "\n",
            "\n",
            "Original Comment: tor mar heda, noakhali ay boira dimu\n",
            "Tokenized Sequence: [17, 487, 488, 2284, 229, 2490, 630]\n",
            "\n",
            "\n",
            "Original Comment: pant chirlo kmne apu,?\n",
            "Tokenized Sequence: [314, 9858, 296, 19]\n",
            "\n",
            "\n",
            "Original Comment: dat ober gaja kaile amon oy\n",
            "Tokenized Sequence: [1653, 3801, 421, 9859, 133, 743]\n",
            "\n",
            "\n",
            "Original Comment: ore halarpula kisue hoinai tor dance\n",
            "Tokenized Sequence: [91, 9860, 9861, 3876, 17, 393]\n",
            "\n",
            "\n",
            "Original Comment: tomar upor crush khai kida bhai\n",
            "Tokenized Sequence: [26, 253, 316, 256, 2036, 53]\n",
            "\n",
            "\n",
            "Original Comment: make up karone prothibir prothom komola colour nagerian lagtase. tai crush khawa nished\n",
            "Tokenized Sequence: [792, 261, 1160, 9862, 1030, 9863, 1813, 9864, 1095, 40, 316, 768, 9865]\n",
            "\n",
            "\n",
            "Original Comment: ceter bal.\n",
            "Tokenized Sequence: [9866, 48]\n",
            "\n",
            "\n",
            "Original Comment: propose dur kotha tra dekhlai amar bomi ase\n",
            "Tokenized Sequence: [1398, 422, 10, 3843, 9867, 9, 3218, 45]\n",
            "\n",
            "\n",
            "Original Comment: ganja porse naki pat\n",
            "Tokenized Sequence: [710, 611, 29, 2323]\n",
            "\n",
            "\n",
            "Original Comment: pagol choda\n",
            "Tokenized Sequence: [108, 415]\n",
            "\n",
            "\n",
            "Original Comment: tr harbal mayed sas\n",
            "Tokenized Sequence: [304, 2491, 9868, 2919]\n",
            "\n",
            "\n",
            "Original Comment: doniyate manuser ovab porse\n",
            "Tokenized Sequence: [9869, 2079, 485, 611]\n",
            "\n",
            "\n",
            "Original Comment: bal cero tumi\n",
            "Tokenized Sequence: [48, 9870, 13]\n",
            "\n",
            "\n",
            "Original Comment: korom chod\n",
            "Tokenized Sequence: [9871, 804]\n",
            "\n",
            "\n",
            "Original Comment: namaj porcis? friday te. hudai vedio charis vag\n",
            "Tokenized Sequence: [1100, 9872, 9873, 25, 746, 347, 9874, 2489]\n",
            "\n",
            "\n",
            "Original Comment: kache aho suna kortachi\n",
            "Tokenized Sequence: [360, 1197, 2429, 9875]\n",
            "\n",
            "\n",
            "Original Comment: appu vhi i fack u,,, tur boin cudi\n",
            "Tokenized Sequence: [2361, 1230, 171, 9876, 862, 1127, 335, 1340]\n",
            "\n",
            "\n",
            "Original Comment: sesra ekta\n",
            "Tokenized Sequence: [3861, 36]\n",
            "\n",
            "\n",
            "Original Comment: khai kam ache bahi\n",
            "Tokenized Sequence: [256, 274, 74, 3035]\n",
            "\n",
            "\n",
            "Original Comment: namber 1tukai\n",
            "Tokenized Sequence: [9877, 9878]\n",
            "\n",
            "\n",
            "Original Comment: vaiya egiye jan\n",
            "Tokenized Sequence: [544, 3945, 378]\n",
            "\n",
            "\n",
            "Original Comment: tor ye je maiya propose korbo hitir moto hagl ekga nai\n",
            "Tokenized Sequence: [17, 1988, 46, 150, 1398, 186, 9879, 16, 9880, 9881, 5]\n",
            "\n",
            "\n",
            "Original Comment: amr cras oppu\n",
            "Tokenized Sequence: [7, 9882, 9883]\n",
            "\n",
            "\n",
            "Original Comment: you are joss vaia\n",
            "Tokenized Sequence: [313, 177, 338, 455]\n",
            "\n",
            "\n",
            "Original Comment: tor look sakib khan moto\n",
            "Tokenized Sequence: [17, 1200, 790, 643, 16]\n",
            "\n",
            "\n",
            "Original Comment: krum na propos\n",
            "Tokenized Sequence: [9884, 1, 9885]\n",
            "\n",
            "\n",
            "Original Comment: ktha age jei obstai chilo oi obstai akhn thakle manaito\n",
            "Tokenized Sequence: [520, 71, 380, 3946, 94, 57, 3946, 151, 143, 9886]\n",
            "\n",
            "\n",
            "Original Comment: aj porjonto kaure proposed kore nai apnare badi dilam\n",
            "Tokenized Sequence: [123, 599, 9887, 9888, 2, 5, 355, 9889, 596]\n",
            "\n",
            "\n",
            "Original Comment: tomar mukhe eta manyna brah\n",
            "Tokenized Sequence: [26, 259, 95, 9890, 3254]\n",
            "\n",
            "\n",
            "Original Comment: are khankir bachcha tor lozza nai\n",
            "Tokenized Sequence: [177, 318, 1195, 17, 9891, 5]\n",
            "\n",
            "\n",
            "Original Comment: ofss.. mojja\n",
            "Tokenized Sequence: [9892, 9893]\n",
            "\n",
            "\n",
            "Original Comment: i think, harbal date ses hoye ashtese\n",
            "Tokenized Sequence: [171, 2422, 2491, 1415, 225, 20, 3602]\n",
            "\n",
            "\n",
            "Original Comment: pote bonde shala\n",
            "Tokenized Sequence: [3266, 9894, 243]\n",
            "\n",
            "\n",
            "Original Comment: tui vuji agula koroc jah like app vedio kor!\n",
            "Tokenized Sequence: [23, 9895, 478, 3743, 9896, 381, 9897, 347, 227]\n",
            "\n",
            "\n",
            "Original Comment: mutki hutkir sathe manah nah vai\n",
            "Tokenized Sequence: [1786, 9898, 77, 9899, 52, 3]\n",
            "\n",
            "\n",
            "Original Comment: opu cudir bhai\n",
            "Tokenized Sequence: [483, 2492, 53]\n",
            "\n",
            "\n",
            "Original Comment: toi abal\n",
            "Tokenized Sequence: [388, 235]\n",
            "\n",
            "\n",
            "Original Comment: mother chod\n",
            "Tokenized Sequence: [1394, 804]\n",
            "\n",
            "\n",
            "Original Comment: onk sundor dkhacce,amr onk vlo lge apnake,mota hye aro vlo dkhacce\n",
            "Tokenized Sequence: [58, 66, 3947, 7, 58, 75, 793, 192, 214, 1186, 131, 75, 3947]\n",
            "\n",
            "\n",
            "Original Comment: mota howar topic jodi bolta tmar moto hoiya sobaike tak lagiye ditam\n",
            "Tokenized Sequence: [214, 645, 9900, 98, 2229, 9901, 16, 232, 1457, 1122, 3948, 1120]\n",
            "\n",
            "\n",
            "Original Comment: gitar bajano kivabe bondho korcen aktu bistarito janaben plz\n",
            "Tokenized Sequence: [3792, 9902, 392, 469, 9903, 178, 9904, 2393, 234]\n",
            "\n",
            "\n",
            "Original Comment: apni thik achen valo achen etai onk\n",
            "Tokenized Sequence: [15, 61, 1400, 6, 1400, 2253, 58]\n",
            "\n",
            "\n",
            "Original Comment: kire ket marka chele tui bole gorur sui nisos\n",
            "Tokenized Sequence: [552, 9905, 325, 346, 23, 54, 1078, 9906, 9907]\n",
            "\n",
            "\n",
            "Original Comment: opu ekta beyadop karon. karon opu vai dui banglar supper star shakib khaner shathe tulona kore. opu vai shakiber payer nokher joggoi na\n",
            "Tokenized Sequence: [483, 36, 1879, 329, 329, 483, 3, 382, 650, 9908, 798, 1462, 9909, 1401, 3316, 2, 483, 3, 9910, 3896, 9911, 9912, 1]\n",
            "\n",
            "\n",
            "Original Comment: bhai mota houar poddhoti bolle khub upokar hoito\n",
            "Tokenized Sequence: [53, 214, 2940, 9913, 785, 51, 1549, 307]\n",
            "\n",
            "\n",
            "Original Comment: amio mota hoite chai sutki jibon bhallage na\n",
            "Tokenized Sequence: [238, 214, 428, 124, 2320, 559, 9914, 1]\n",
            "\n",
            "\n",
            "Original Comment: vai tumi use kore muta hoycho..and eto sundor hoyche setai jante cai..???\n",
            "Tokenized Sequence: [3, 13, 403, 2, 9915, 9916, 200, 60, 66, 9917, 1147, 533, 513]\n",
            "\n",
            "\n",
            "Original Comment: video mone hoi bathroom make kora !!\n",
            "Tokenized Sequence: [24, 34, 38, 1318, 792, 39]\n",
            "\n",
            "\n",
            "Original Comment: tmi cudir silay ekn oo aso\n",
            "Tokenized Sequence: [69, 2492, 9918, 691, 693, 237]\n",
            "\n",
            "\n",
            "Original Comment: vai tmr tik tok account verified hocce na keno?\n",
            "Tokenized Sequence: [3, 32, 269, 778, 9919, 3689, 825, 1, 111]\n",
            "\n",
            "\n",
            "Original Comment: mangerbeta\n",
            "Tokenized Sequence: [9920]\n",
            "\n",
            "\n",
            "Original Comment: kichu janar nay sudu eta bolbo egiye jaw kew kichu bolle mono bol haraiyo nah bhai\n",
            "Tokenized Sequence: [80, 3642, 658, 336, 95, 473, 3945, 597, 142, 80, 785, 2883, 779, 9921, 52, 53]\n",
            "\n",
            "\n",
            "Original Comment: tor fokinnir poo vab codao ,nai she kono cheter bal vab lou lakh poti\n",
            "Tokenized Sequence: [17, 1705, 9922, 525, 2128, 5, 795, 27, 1861, 48, 525, 9923, 1540, 3118]\n",
            "\n",
            "\n",
            "Original Comment: vai mota hoite partace na j gf brek up kore palce, kamne mota homu.\n",
            "Tokenized Sequence: [3, 214, 428, 9924, 1, 42, 359, 9925, 261, 2, 9926, 1507, 214, 9927]\n",
            "\n",
            "\n",
            "Original Comment: beda tui amader president hoisos naki questions kortam mora goro keyea boli gesos.naki harbal.kaisos bai\n",
            "Tokenized Sequence: [1223, 23, 132, 2597, 9928, 29, 9929, 675, 1184, 9930, 9931, 2876, 9932, 29, 2491, 3189, 471]\n",
            "\n",
            "\n",
            "Original Comment: apne akhone kothay thaken ?r bortomane kii kaj kortesen?r porashuna koren?na korle korar icche ache kina?\n",
            "Tokenized Sequence: [638, 9933, 528, 748, 162, 9934, 1254, 109, 1019, 162, 9935, 83, 1, 183, 101, 3540, 74, 1435]\n",
            "\n",
            "\n",
            "Original Comment: apu vai tumi akta manchu dadar closup hasi dao\n",
            "Tokenized Sequence: [19, 3, 13, 37, 9936, 2794, 9937, 628, 581]\n",
            "\n",
            "\n",
            "Original Comment: aiccha vai apnar lojja lage na?\n",
            "Tokenized Sequence: [9938, 3, 22, 245, 47, 1]\n",
            "\n",
            "\n",
            "Original Comment: opu vhai i love you\n",
            "Tokenized Sequence: [483, 855, 171, 444, 313]\n",
            "\n",
            "\n",
            "Original Comment: biyah me..hanga me opu vhai\n",
            "Tokenized Sequence: [9939, 1081, 9940, 1081, 483, 855]\n",
            "\n",
            "\n",
            "Original Comment: manous poribotton seil hoicea\n",
            "Tokenized Sequence: [9941, 9942, 9943, 9944]\n",
            "\n",
            "\n",
            "Original Comment: halarpu hala gorur osud khaia mota hoia vab chudao vab tmr pukki dia dukhie dibo\n",
            "Tokenized Sequence: [9945, 333, 1078, 9946, 717, 214, 295, 525, 2340, 525, 32, 9947, 252, 9948, 189]\n",
            "\n",
            "\n",
            "Original Comment: 2r hijrar moto lagce\n",
            "Tokenized Sequence: [9949, 2689, 16, 773]\n",
            "\n",
            "\n",
            "Original Comment: apnar videor sound quality valo na\n",
            "Tokenized Sequence: [22, 2455, 878, 2493, 6, 1]\n",
            "\n",
            "\n",
            "Original Comment: mama ahon ganja khau\n",
            "Tokenized Sequence: [625, 1603, 710, 2443]\n",
            "\n",
            "\n",
            "Original Comment: khaya daya kam nai\n",
            "Tokenized Sequence: [1218, 1881, 274, 5]\n",
            "\n",
            "\n",
            "Original Comment: sara din ....ase\n",
            "Tokenized Sequence: [298, 35, 45]\n",
            "\n",
            "\n",
            "Original Comment: answer koi pabo vaiya\n",
            "Tokenized Sequence: [2473, 93, 1213, 544]\n",
            "\n",
            "\n",
            "Original Comment: sound quality baze\n",
            "Tokenized Sequence: [878, 2493, 3332]\n",
            "\n",
            "\n",
            "Original Comment: fokinnir pola tor pakha gojaise taina?\n",
            "Tokenized Sequence: [1705, 116, 17, 9950, 9951, 2979]\n",
            "\n",
            "\n",
            "Original Comment: chudir vai tui abar aschis mcd\n",
            "Tokenized Sequence: [666, 3, 23, 86, 9952, 9953]\n",
            "\n",
            "\n",
            "Original Comment: khub sundor kotha\n",
            "Tokenized Sequence: [51, 66, 10]\n",
            "\n",
            "\n",
            "Original Comment: tumi akta cudir bhai\n",
            "Tokenized Sequence: [13, 37, 2492, 53]\n",
            "\n",
            "\n",
            "Original Comment: taklai ajkey mod kaynai\n",
            "Tokenized Sequence: [9954, 9955, 593, 9956]\n",
            "\n",
            "\n",
            "Original Comment: haramzada akta\n",
            "Tokenized Sequence: [9957, 37]\n",
            "\n",
            "\n",
            "Original Comment: pam mara suru korse...boy paise huhu\n",
            "Tokenized Sequence: [9958, 195, 272, 202, 956, 1327, 9959]\n",
            "\n",
            "\n",
            "Original Comment: takla murad\n",
            "Tokenized Sequence: [958, 2349]\n",
            "\n",
            "\n",
            "Original Comment: eita kno kothasob pagol hoye gese\n",
            "Tokenized Sequence: [289, 64, 9960, 108, 20, 87]\n",
            "\n",
            "\n",
            "Original Comment: takla\n",
            "Tokenized Sequence: [958]\n",
            "\n",
            "\n",
            "Original Comment: kottar bassa\n",
            "Tokenized Sequence: [1643, 1167]\n",
            "\n",
            "\n",
            "Original Comment: percent ba kheah aisen na ge khaben??\n",
            "Tokenized Sequence: [9961, 240, 9962, 9963, 1, 9964, 9965]\n",
            "\n",
            "\n",
            "Original Comment: taklar bassa\n",
            "Tokenized Sequence: [2052, 1167]\n",
            "\n",
            "\n",
            "Original Comment: madarbord\n",
            "Tokenized Sequence: [9966]\n",
            "\n",
            "\n",
            "Original Comment: taklar mukhe gondho\n",
            "Tokenized Sequence: [2052, 259, 3949]\n",
            "\n",
            "\n",
            "Original Comment: ay deshe ain ase naki????\n",
            "Tokenized Sequence: [229, 875, 3030, 45, 29]\n",
            "\n",
            "\n",
            "Original Comment: tore niog dice janoar\n",
            "Tokenized Sequence: [216, 9967, 922, 3147]\n",
            "\n",
            "\n",
            "Original Comment: oy akta feraon\n",
            "Tokenized Sequence: [743, 37, 9968]\n",
            "\n",
            "\n",
            "Original Comment: dem mal khaiche\n",
            "Tokenized Sequence: [9969, 247, 9970]\n",
            "\n",
            "\n",
            "Original Comment: tui akta pagol daktar\n",
            "Tokenized Sequence: [23, 37, 108, 9971]\n",
            "\n",
            "\n",
            "Original Comment: tomi ato bal paknami koro na na sala dallal\n",
            "Tokenized Sequence: [569, 43, 48, 2262, 78, 1, 1, 159, 9972]\n",
            "\n",
            "\n",
            "Original Comment: faraoner bacca pagol\n",
            "Tokenized Sequence: [9973, 562, 108]\n",
            "\n",
            "\n",
            "Original Comment: ish innocent ...takku mathy kau ganjar tell maikhaa deu\n",
            "Tokenized Sequence: [9974, 9975, 9976, 9977, 1386, 9978, 9979, 9980, 9981]\n",
            "\n",
            "\n",
            "Original Comment: madar codd toi\n",
            "Tokenized Sequence: [1152, 9982, 388]\n",
            "\n",
            "\n",
            "Original Comment: toi kutta murad\n",
            "Tokenized Sequence: [388, 606, 2349]\n",
            "\n",
            "\n",
            "Original Comment: tore laga...\n",
            "Tokenized Sequence: [216, 427]\n",
            "\n",
            "\n",
            "Original Comment: world class abal....\n",
            "Tokenized Sequence: [391, 1083, 235]\n",
            "\n",
            "\n",
            "Original Comment: ater hota foniber shomoi nai,amader!\n",
            "Tokenized Sequence: [9983, 1724, 9984, 9985, 5, 132]\n",
            "\n",
            "\n",
            "Original Comment: madarsod tor cansar hoba ok\n",
            "Tokenized Sequence: [9986, 17, 9987, 258, 858]\n",
            "\n",
            "\n",
            "Original Comment: ore batpar\n",
            "Tokenized Sequence: [91, 1237]\n",
            "\n",
            "\n",
            "Original Comment: vai bhut mhuka ram nam.kotha gula sunta aktu otbhut laglo\n",
            "Tokenized Sequence: [3, 3778, 9988, 1721, 144, 10, 55, 3807, 178, 9989, 524]\n",
            "\n",
            "\n",
            "Original Comment: sob bujlm bt hijla der moto kore aida?\n",
            "Tokenized Sequence: [8, 2590, 481, 1404, 44, 16, 2, 899]\n",
            "\n",
            "\n",
            "Original Comment: digital. chor\n",
            "Tokenized Sequence: [9990, 1472]\n",
            "\n",
            "\n",
            "Original Comment: batpar batpar. vote. chor batpar moussy. c ccc. xxxx. l. l. l\n",
            "Tokenized Sequence: [1237, 1237, 1792, 1472, 1237, 9991, 317, 2289, 9992, 897, 897, 897]\n",
            "\n",
            "\n",
            "Original Comment: mohammad onek nari bhog korse tai muslim emon\n",
            "Tokenized Sequence: [9993, 56, 1239, 9994, 202, 40, 82, 156]\n",
            "\n",
            "\n",
            "Original Comment: hindu ba kaferder sathe hat miliye shara duniya shesh hoye jachhe\n",
            "Tokenized Sequence: [89, 240, 9995, 77, 379, 9996, 1486, 1805, 701, 20, 9997]\n",
            "\n",
            "\n",
            "Original Comment: fokinnir beer\n",
            "Tokenized Sequence: [1705, 9998]\n",
            "\n",
            "\n",
            "Original Comment: ato hot kemne\n",
            "Tokenized Sequence: [43, 319, 602]\n",
            "\n",
            "\n",
            "Original Comment: owo nijer nije dekso keno ? amra jeno dekte pai sei jonno close pic dao\n",
            "Tokenized Sequence: [3872, 147, 203, 9999, 111, 85, 452, 479, 463, 115, 28, 1984, 63, 581]\n",
            "\n",
            "\n",
            "Original Comment: inbx nude pathao babe\n",
            "Tokenized Sequence: [10000, 2276, 3373, 1174]\n",
            "\n",
            "\n",
            "Original Comment: oto hoye gese tai nh\n",
            "Tokenized Sequence: [948, 20, 87, 40, 135]\n",
            "\n",
            "\n",
            "Original Comment: chikna sorir eto boro jinis kemne hoilo?\n",
            "Tokenized Sequence: [10001, 670, 60, 18, 467, 602, 249]\n",
            "\n",
            "\n",
            "Original Comment: doro tor. mare codi\n",
            "Tokenized Sequence: [2484, 17, 375, 10002]\n",
            "\n",
            "\n",
            "Original Comment: dudu choto hoye gese tai nh\n",
            "Tokenized Sequence: [260, 129, 20, 87, 40, 135]\n",
            "\n",
            "\n",
            "Original Comment: hishu korla naki\n",
            "Tokenized Sequence: [10003, 766, 29]\n",
            "\n",
            "\n",
            "Original Comment: superb purai mal\n",
            "Tokenized Sequence: [10004, 291, 247]\n",
            "\n",
            "\n",
            "Original Comment: koto sundor gol gol\n",
            "Tokenized Sequence: [33, 66, 1849, 1849]\n",
            "\n",
            "\n",
            "Original Comment: boobs valoi boro hoise...\n",
            "Tokenized Sequence: [1166, 486, 18, 188]\n",
            "\n",
            "\n",
            "Original Comment: cox's bazer theke acher por daktci mota hoiya jaitacn, gotona\n",
            "Tokenized Sequence: [10005, 10006, 21, 10007, 72, 10008, 214, 232, 10009, 10010]\n",
            "\n",
            "\n",
            "Original Comment: ja ja korso bad daw maf kore dibo amar sathe biya kore felo\n",
            "Tokenized Sequence: [70, 70, 1173, 174, 376, 2954, 2, 189, 9, 77, 366, 2, 3780]\n",
            "\n",
            "\n",
            "Original Comment: tumr i'd koyta\n",
            "Tokenized Sequence: [1196, 2421, 1060]\n",
            "\n",
            "\n",
            "Original Comment: bar bar tomr oi makonar moto dud 2 ty crush kai\n",
            "Tokenized Sequence: [134, 134, 1085, 57, 10011, 16, 208, 166, 1778, 316, 1753]\n",
            "\n",
            "\n",
            "Original Comment: tor moton khankir nam pashe islam na manai na\n",
            "Tokenized Sequence: [17, 490, 318, 144, 699, 309, 1, 1145, 1]\n",
            "\n",
            "\n",
            "Original Comment: muslim nam kolngo tui\n",
            "Tokenized Sequence: [82, 144, 10012, 23]\n",
            "\n",
            "\n",
            "Original Comment: gulo choto hoye gese, boro size kine ano jao\n",
            "Tokenized Sequence: [107, 129, 20, 87, 18, 276, 1099, 2546, 353]\n",
            "\n",
            "\n",
            "Original Comment: din din sexiness bartache massages dicche\n",
            "Tokenized Sequence: [35, 35, 10013, 10014, 10015, 2414]\n",
            "\n",
            "\n",
            "Original Comment: tomar porn ber hoice dekhlam\n",
            "Tokenized Sequence: [26, 1869, 139, 356, 278]\n",
            "\n",
            "\n",
            "Original Comment: uffffff boobs baba, purai matha nosto\n",
            "Tokenized Sequence: [1471, 1166, 401, 291, 420, 215]\n",
            "\n",
            "\n",
            "Original Comment: hot suna lagaba\n",
            "Tokenized Sequence: [319, 2429, 3823]\n",
            "\n",
            "\n",
            "Original Comment: manus tmader theke dud ber kora sikhbe\n",
            "Tokenized Sequence: [140, 3579, 21, 208, 139, 39, 10016]\n",
            "\n",
            "\n",
            "Original Comment: boro hoisa vab\n",
            "Tokenized Sequence: [18, 3950, 525]\n",
            "\n",
            "\n",
            "Original Comment: bra sara ekta cobi post koro.\n",
            "Tokenized Sequence: [221, 298, 36, 2358, 110, 78]\n",
            "\n",
            "\n",
            "Original Comment: tmr dud onk boro tmr dud khamu\n",
            "Tokenized Sequence: [32, 208, 58, 18, 32, 208, 10017]\n",
            "\n",
            "\n",
            "Original Comment: tmder baba ma ghumay?\n",
            "Tokenized Sequence: [3580, 401, 187, 3558]\n",
            "\n",
            "\n",
            "Original Comment: per night koto taka nes magi ?\n",
            "Tokenized Sequence: [10018, 1187, 33, 172, 10019, 96]\n",
            "\n",
            "\n",
            "Original Comment: paikhana ber korbo pasa chaita\n",
            "Tokenized Sequence: [10020, 139, 186, 472, 10021]\n",
            "\n",
            "\n",
            "Original Comment: hagu khabo\n",
            "Tokenized Sequence: [3452, 412]\n",
            "\n",
            "\n",
            "Original Comment: hot hoite jaiya toh leghta hoiya jaitahso khanki magi tor thk eh toh tor dudh boro\n",
            "Tokenized Sequence: [319, 428, 10022, 88, 10023, 232, 10024, 285, 96, 17, 3714, 3921, 88, 17, 119, 18]\n",
            "\n",
            "\n",
            "Original Comment: dudu josss hoby khity\n",
            "Tokenized Sequence: [260, 2485, 10025, 3951]\n",
            "\n",
            "\n",
            "Original Comment: baaal shob video te koi theke ase.\n",
            "Tokenized Sequence: [2909, 127, 24, 25, 93, 21, 45]\n",
            "\n",
            "\n",
            "Original Comment: dekhte lage maiyya go moto\n",
            "Tokenized Sequence: [112, 47, 1918, 137, 16]\n",
            "\n",
            "\n",
            "Original Comment: faltu pola\n",
            "Tokenized Sequence: [416, 116]\n",
            "\n",
            "\n",
            "Original Comment: ey hijra tmr choda khay?\n",
            "Tokenized Sequence: [815, 284, 32, 415, 574]\n",
            "\n",
            "\n",
            "Original Comment: josss hobe khity\n",
            "Tokenized Sequence: [2485, 11, 3951]\n",
            "\n",
            "\n",
            "Original Comment: mane prothom deikha moja paisilam oi hizrar bachcha deikha pura mood kharab hoya gese\n",
            "Tokenized Sequence: [155, 1030, 482, 224, 3578, 57, 10026, 1195, 482, 384, 10027, 10028, 286, 87]\n",
            "\n",
            "\n",
            "Original Comment: thakti bostite prostitute hoia akhon boroloki maras magi\n",
            "Tokenized Sequence: [10029, 10030, 2786, 295, 268, 10031, 10032, 96]\n",
            "\n",
            "\n",
            "Original Comment: sather hizla\n",
            "Tokenized Sequence: [3196, 3944]\n",
            "\n",
            "\n",
            "Original Comment: tmr friend niya thailand jao, ore boobs implant korao, she deserve it\n",
            "Tokenized Sequence: [32, 761, 211, 10033, 353, 91, 1166, 10034, 10035, 795, 3648, 2410]\n",
            "\n",
            "\n",
            "Original Comment: jore jore thap maro\n",
            "Tokenized Sequence: [1443, 1443, 3952, 856]\n",
            "\n",
            "\n",
            "Original Comment: hijra sala\n",
            "Tokenized Sequence: [284, 159]\n",
            "\n",
            "\n",
            "Original Comment: chusa dimu dudh\n",
            "Tokenized Sequence: [10036, 630, 119]\n",
            "\n",
            "\n",
            "Original Comment: hijratar shathe eto ki!\n",
            "Tokenized Sequence: [2465, 1401, 60, 175]\n",
            "\n",
            "\n",
            "Original Comment: hijra sathe thake bal\n",
            "Tokenized Sequence: [284, 77, 114, 48]\n",
            "\n",
            "\n",
            "Original Comment: khuila de...magi\n",
            "Tokenized Sequence: [1203, 266, 96]\n",
            "\n",
            "\n",
            "Original Comment: bessha magir dol\n",
            "Tokenized Sequence: [1245, 363, 511]\n",
            "\n",
            "\n",
            "Original Comment: lagiso naki\n",
            "Tokenized Sequence: [10037, 29]\n",
            "\n",
            "\n",
            "Original Comment: 2 kamuki magi\n",
            "Tokenized Sequence: [166, 3007, 96]\n",
            "\n",
            "\n",
            "Original Comment: kirmi utse pasay...pata voda\n",
            "Tokenized Sequence: [10038, 3253, 1209, 1863, 1376]\n",
            "\n",
            "\n",
            "Original Comment: pisoner apu beshi horny\n",
            "Tokenized Sequence: [1740, 19, 120, 2354]\n",
            "\n",
            "\n",
            "Original Comment: lassanai baba\n",
            "Tokenized Sequence: [10039, 401]\n",
            "\n",
            "\n",
            "Original Comment: lesbo club maiyya\n",
            "Tokenized Sequence: [10040, 10041, 1918]\n",
            "\n",
            "\n",
            "Original Comment: canada chole jaw, bd te tmk manay na\n",
            "Tokenized Sequence: [10042, 385, 597, 344, 25, 273, 678, 1]\n",
            "\n",
            "\n",
            "Original Comment: tumii randi di di di\n",
            "Tokenized Sequence: [10043, 1661, 475, 475, 475]\n",
            "\n",
            "\n",
            "Original Comment: pechoner take guha mere moja beshi pwa jbe\n",
            "Tokenized Sequence: [10044, 223, 10045, 939, 224, 120, 10046, 1765]\n",
            "\n",
            "\n",
            "Original Comment: lesbian 2ta khanki\n",
            "Tokenized Sequence: [2708, 2166, 285]\n",
            "\n",
            "\n",
            "Original Comment: randi rate koto\n",
            "Tokenized Sequence: [1661, 374, 33]\n",
            "\n",
            "\n",
            "Original Comment: bottle jaiga moto dukasso ato ovab\n",
            "Tokenized Sequence: [10047, 556, 16, 10048, 43, 485]\n",
            "\n",
            "\n",
            "Original Comment: akhne amr crush tao ase dekhi? black\n",
            "Tokenized Sequence: [10049, 7, 316, 302, 45, 157, 1508]\n",
            "\n",
            "\n",
            "Original Comment: tmr hogay onek gondho\n",
            "Tokenized Sequence: [32, 2239, 56, 3949]\n",
            "\n",
            "\n",
            "Original Comment: koto kharap tora\n",
            "Tokenized Sequence: [33, 79, 152]\n",
            "\n",
            "\n",
            "Original Comment: shawwa fatiye daw butol dukhiye\n",
            "Tokenized Sequence: [3746, 10050, 376, 3164, 10051]\n",
            "\n",
            "\n",
            "Original Comment: narikel gache daab\n",
            "Tokenized Sequence: [10052, 1273, 2384]\n",
            "\n",
            "\n",
            "Original Comment: trpr hogamara tao onek sweet and unexpected hoi\n",
            "Tokenized Sequence: [1188, 2826, 302, 56, 1413, 200, 10053, 38]\n",
            "\n",
            "\n",
            "Original Comment: hate dilam kola ingine dilam thela\n",
            "Tokenized Sequence: [1406, 596, 1498, 10054, 596, 3545]\n",
            "\n",
            "\n",
            "Original Comment: babe..kotobar bolbo eisob choto kapor poira pic diba na\n",
            "Tokenized Sequence: [1174, 10055, 473, 586, 129, 201, 548, 63, 480, 1]\n",
            "\n",
            "\n",
            "Original Comment: tumi amar moto hoba\n",
            "Tokenized Sequence: [13, 9, 16, 258]\n",
            "\n",
            "\n",
            "Original Comment: profile deky duky akn dekhi sodor ghat\n",
            "Tokenized Sequence: [2156, 10056, 10057, 685, 157, 3939, 3940]\n",
            "\n",
            "\n",
            "Original Comment: vlo hoye pic post koren\n",
            "Tokenized Sequence: [75, 20, 63, 110, 83]\n",
            "\n",
            "\n",
            "Original Comment: mamla tumi khaba dorjo doro\n",
            "Tokenized Sequence: [3125, 13, 10058, 10059, 2484]\n",
            "\n",
            "\n",
            "Original Comment: babuder jonno 13ai february jonno ogrim gift kayo mara mari.korben na line thakle sobai pabe,, hutash howa jabe na amader desher jenish\n",
            "Tokenized Sequence: [10060, 28, 10061, 10062, 28, 10063, 775, 10064, 195, 940, 306, 1, 730, 143, 104, 892, 10065, 1672, 126, 1, 132, 632, 10066]\n",
            "\n",
            "\n",
            "Original Comment: ato boro boro hoisa kan??.\n",
            "Tokenized Sequence: [43, 18, 18, 3950, 860]\n",
            "\n",
            "\n",
            "Original Comment: olan gulo eto boro kno\n",
            "Tokenized Sequence: [10067, 107, 60, 18, 64]\n",
            "\n",
            "\n",
            "Original Comment: nogno hole arekto valo lagto\n",
            "Tokenized Sequence: [2696, 121, 10068, 6, 711]\n",
            "\n",
            "\n",
            "Original Comment: amr i'd tei esb ase\n",
            "Tokenized Sequence: [7, 2421, 763, 3349, 45]\n",
            "\n",
            "\n",
            "Original Comment: ata dekhar jonno jati postot silo na\n",
            "Tokenized Sequence: [102, 250, 28, 1718, 10069, 518, 1]\n",
            "\n",
            "\n",
            "Original Comment: ato boro dodo\n",
            "Tokenized Sequence: [43, 18, 1571]\n",
            "\n",
            "\n",
            "Original Comment: ek rate theke dhekte hobe besi hot\n",
            "Tokenized Sequence: [125, 374, 21, 10070, 11, 176, 319]\n",
            "\n",
            "\n",
            "Original Comment: dud gula oneak cute\n",
            "Tokenized Sequence: [208, 55, 3776, 348]\n",
            "\n",
            "\n",
            "Original Comment: apni je bab doren mone hoi nekat koren\n",
            "Tokenized Sequence: [15, 46, 2428, 1841, 34, 38, 10071, 83]\n",
            "\n",
            "\n",
            "Original Comment: anek din por apnake dekhte pelam\n",
            "Tokenized Sequence: [1453, 35, 72, 192, 112, 760]\n",
            "\n",
            "\n",
            "Original Comment: ahago amr crush.. jibonda ses koira dc tumare mone koira koira\n",
            "Tokenized Sequence: [10072, 7, 316, 10073, 225, 99, 10074, 1797, 34, 99, 99]\n",
            "\n",
            "\n",
            "Original Comment: tore dekle vala takon jai\n",
            "Tokenized Sequence: [216, 642, 541, 10075, 90]\n",
            "\n",
            "\n",
            "Original Comment: hayree becara mair khaite khaite goja hoiya gece jara maree tather akto maya hoy nai amn cute meye din rate 5 bar mair dele hoy ora mone hoy sara din mare\n",
            "Tokenized Sequence: [10076, 2628, 803, 495, 495, 10077, 232, 448, 217, 10078, 10079, 777, 705, 14, 5, 213, 348, 50, 35, 374, 443, 134, 803, 2097, 14, 158, 34, 14, 298, 35, 375]\n",
            "\n",
            "\n",
            "Original Comment: size jeno lagteche\n",
            "Tokenized Sequence: [276, 452, 3924]\n",
            "\n",
            "\n",
            "Original Comment: amon beporday dhekbo bhabini\n",
            "Tokenized Sequence: [133, 10080, 10081, 10082]\n",
            "\n",
            "\n",
            "Original Comment: obostha dekho,,nam diche jannatul,,othocho cholafera koto sundor,,jahannamer agun\n",
            "Tokenized Sequence: [383, 772, 144, 2938, 3618, 3931, 10083, 33, 66, 10084, 1182]\n",
            "\n",
            "\n",
            "Original Comment: chosma khulen to, oi cok duto dekhi\n",
            "Tokenized Sequence: [10085, 10086, 506, 57, 10087, 1791, 157]\n",
            "\n",
            "\n",
            "Original Comment: onk doira maybe khay nah.tai sorir amn\n",
            "Tokenized Sequence: [58, 10088, 2072, 574, 52, 40, 670, 213]\n",
            "\n",
            "\n",
            "Original Comment: duru bedi..pagli pagli lagse\n",
            "Tokenized Sequence: [10089, 783, 2203, 2203, 435]\n",
            "\n",
            "\n",
            "Original Comment: jai koro na tmk amr vloy lagea... comment reply gula sei dao\n",
            "Tokenized Sequence: [90, 78, 1, 273, 7, 10090, 10091, 197, 598, 55, 115, 581]\n",
            "\n",
            "\n",
            "Original Comment: tomak respect dawa possible na dishmish\n",
            "Tokenized Sequence: [1437, 784, 590, 1430, 1, 10092]\n",
            "\n",
            "\n",
            "Original Comment: namaz poro apu..aisob kaje asbe na kobore...valo hoia jan apu..allah bhoi koren..\n",
            "Tokenized Sequence: [977, 1561, 19, 357, 1129, 970, 1, 3953, 6, 295, 378, 19, 59, 10093, 83]\n",
            "\n",
            "\n",
            "Original Comment: oita tmr pison diya dukiya nara diye tmr mhuk bore debo....kmn...\n",
            "Tokenized Sequence: [311, 32, 3457, 76, 10094, 2243, 49, 32, 10095, 10096, 500, 497]\n",
            "\n",
            "\n",
            "Original Comment: bal fakna maia\n",
            "Tokenized Sequence: [48, 10097, 1205]\n",
            "\n",
            "\n",
            "Original Comment: golumolu vlo cilenn akn baje lagce!!\n",
            "Tokenized Sequence: [10098, 75, 10099, 685, 182, 773]\n",
            "\n",
            "\n",
            "Original Comment: thobra dekte mon chay na\n",
            "Tokenized Sequence: [10100, 479, 84, 300, 1]\n",
            "\n",
            "\n",
            "Original Comment: deke amr nice jhara dilo kno\n",
            "Tokenized Sequence: [418, 7, 529, 10101, 321, 64]\n",
            "\n",
            "\n",
            "Original Comment: ankush chap diye roga korasse\n",
            "Tokenized Sequence: [3954, 2460, 49, 1768, 10102]\n",
            "\n",
            "\n",
            "Original Comment: boin toi bojos na toi moto thakley cute lage,, ekn tore sotki macher moto lagtase...\n",
            "Tokenized Sequence: [335, 388, 10103, 1, 388, 16, 3510, 348, 47, 691, 216, 10104, 10105, 16, 1095]\n",
            "\n",
            "\n",
            "Original Comment: koto kalo bonduk khabe.... akn biye kore naw\n",
            "Tokenized Sequence: [33, 212, 10106, 930, 685, 267, 2, 2175]\n",
            "\n",
            "\n",
            "Original Comment: dehay bejae duidare,karon ace jhule\n",
            "Tokenized Sequence: [10107, 10108, 2561, 329, 207, 1176]\n",
            "\n",
            "\n",
            "Original Comment: 3din hago nah hola kostokatinno roger muk amon karp hoina\n",
            "Tokenized Sequence: [10109, 10110, 52, 1389, 10111, 10112, 3503, 133, 10113, 3495]\n",
            "\n",
            "\n",
            "Original Comment: apnar attitude apnar face sathamanai na\n",
            "Tokenized Sequence: [22, 1751, 22, 456, 10114, 1]\n",
            "\n",
            "\n",
            "Original Comment: pola tore biya korbona boin.. kheye dibe bujhbi na\n",
            "Tokenized Sequence: [116, 216, 366, 10115, 335, 165, 305, 10116, 1]\n",
            "\n",
            "\n",
            "Original Comment: assa apnara biyea koren nha\n",
            "Tokenized Sequence: [997, 280, 10117, 83, 10118]\n",
            "\n",
            "\n",
            "Original Comment: oindrila apur theke onkus boro mone hosce\n",
            "Tokenized Sequence: [10119, 1436, 21, 10120, 18, 34, 10121]\n",
            "\n",
            "\n",
            "Original Comment: faltu lagce cekon hoya\n",
            "Tokenized Sequence: [416, 773, 10122, 286]\n",
            "\n",
            "\n",
            "Original Comment: moteo valo lagchena agei valo lagto quite lag to.\n",
            "Tokenized Sequence: [10123, 6, 10124, 877, 6, 711, 3298, 3658, 506]\n",
            "\n",
            "\n",
            "Original Comment: valo kichu porte paren na. berie take soob dekha jai\n",
            "Tokenized Sequence: [6, 80, 627, 648, 1, 2646, 223, 457, 122, 90]\n",
            "\n",
            "\n",
            "Original Comment: naujubillah ci ata doronr dress\n",
            "Tokenized Sequence: [1573, 876, 102, 10125, 164]\n",
            "\n",
            "\n",
            "Original Comment: tumke agula manai na tumake saritei bes lage apu\n",
            "Tokenized Sequence: [2451, 478, 1145, 1, 1193, 3565, 1745, 47, 19]\n",
            "\n",
            "\n",
            "Original Comment: sob poren apny manay na\n",
            "Tokenized Sequence: [8, 1190, 3381, 678, 1]\n",
            "\n",
            "\n",
            "Original Comment: diet koiren na, sutki hoia gesen\n",
            "Tokenized Sequence: [10126, 1423, 1, 2320, 295, 1989]\n",
            "\n",
            "\n",
            "Original Comment: side dia deikha feksi tmr bobs\n",
            "Tokenized Sequence: [1788, 252, 482, 10127, 32, 10128]\n",
            "\n",
            "\n",
            "Original Comment: mutki hoico kno emn!\n",
            "Tokenized Sequence: [1786, 2372, 64, 246]\n",
            "\n",
            "\n",
            "Original Comment: biye korba kobe! evabe raat katao je, horme soibe na\n",
            "Tokenized Sequence: [267, 565, 423, 1904, 1026, 10129, 46, 10130, 10131, 1]\n",
            "\n",
            "\n",
            "Original Comment: apnaka lagata essa kora\n",
            "Tokenized Sequence: [2436, 10132, 10133, 39]\n",
            "\n",
            "\n",
            "Original Comment: ramcudu kheyece\n",
            "Tokenized Sequence: [10134, 10135]\n",
            "\n",
            "\n",
            "Original Comment: 6 9 khabo amra ros\n",
            "Tokenized Sequence: [1159, 3040, 412, 85, 2456]\n",
            "\n",
            "\n",
            "Original Comment: eto cikon tmi na..mota alur bosta tmi.manush boka banao\n",
            "Tokenized Sequence: [60, 1793, 69, 1, 214, 2252, 2386, 69, 67, 986, 10136]\n",
            "\n",
            "\n",
            "Original Comment: mutki ekta, edi koira abr cikon hoise\n",
            "Tokenized Sequence: [1786, 36, 2921, 99, 169, 1793, 188]\n",
            "\n",
            "\n",
            "Original Comment: cikna hoi kmne era ay mota ay cikna,ajob bara\n",
            "Tokenized Sequence: [3955, 38, 296, 331, 229, 214, 229, 3955, 662, 173]\n",
            "\n",
            "\n",
            "Original Comment: jama na prleo hoto, sudu sudu kosto\n",
            "Tokenized Sequence: [179, 1, 10137, 257, 336, 336, 293]\n",
            "\n",
            "\n",
            "Original Comment: dasi vikarir moto laga\n",
            "Tokenized Sequence: [10138, 10139, 16, 427]\n",
            "\n",
            "\n",
            "Original Comment: tomar sathe amar beeyer kotha chhilo. amay ceere 3inch ee kno gale\n",
            "Tokenized Sequence: [26, 77, 9, 10140, 10, 10141, 1601, 10142, 10143, 584, 64, 1796]\n",
            "\n",
            "\n",
            "Original Comment: ato oo sondor na tumi\n",
            "Tokenized Sequence: [43, 693, 993, 1, 13]\n",
            "\n",
            "\n",
            "Original Comment: uff sei sexxy ..khelba\n",
            "Tokenized Sequence: [424, 115, 3873, 2068]\n",
            "\n",
            "\n",
            "Original Comment: abal. moydar dibba.\n",
            "Tokenized Sequence: [235, 10144, 10145]\n",
            "\n",
            "\n",
            "Original Comment: tomar nichtalay kamor debo\n",
            "Tokenized Sequence: [26, 10146, 1208, 500]\n",
            "\n",
            "\n",
            "Original Comment: kisuta kaker sathe face mill ase\n",
            "Tokenized Sequence: [10147, 10148, 77, 456, 10149, 45]\n",
            "\n",
            "\n",
            "Original Comment: bangalider kalai hoy kintu. eta edit kora\n",
            "Tokenized Sequence: [10150, 10151, 14, 68, 95, 722, 39]\n",
            "\n",
            "\n",
            "Original Comment: zim koro aro sexy hobe. tumi emon utcho bosecho mone hochey ankush chudchey.\n",
            "Tokenized Sequence: [10152, 78, 131, 925, 11, 13, 156, 10153, 10154, 34, 10155, 3954, 10156]\n",
            "\n",
            "\n",
            "Original Comment: aste aste, nich fete gelo\n",
            "Tokenized Sequence: [889, 889, 2486, 1769, 105]\n",
            "\n",
            "\n",
            "Original Comment: cagai te cagaite shesh\n",
            "Tokenized Sequence: [10157, 25, 10158, 701]\n",
            "\n",
            "\n",
            "Original Comment: gim koro na, deho dekhao. he he\n",
            "Tokenized Sequence: [3515, 78, 1, 1011, 886, 532, 532]\n",
            "\n",
            "\n",
            "Original Comment: kauay hoibo kokil!\n",
            "Tokenized Sequence: [10159, 454, 10160]\n",
            "\n",
            "\n",
            "Original Comment: gym koren, valo.kintu ogula sukale kotha bolbo na\n",
            "Tokenized Sequence: [1183, 83, 6, 68, 10161, 10162, 10, 473, 1]\n",
            "\n",
            "\n",
            "Original Comment: baje. faltu mei jemon dekte bajr nonra\n",
            "Tokenized Sequence: [182, 416, 10163, 914, 479, 10164, 3956]\n",
            "\n",
            "\n",
            "Original Comment: sat pake badhay beshi sundor lagto akhn tmn cute lage na\n",
            "Tokenized Sequence: [10165, 10166, 10167, 120, 66, 711, 151, 10168, 348, 47, 1]\n",
            "\n",
            "\n",
            "Original Comment: eraa ato taratari soto, boro, mota, chikon kore kivabe\n",
            "Tokenized Sequence: [10169, 43, 659, 1315, 18, 214, 1811, 2, 392]\n",
            "\n",
            "\n",
            "Original Comment: tumi age jemon sila temni sundor\n",
            "Tokenized Sequence: [13, 71, 914, 10170, 10171, 66]\n",
            "\n",
            "\n",
            "Original Comment: tumar moto akta rosalo bou thakla kicu lagto na????\n",
            "Tokenized Sequence: [281, 16, 37, 10172, 199, 2250, 270, 711, 1]\n",
            "\n",
            "\n",
            "Original Comment: haibid pacha holo kmne apner\n",
            "Tokenized Sequence: [10173, 1162, 170, 296, 290]\n",
            "\n",
            "\n",
            "Original Comment: bhalo lagcha na didi\n",
            "Tokenized Sequence: [198, 1178, 1, 647]\n",
            "\n",
            "\n",
            "Original Comment: mota thke ekhn sukno chamsi\n",
            "Tokenized Sequence: [214, 10174, 716, 10175, 10176]\n",
            "\n",
            "\n",
            "Original Comment: na mane pant poren kn, nillojjo\n",
            "Tokenized Sequence: [1, 155, 314, 1190, 239, 10177]\n",
            "\n",
            "\n",
            "Original Comment: amio erm selfie tulm trainer bar kore diyeche, aj meye hole dito na\n",
            "Tokenized Sequence: [238, 10178, 2594, 10179, 10180, 134, 2, 3716, 123, 50, 121, 954, 1]\n",
            "\n",
            "\n",
            "Original Comment: ektu mota chilo tokhoni beshi valo lagto\n",
            "Tokenized Sequence: [154, 214, 94, 3735, 120, 6, 711]\n",
            "\n",
            "\n",
            "Original Comment: didi dad parce kapata, he he\n",
            "Tokenized Sequence: [647, 3723, 10181, 10182, 532, 532]\n",
            "\n",
            "\n",
            "Original Comment: ekdom valo lagena agei onek cute lagto\n",
            "Tokenized Sequence: [530, 6, 1348, 877, 56, 348, 711]\n",
            "\n",
            "\n",
            "Original Comment: chi,kothay chulkaya dilo. bodmais\n",
            "Tokenized Sequence: [350, 528, 10183, 321, 10184]\n",
            "\n",
            "\n",
            "Original Comment: jotoi koro, tumi valo hoba na\n",
            "Tokenized Sequence: [974, 78, 13, 6, 258, 1]\n",
            "\n",
            "\n",
            "Original Comment: tmi ato jim kro tau roga how na kn??\n",
            "Tokenized Sequence: [69, 43, 2371, 1231, 3151, 1768, 3548, 1, 239]\n",
            "\n",
            "\n",
            "Original Comment: nongramao koro!\n",
            "Tokenized Sequence: [10185, 78]\n",
            "\n",
            "\n",
            "Original Comment: gym ee giye deho dekho, exercise koroi na\n",
            "Tokenized Sequence: [1183, 584, 462, 1011, 772, 10186, 10187, 1]\n",
            "\n",
            "\n",
            "Original Comment: oi meye jama nai, naki jamai chire fele rat\n",
            "Tokenized Sequence: [57, 50, 179, 5, 29, 466, 973, 832, 719]\n",
            "\n",
            "\n",
            "Original Comment: akta jama diye sudhu pic tolo,fokir\n",
            "Tokenized Sequence: [37, 179, 49, 255, 63, 10188, 3957]\n",
            "\n",
            "\n",
            "Original Comment: boro vuri hoisego\n",
            "Tokenized Sequence: [18, 1260, 10189]\n",
            "\n",
            "\n",
            "Original Comment: apu somoy takte fordha korun plz...ei rkm pic post kora valo nah...valo hoye jaw plzzz...\n",
            "Tokenized Sequence: [19, 210, 10190, 10191, 451, 234, 1520, 10192, 63, 110, 39, 6, 52, 6, 20, 597, 2369]\n",
            "\n",
            "\n",
            "Original Comment: keno je tumay eto valo lagee,ar bicana vijay dei\n",
            "Tokenized Sequence: [111, 46, 3388, 60, 6, 10193, 445, 10194, 10195, 330]\n",
            "\n",
            "\n",
            "Original Comment: magi borak bass dwaa dorkar\n",
            "Tokenized Sequence: [96, 10196, 3685, 10197, 100]\n",
            "\n",
            "\n",
            "Original Comment: ups hat khepe gelo amr, obostha\n",
            "Tokenized Sequence: [10198, 379, 10199, 105, 7, 383]\n",
            "\n",
            "\n",
            "Original Comment: khaia khaia muti hoise\n",
            "Tokenized Sequence: [717, 717, 10200, 188]\n",
            "\n",
            "\n",
            "Original Comment: dekte valo na, kintu vab mare koti takar\n",
            "Tokenized Sequence: [479, 6, 1, 68, 525, 375, 10201, 945]\n",
            "\n",
            "\n",
            "Original Comment: bikini tei valo manay ekhon ager te\n",
            "Tokenized Sequence: [1432, 763, 6, 678, 185, 561, 25]\n",
            "\n",
            "\n",
            "Original Comment: bacca dila figar ses, tumi expired\n",
            "Tokenized Sequence: [562, 519, 3526, 225, 13, 3639]\n",
            "\n",
            "\n",
            "Original Comment: biyar por te nyka nyka lage na\n",
            "Tokenized Sequence: [1110, 72, 25, 3958, 3958, 47, 1]\n",
            "\n",
            "\n",
            "Original Comment: buri boyseo saxi\n",
            "Tokenized Sequence: [419, 10202, 10203]\n",
            "\n",
            "\n",
            "Original Comment: tor ja koto rup, makeup koira khali dhkos\n",
            "Tokenized Sequence: [17, 70, 33, 2365, 368, 99, 167, 10204]\n",
            "\n",
            "\n",
            "Original Comment: nani apni koto bosor rokom takben\n",
            "Tokenized Sequence: [1734, 15, 33, 3796, 251, 3055]\n",
            "\n",
            "\n",
            "Original Comment: shalar makeup edit chote hot lgae\n",
            "Tokenized Sequence: [924, 368, 722, 10205, 319, 10206]\n",
            "\n",
            "\n",
            "Original Comment: ahree koto deho dekhaba!\n",
            "Tokenized Sequence: [10207, 33, 1011, 2503]\n",
            "\n",
            "\n",
            "Original Comment: sari porlen, kintu upor nich soob ee deka jay\n",
            "Tokenized Sequence: [1782, 10208, 68, 253, 2486, 457, 584, 881, 92]\n",
            "\n",
            "\n",
            "Original Comment: magida sexi hoi gese\n",
            "Tokenized Sequence: [10209, 3530, 38, 87]\n",
            "\n",
            "\n",
            "Original Comment: magir putki dia baksh hobe\n",
            "Tokenized Sequence: [363, 425, 252, 10210, 11]\n",
            "\n",
            "\n",
            "Original Comment: lucca deksi emn dekini\n",
            "Tokenized Sequence: [2328, 2378, 246, 10211]\n",
            "\n",
            "\n",
            "Original Comment: emn ada lenta hoia kemera te aso\n",
            "Tokenized Sequence: [246, 2792, 10212, 295, 10213, 25, 237]\n",
            "\n",
            "\n",
            "Original Comment: taka thakle onk gorto ahe koilam\n",
            "Tokenized Sequence: [172, 143, 58, 3819, 3835, 1884]\n",
            "\n",
            "\n",
            "Original Comment: suhdhu bf dile hoy nai, amarao pabar koyha bebi\n",
            "Tokenized Sequence: [10214, 938, 254, 14, 5, 10215, 10216, 10217, 10218]\n",
            "\n",
            "\n",
            "Original Comment: tomare nangta koira pitale valo hoiba\n",
            "Tokenized Sequence: [819, 3804, 99, 10219, 6, 10220]\n",
            "\n",
            "\n",
            "Original Comment: meyego eto bujte hoy na, sudu pa fak kore dite hoy\n",
            "Tokenized Sequence: [3337, 60, 1050, 14, 1, 336, 1574, 1903, 2, 117, 14]\n",
            "\n",
            "\n",
            "Original Comment: ore jama re, fokir naki\n",
            "Tokenized Sequence: [91, 179, 1343, 3957, 29]\n",
            "\n",
            "\n",
            "Original Comment: fokkini rao cheye boro jama pora\n",
            "Tokenized Sequence: [10221, 10222, 535, 18, 179, 244]\n",
            "\n",
            "\n",
            "Original Comment: maal kheye na dile thambe na dekci\n",
            "Tokenized Sequence: [310, 165, 1, 254, 10223, 1, 2439]\n",
            "\n",
            "\n",
            "Original Comment: tmr leeeleee dekha jay\n",
            "Tokenized Sequence: [32, 10224, 122, 92]\n",
            "\n",
            "\n",
            "Original Comment: eeeee buke kapor nai kn!\n",
            "Tokenized Sequence: [10225, 1410, 201, 5, 239]\n",
            "\n",
            "\n",
            "Original Comment: apne buri hoben kobe go..?\n",
            "Tokenized Sequence: [638, 419, 2351, 423, 137]\n",
            "\n",
            "\n",
            "Original Comment: erokom pic dile coto matha ghoray.\n",
            "Tokenized Sequence: [835, 63, 254, 891, 420, 10226]\n",
            "\n",
            "\n",
            "Original Comment: sarir aacol akto sorale amon prblm hoto bby\n",
            "Tokenized Sequence: [3564, 10227, 777, 10228, 133, 10229, 257, 3587]\n",
            "\n",
            "\n",
            "Original Comment: adha dodo dekhao kn....\n",
            "Tokenized Sequence: [10230, 1571, 886, 239]\n",
            "\n",
            "\n",
            "Original Comment: ektu dhormer pothe ashun ektu porda korun..... boyos kom hoise na..... koto taka kamaiben?\n",
            "Tokenized Sequence: [154, 572, 1017, 10231, 154, 1690, 451, 901, 248, 188, 1, 33, 172, 10232]\n",
            "\n",
            "\n",
            "Original Comment: cleaveg taa uffooo sorry ami dekhe nai\n",
            "Tokenized Sequence: [10233, 1301, 10234, 896, 4, 73, 5]\n",
            "\n",
            "\n",
            "Original Comment: tumer doshe abr gusol korte hobo valolage na\n",
            "Tokenized Sequence: [1817, 10235, 169, 10236, 41, 1866, 10237, 1]\n",
            "\n",
            "\n",
            "Original Comment: are masi apne seci\n",
            "Tokenized Sequence: [177, 10238, 638, 3959]\n",
            "\n",
            "\n",
            "Original Comment: duder chipa ber hoia gese\n",
            "Tokenized Sequence: [1048, 10239, 139, 295, 87]\n",
            "\n",
            "\n",
            "Original Comment: gidor marka bedi.. buera van.. vabta na nay.. chii\n",
            "Tokenized Sequence: [2171, 325, 783, 10240, 10241, 10242, 1, 658, 2881]\n",
            "\n",
            "\n",
            "Original Comment: dudu na dekhale comment pore na!\n",
            "Tokenized Sequence: [260, 1, 3762, 197, 62, 1]\n",
            "\n",
            "\n",
            "Original Comment: tumi buri hote hote amr nati natni hata sheke jba\n",
            "Tokenized Sequence: [13, 419, 184, 184, 7, 2033, 10243, 2312, 10244, 3593]\n",
            "\n",
            "\n",
            "Original Comment: din din koci hou kibabe?\n",
            "Tokenized Sequence: [35, 35, 1816, 1051, 2174]\n",
            "\n",
            "\n",
            "Original Comment: kheye dilo tmk india\n",
            "Tokenized Sequence: [165, 321, 273, 161]\n",
            "\n",
            "\n",
            "Original Comment: bra tia rong naki,\n",
            "Tokenized Sequence: [221, 10245, 1175, 29]\n",
            "\n",
            "\n",
            "Original Comment: din din bodmash oijire\n",
            "Tokenized Sequence: [35, 35, 10246, 10247]\n",
            "\n",
            "\n",
            "Original Comment: bura hoiao tight koto dekssenni\n",
            "Tokenized Sequence: [607, 3960, 1407, 33, 10248]\n",
            "\n",
            "\n",
            "Original Comment: khabo tumar oi duto habudubu, hae ja vabso otai\n",
            "Tokenized Sequence: [412, 281, 57, 1791, 10249, 2380, 70, 10250, 3063]\n",
            "\n",
            "\n",
            "Original Comment: sob bujlam sali pant zip kno dise!!?\n",
            "Tokenized Sequence: [8, 560, 1010, 314, 10251, 64, 205]\n",
            "\n",
            "\n",
            "Original Comment: kiser jani chap pore ache dress upor\n",
            "Tokenized Sequence: [10252, 160, 2460, 62, 74, 164, 253]\n",
            "\n",
            "\n",
            "Original Comment: opss hot vai..!!\n",
            "Tokenized Sequence: [10253, 319, 3]\n",
            "\n",
            "\n",
            "Original Comment: ato sodo jinish deikha moja nai, aso boro kore dei\n",
            "Tokenized Sequence: [43, 2237, 283, 482, 224, 5, 237, 18, 2, 330]\n",
            "\n",
            "\n",
            "Original Comment: koci sobji aita khete onek valo hobe, rose vora ekdom, ufff\n",
            "Tokenized Sequence: [1816, 10254, 149, 450, 56, 6, 11, 2311, 1039, 530, 652]\n",
            "\n",
            "\n",
            "Original Comment: pore na chokher polok tmr surgery makeup jholok\n",
            "Tokenized Sequence: [62, 1, 10255, 3961, 32, 10256, 368, 10257]\n",
            "\n",
            "\n",
            "Original Comment: bura beti din din bacca hoitace..\n",
            "Tokenized Sequence: [607, 787, 35, 35, 562, 1689]\n",
            "\n",
            "\n",
            "Original Comment: jule porche re, are jama jhule gese, bolod\n",
            "Tokenized Sequence: [3380, 895, 1343, 177, 179, 1176, 87, 2360]\n",
            "\n",
            "\n",
            "Original Comment: nicher jeno dekha jai\n",
            "Tokenized Sequence: [665, 452, 122, 90]\n",
            "\n",
            "\n",
            "Original Comment: koto pagol hobo choto theke pagol hoye achi,boro hoye aro koto kichu dekchi\n",
            "Tokenized Sequence: [33, 108, 1866, 129, 21, 108, 20, 3914, 18, 20, 131, 33, 80, 10258]\n",
            "\n",
            "\n",
            "Original Comment: baler pic dice bra buja jai\n",
            "Tokenized Sequence: [194, 63, 922, 221, 726, 90]\n",
            "\n",
            "\n",
            "Original Comment: eto dhong na dekhaleo cholbe, bap bap vag sali\n",
            "Tokenized Sequence: [60, 981, 1, 10259, 2977, 404, 404, 2489, 1010]\n",
            "\n",
            "\n",
            "Original Comment: apni kundin buri hoben khala\n",
            "Tokenized Sequence: [15, 10260, 419, 2351, 824]\n",
            "\n",
            "\n",
            "Original Comment: eij sob dekhao, amr pant change kora lage\n",
            "Tokenized Sequence: [10261, 8, 886, 7, 314, 546, 39, 47]\n",
            "\n",
            "\n",
            "Original Comment: jama poren je bra buja jay\n",
            "Tokenized Sequence: [179, 1190, 46, 221, 726, 92]\n",
            "\n",
            "\n",
            "Original Comment: dhormu vormu sesh bujla beti\n",
            "Tokenized Sequence: [10262, 10263, 204, 2326, 787]\n",
            "\n",
            "\n",
            "Original Comment: koto amader rod niye khela korba tumi\n",
            "Tokenized Sequence: [33, 132, 3962, 65, 130, 565, 13]\n",
            "\n",
            "\n",
            "Original Comment: amr rod boso, trpr tmr bel bajabo dong dong\n",
            "Tokenized Sequence: [7, 3962, 10264, 1188, 32, 10265, 10266, 1807, 1807]\n",
            "\n",
            "\n",
            "Original Comment: are bha salire amra gol bhabi are sali bastobe stick\n",
            "Tokenized Sequence: [177, 3311, 10267, 85, 1849, 2780, 177, 1010, 10268, 10269]\n",
            "\n",
            "\n",
            "Original Comment: afa daria ghuman ka?? bed nai\n",
            "Tokenized Sequence: [708, 10270, 10271, 476, 1980, 5]\n",
            "\n",
            "\n",
            "Original Comment: ahh bole lav uni ahh ahh karon hobe\n",
            "Tokenized Sequence: [944, 54, 517, 226, 944, 944, 329, 11]\n",
            "\n",
            "\n",
            "Original Comment: bra rokom na dekhaiya shirt khule dekhaiten\n",
            "Tokenized Sequence: [221, 251, 1, 2487, 923, 279, 10272]\n",
            "\n",
            "\n",
            "Original Comment: kutti maiya,,,thapraite mon chay\n",
            "Tokenized Sequence: [10273, 150, 10274, 84, 300]\n",
            "\n",
            "\n",
            "Original Comment: appi joto hedar kam koren na ken pori moni theikka shundor hoite parben na\n",
            "Tokenized Sequence: [1321, 337, 657, 274, 83, 1, 146, 136, 417, 10275, 303, 428, 578, 1]\n",
            "\n",
            "\n",
            "Original Comment: emon cuto kaporer style amio dita pari kinto allha voi pai tor moto nh\n",
            "Tokenized Sequence: [156, 10276, 10277, 508, 238, 1766, 138, 1281, 1688, 3036, 463, 17, 16, 135]\n",
            "\n",
            "\n",
            "Original Comment: nostamir ekta sima thaka dorkar\n",
            "Tokenized Sequence: [10278, 36, 10279, 292, 100]\n",
            "\n",
            "\n",
            "Original Comment: tui hossis bangladesh kolongko\n",
            "Tokenized Sequence: [23, 10280, 12, 10281]\n",
            "\n",
            "\n",
            "Original Comment: sob makeup kamal makeup tullei sob sundorjo ses\n",
            "Tokenized Sequence: [8, 368, 10282, 368, 10283, 8, 3963, 225]\n",
            "\n",
            "\n",
            "Original Comment: kno pori moni deika sojjo hocce na... bal cal\n",
            "Tokenized Sequence: [64, 136, 417, 3964, 1082, 825, 1, 48, 3869]\n",
            "\n",
            "\n",
            "Original Comment: jotoi koro bahana, firbe na tomar zoubonota!\n",
            "Tokenized Sequence: [974, 78, 10284, 10285, 1, 26, 10286]\n",
            "\n",
            "\n",
            "Original Comment: ey bochor krimir dose na newar porinoti te emn chegaya model kore kn!\n",
            "Tokenized Sequence: [815, 880, 10287, 10288, 1, 3267, 10289, 25, 246, 2560, 791, 2, 239]\n",
            "\n",
            "\n",
            "Original Comment: tmr navi dekay dila sobaike\n",
            "Tokenized Sequence: [32, 1770, 10290, 519, 1457]\n",
            "\n",
            "\n",
            "Original Comment: emon kore kere? mone hoi pipra pasay kamor dise...\n",
            "Tokenized Sequence: [156, 2, 1433, 34, 38, 2337, 1209, 1208, 205]\n",
            "\n",
            "\n",
            "Original Comment: buira always bura..jotoi bav lon na kno\n",
            "Tokenized Sequence: [715, 1104, 607, 974, 10291, 3551, 1, 64]\n",
            "\n",
            "\n",
            "Original Comment: anti lengta hoye jan photo valo ashbe\n",
            "Tokenized Sequence: [1451, 1431, 20, 378, 845, 6, 849]\n",
            "\n",
            "\n",
            "Original Comment: apner dress kon kon dike amn air cooling jonno faka ase?\n",
            "Tokenized Sequence: [290, 164, 145, 145, 386, 213, 10292, 10293, 28, 10294, 45]\n",
            "\n",
            "\n",
            "Original Comment: eto choto apnr ta? biya koren amk,thik size kore debo doli doli\n",
            "Tokenized Sequence: [60, 129, 222, 871, 366, 83, 429, 61, 276, 2, 500, 3965, 3965]\n",
            "\n",
            "\n",
            "Original Comment: buira hoiao koto dhong, ere deikha 4 din kharay na, dheeeeet\n",
            "Tokenized Sequence: [715, 3960, 33, 981, 2389, 482, 660, 35, 10295, 1, 10296]\n",
            "\n",
            "\n",
            "Original Comment: buri khala amma kore lav!\n",
            "Tokenized Sequence: [419, 824, 3067, 2, 517]\n",
            "\n",
            "\n",
            "Original Comment: nispap bokasoda lage, kintu asole....\n",
            "Tokenized Sequence: [2390, 10297, 47, 68, 407]\n",
            "\n",
            "\n",
            "Original Comment: ek kapore koto din cholba!\n",
            "Tokenized Sequence: [125, 10298, 33, 35, 10299]\n",
            "\n",
            "\n",
            "Original Comment: dukkher majheo hot pic deikha batrom te ailam\n",
            "Tokenized Sequence: [10300, 10301, 319, 63, 482, 10302, 25, 10303]\n",
            "\n",
            "\n",
            "Original Comment: joya tmi manush hoba na,khali khali horny picture dao\n",
            "Tokenized Sequence: [10304, 69, 67, 258, 1, 167, 167, 2354, 817, 581]\n",
            "\n",
            "\n",
            "Original Comment: nanir zoubon ehono togboge dekhi\n",
            "Tokenized Sequence: [1112, 10305, 10306, 10307, 157]\n",
            "\n",
            "\n",
            "Original Comment: balda jiboneo bura hoibe nah\n",
            "Tokenized Sequence: [2494, 10308, 607, 10309, 52]\n",
            "\n",
            "\n",
            "Original Comment: anty apni kbe buri hben apner jonnoi amder biye hocse na etto sundori keno?\n",
            "Tokenized Sequence: [1926, 15, 2261, 419, 10310, 290, 839, 1829, 267, 10311, 1, 1235, 894, 111]\n",
            "\n",
            "\n",
            "Original Comment: din din yeang hocchen seci oo\n",
            "Tokenized Sequence: [35, 35, 10312, 2359, 3959, 693]\n",
            "\n",
            "\n",
            "Original Comment: are mone hoi rate gum asbe nah,esob nosta pic dao kno\n",
            "Tokenized Sequence: [177, 34, 38, 374, 2453, 970, 52, 369, 2215, 63, 581, 64]\n",
            "\n",
            "\n",
            "Original Comment: jotoi moyda maro, anti anti thake, buri demri\n",
            "Tokenized Sequence: [974, 1448, 856, 1451, 1451, 114, 419, 10313]\n",
            "\n",
            "\n",
            "Original Comment: joubone tmr tometo khete parle valo lagto\n",
            "Tokenized Sequence: [10314, 32, 10315, 450, 464, 6, 711]\n",
            "\n",
            "\n",
            "Original Comment: bora boyos asob dorkar chilo\n",
            "Tokenized Sequence: [1663, 901, 579, 100, 94]\n",
            "\n",
            "\n",
            "Original Comment: tin projonmer je kheer loss hoy, eita apner gouboner dosh\n",
            "Tokenized Sequence: [1479, 3446, 46, 3966, 10316, 14, 289, 290, 10317, 1439]\n",
            "\n",
            "\n",
            "Original Comment: aunti alga khaoya chari halal koira khan\n",
            "Tokenized Sequence: [3967, 10318, 10319, 10320, 10321, 99, 643]\n",
            "\n",
            "\n",
            "Original Comment: hobe shouwndorjo dia shomay khob shimito, aso biye kore feli, trpr ufff.... hobe\n",
            "Tokenized Sequence: [11, 10322, 252, 10323, 1380, 10324, 237, 267, 2, 1556, 1188, 652, 11]\n",
            "\n",
            "\n",
            "Original Comment: ek matro hotee aunti, jar liga kochi polarao pagol\n",
            "Tokenized Sequence: [125, 672, 10325, 3967, 193, 2483, 1012, 10326, 108]\n",
            "\n",
            "\n",
            "Original Comment: baldar boyos bare nah\n",
            "Tokenized Sequence: [10327, 901, 867, 52]\n",
            "\n",
            "\n",
            "Original Comment: upore tostosa hoileo vitore mora\n",
            "Tokenized Sequence: [853, 10328, 3406, 927, 1184]\n",
            "\n",
            "\n",
            "Original Comment: tumar libistik tes jante caoa amr mon\n",
            "Tokenized Sequence: [281, 10329, 10330, 533, 2181, 7, 84]\n",
            "\n",
            "\n",
            "Original Comment: mal out baby, shudhu tomer jonna\n",
            "Tokenized Sequence: [247, 2268, 505, 698, 1225, 3029]\n",
            "\n",
            "\n",
            "Original Comment: ros ber hoy na koydin dhore\n",
            "Tokenized Sequence: [2456, 139, 14, 1, 10331, 734]\n",
            "\n",
            "\n",
            "Original Comment: hmmm jemon apnare dekhlei opolop distite dekhtei iche kore, je pore gese ter pai\n",
            "Tokenized Sequence: [3815, 914, 355, 461, 10332, 10333, 10334, 10335, 2, 46, 62, 87, 2049, 463]\n",
            "\n",
            "\n",
            "Original Comment: chit hoye ace khabar jonno, keu ghono kheer shot kor\n",
            "Tokenized Sequence: [10336, 20, 207, 1585, 28, 390, 2458, 3966, 10337, 227]\n",
            "\n",
            "\n",
            "Original Comment: vabcilam tormuch akhon dekhi apple, hotasa\n",
            "Tokenized Sequence: [10338, 10339, 268, 157, 3933, 10340]\n",
            "\n",
            "\n",
            "Original Comment: zubon theal sesh nai\n",
            "Tokenized Sequence: [10341, 10342, 204, 5]\n",
            "\n",
            "\n",
            "Original Comment: anty din din koci maal hosse\n",
            "Tokenized Sequence: [1926, 35, 35, 1816, 310, 601]\n",
            "\n",
            "\n",
            "Original Comment: pore na coker polok bab codaile kaiva block\n",
            "Tokenized Sequence: [62, 1, 10343, 3961, 2428, 10344, 10345, 10346]\n",
            "\n",
            "\n",
            "Original Comment: tomar sundor pahare testa metabo ami\n",
            "Tokenized Sequence: [26, 66, 3865, 10347, 10348, 4]\n",
            "\n",
            "\n",
            "Original Comment: 1 bar paylea ufff kortam\n",
            "Tokenized Sequence: [297, 134, 10349, 652, 675]\n",
            "\n",
            "\n",
            "Original Comment: tmk kati sorisa tel lagiye pundabu\n",
            "Tokenized Sequence: [273, 2775, 10350, 720, 3948, 10351]\n",
            "\n",
            "\n",
            "Original Comment: muslim hoye puja te jawa thik hoyni.. ..\n",
            "Tokenized Sequence: [82, 20, 370, 25, 1450, 61, 10352]\n",
            "\n",
            "\n",
            "Original Comment: varot gia koyjon thap khaia aila\n",
            "Tokenized Sequence: [2233, 1355, 1996, 3952, 717, 3968]\n",
            "\n",
            "\n",
            "Original Comment: kire bedi tui pujay jabi kn, musolman na tui\n",
            "Tokenized Sequence: [552, 783, 23, 1641, 10353, 239, 1337, 1, 23]\n",
            "\n",
            "\n",
            "Original Comment: actually apni muslim na hindu i,m confused!!!\n",
            "Tokenized Sequence: [2412, 15, 82, 1, 89, 171, 1428, 3763]\n",
            "\n",
            "\n",
            "Original Comment: cudani tui hindu tui kno anondo korbi\n",
            "Tokenized Sequence: [10354, 23, 89, 23, 64, 2357, 826]\n",
            "\n",
            "\n",
            "Original Comment: toi hindu?? vabsilm muslim\n",
            "Tokenized Sequence: [388, 89, 2342, 82]\n",
            "\n",
            "\n",
            "Original Comment: ee maal hindu na\n",
            "Tokenized Sequence: [584, 310, 89, 1]\n",
            "\n",
            "\n",
            "Original Comment: muslim bacca hoia pujay gaiba tumi\n",
            "Tokenized Sequence: [82, 562, 295, 1641, 10355, 13]\n",
            "\n",
            "\n",
            "Original Comment: kobore jaw... tmr pasar modde bas vora murti rokkha korbe.....agula sob takai bikri dui takar nortoki\n",
            "Tokenized Sequence: [3953, 597, 32, 3588, 696, 1052, 1039, 621, 1827, 262, 478, 8, 3768, 1074, 382, 945, 10356]\n",
            "\n",
            "\n",
            "Original Comment: mona prana hindu nama muslim.aita baro akta maggi\n",
            "Tokenized Sequence: [841, 10357, 89, 10358, 82, 149, 1557, 37, 2223]\n",
            "\n",
            "\n",
            "Original Comment: ato kiso holo hindo amder quran take osomman korlo.. oni chi chi chi\n",
            "Tokenized Sequence: [43, 692, 170, 1820, 1829, 980, 223, 3518, 343, 1289, 350, 350, 350]\n",
            "\n",
            "\n",
            "Original Comment: tumi aso koto din khabo toto din\n",
            "Tokenized Sequence: [13, 237, 33, 35, 412, 1014, 35]\n",
            "\n",
            "\n",
            "Original Comment: tomar golar har amay dibe? amar ekti meye kukur ache take porabo\n",
            "Tokenized Sequence: [26, 10359, 10360, 1601, 305, 9, 10361, 50, 1569, 74, 223, 10362]\n",
            "\n",
            "\n",
            "Original Comment: beb gash gula kaita raikho ami ashtesi, trpr ghoap ghop\n",
            "Tokenized Sequence: [10363, 10364, 55, 2164, 10365, 4, 3641, 1188, 10366, 10367]\n",
            "\n",
            "\n",
            "Original Comment: onek din hoilo tmr hot pic dekhi na\n",
            "Tokenized Sequence: [56, 35, 249, 32, 319, 63, 157, 1]\n",
            "\n",
            "\n",
            "Original Comment: kisu ase bra strap deikhei felte suru korbe\n",
            "Tokenized Sequence: [106, 45, 221, 10368, 10369, 2433, 272, 262]\n",
            "\n",
            "\n",
            "Original Comment: bra eto tait kno, betha pabe dodo te\n",
            "Tokenized Sequence: [221, 60, 2260, 64, 1181, 892, 1571, 25]\n",
            "\n",
            "\n",
            "Original Comment: bujhi na tmr dab hothath eto uca\n",
            "Tokenized Sequence: [733, 1, 32, 1114, 10370, 60, 10371]\n",
            "\n",
            "\n",
            "Original Comment: bura hetir hallot deko\n",
            "Tokenized Sequence: [607, 1683, 10372, 1222]\n",
            "\n",
            "\n",
            "Original Comment: salar indian gula mohila koto je khaia dise!\n",
            "Tokenized Sequence: [512, 732, 55, 181, 33, 46, 717, 205]\n",
            "\n",
            "\n",
            "Original Comment: jama jmn pink, biral oo pink\n",
            "Tokenized Sequence: [179, 3463, 3969, 1013, 693, 3969]\n",
            "\n",
            "\n",
            "Original Comment: bra khule gelo bujhi vaar ee\n",
            "Tokenized Sequence: [221, 279, 105, 733, 10373, 584]\n",
            "\n",
            "\n",
            "Original Comment: kire beti bra dekhas emne, jama valo por\n",
            "Tokenized Sequence: [552, 787, 221, 10374, 1510, 179, 6, 72]\n",
            "\n",
            "\n",
            "Original Comment: bra fita dekha jai khala\n",
            "Tokenized Sequence: [221, 10375, 122, 90, 824]\n",
            "\n",
            "\n",
            "Original Comment: dekhi puro sorir makeup lagase.makeup sara aktu samne asio.tmr asol sundorjo dekhte chai munu\n",
            "Tokenized Sequence: [157, 740, 670, 368, 10376, 368, 298, 178, 389, 10377, 32, 808, 3963, 112, 124, 10378]\n",
            "\n",
            "\n",
            "Original Comment: buri dekhte dekhte nije choto thek boro hoa gelam kintu burir bura boyoser tel kome na... burir soril dekhte dekhte ami aj birokto...\n",
            "Tokenized Sequence: [419, 112, 112, 203, 129, 3436, 18, 864, 439, 68, 1595, 607, 3284, 720, 1338, 1, 1595, 3203, 112, 112, 4, 123, 10379]\n",
            "\n",
            "\n",
            "Original Comment: khola mela pic diya bojhate chan amne jowan? anne je buira beti amne je 2nd hand sheita bekei jane\n",
            "Tokenized Sequence: [1709, 957, 63, 76, 3521, 2298, 1249, 10380, 10381, 46, 715, 787, 1249, 46, 10382, 3532, 3327, 10383, 275]\n",
            "\n",
            "\n",
            "Original Comment: pura bodi moyda makhen abr bah\n",
            "Tokenized Sequence: [384, 2376, 1448, 10384, 169, 327]\n",
            "\n",
            "\n",
            "Original Comment: apner mekap man hobo, tpr full bodi mekap debo\n",
            "Tokenized Sequence: [290, 2383, 494, 1866, 10385, 811, 2376, 2383, 500]\n",
            "\n",
            "\n",
            "Original Comment: khali jainga poira cemeray asen chi\n",
            "Tokenized Sequence: [167, 10386, 548, 10387, 1185, 350]\n",
            "\n",
            "\n",
            "Original Comment: bura matharir pank dekhle mon da cay bis khai\n",
            "Tokenized Sequence: [607, 10388, 10389, 332, 84, 351, 1132, 2173, 256]\n",
            "\n",
            "\n",
            "Original Comment: silai kore nen jamata apnr pasa bair hoi jacce\n",
            "Tokenized Sequence: [10390, 2, 1264, 10391, 222, 472, 671, 38, 1066]\n",
            "\n",
            "\n",
            "Original Comment: kobi blesen.poshake jotota vlo lge tar cheyo aro vlo lge poshag na thakle\n",
            "Tokenized Sequence: [3538, 10392, 10393, 10394, 75, 793, 31, 10395, 131, 75, 793, 10396, 1, 143]\n",
            "\n",
            "\n",
            "Original Comment: bolci j panti nh poira khuilla rakho valo hoibo\n",
            "Tokenized Sequence: [10397, 42, 10398, 135, 548, 2336, 752, 6, 454]\n",
            "\n",
            "\n",
            "Original Comment: ato choto kapor tara pore kivabe lojja lage nah!\n",
            "Tokenized Sequence: [43, 129, 201, 287, 62, 392, 245, 47, 52]\n",
            "\n",
            "\n",
            "Original Comment: vondami caren, boyos hoice\n",
            "Tokenized Sequence: [3477, 10399, 901, 356]\n",
            "\n",
            "\n",
            "Original Comment: boin lo drug mone beshi poira jaitache control\n",
            "Tokenized Sequence: [335, 2810, 10400, 34, 120, 548, 10401, 2135]\n",
            "\n",
            "\n",
            "Original Comment: mod khaia pondai tumare\n",
            "Tokenized Sequence: [593, 717, 10402, 1797]\n",
            "\n",
            "\n",
            "Original Comment: tuku kapor pore asen ken oitaw khule felun nonra manob\n",
            "Tokenized Sequence: [1111, 201, 62, 1185, 146, 10403, 279, 10404, 3956, 3018]\n",
            "\n",
            "\n",
            "Original Comment: boira badir sok dakla majaj krp hoi\n",
            "Tokenized Sequence: [2490, 10405, 10406, 3929, 10407, 3663, 38]\n",
            "\n",
            "\n",
            "Original Comment: anti din din koto kisu dakhaiben, kocider sugok dim\n",
            "Tokenized Sequence: [1451, 35, 35, 33, 106, 10408, 10409, 10410, 349]\n",
            "\n",
            "\n",
            "Original Comment: buri bedi emn nengta hoile, picci maia diboi\n",
            "Tokenized Sequence: [419, 783, 246, 1108, 398, 10411, 1205, 10412]\n",
            "\n",
            "\n",
            "Original Comment: bedir boyos joto bare, kapor coto hoy, ek smy lengta hoibo\n",
            "Tokenized Sequence: [1524, 901, 337, 867, 201, 891, 14, 125, 3791, 1431, 454]\n",
            "\n",
            "\n",
            "Original Comment: body makeuo nengta hoia kore\n",
            "Tokenized Sequence: [2362, 10413, 1108, 295, 2]\n",
            "\n",
            "\n",
            "Original Comment: kobe je dola khawar khobor pamo bedir\n",
            "Tokenized Sequence: [423, 46, 10414, 706, 861, 10415, 1524]\n",
            "\n",
            "\n",
            "Original Comment: deko maia pant na poira aisa porse\n",
            "Tokenized Sequence: [1222, 1205, 314, 1, 548, 3544, 611]\n",
            "\n",
            "\n",
            "Original Comment: meye ses boyos ak br nosto hoye glo india giya..botam lagao ccc takano jacce na\n",
            "Tokenized Sequence: [50, 225, 901, 206, 10416, 215, 20, 10417, 161, 866, 10418, 1767, 2289, 3013, 1066, 1]\n",
            "\n",
            "\n",
            "Original Comment: chera fara kapor poira koto ghurben amar bashar paruler puran koita jama ache tobe chira na niye jayen\n",
            "Tokenized Sequence: [1215, 10419, 201, 548, 33, 10420, 9, 1523, 10421, 2424, 1370, 179, 74, 762, 1790, 1, 65, 10422]\n",
            "\n",
            "\n",
            "Original Comment: chele der hat marte sahajjo korar jonno take ekta award dawa drkr...\n",
            "Tokenized Sequence: [346, 44, 379, 704, 2106, 101, 28, 223, 36, 3920, 590, 995]\n",
            "\n",
            "\n",
            "Original Comment: apnago morar vhoy nai!ki shob dress poren..!\n",
            "Tokenized Sequence: [10423, 1691, 10424, 5, 175, 127, 164, 1190]\n",
            "\n",
            "\n",
            "Original Comment: baby amr aho buke aho... khela hobbe... football khelmu\n",
            "Tokenized Sequence: [505, 7, 1197, 1410, 1197, 130, 10425, 583, 10426]\n",
            "\n",
            "\n",
            "Original Comment: gota diye pregnant kore dibo sudir boin\n",
            "Tokenized Sequence: [10427, 49, 10428, 2, 189, 1882, 335]\n",
            "\n",
            "\n",
            "Original Comment: deho evabe bilaien takar liga chi\n",
            "Tokenized Sequence: [1011, 1904, 10429, 945, 2483, 350]\n",
            "\n",
            "\n",
            "Original Comment: hotelewo akhon ager moto dam payna. apnar moto bedi\n",
            "Tokenized Sequence: [10430, 268, 561, 16, 1102, 3044, 22, 16, 783]\n",
            "\n",
            "\n",
            "Original Comment: guya mara kha..\n",
            "Tokenized Sequence: [1956, 195, 663]\n",
            "\n",
            "\n",
            "Original Comment: tr cheye amr pasa sundor\n",
            "Tokenized Sequence: [304, 535, 7, 472, 66]\n",
            "\n",
            "\n",
            "Original Comment: tomar tuntuni dia jhunjhuni bajamu injection dimu\n",
            "Tokenized Sequence: [26, 10431, 252, 10432, 10433, 3338, 630]\n",
            "\n",
            "\n",
            "Original Comment: apni emn horni horni thaken je, fete jabe sob\n",
            "Tokenized Sequence: [15, 246, 3970, 3970, 748, 46, 1769, 126, 8]\n",
            "\n",
            "\n",
            "Original Comment: lipstick flavour jante cai, kache aso ettu\n",
            "Tokenized Sequence: [1864, 10434, 533, 513, 360, 237, 10435]\n",
            "\n",
            "\n",
            "Original Comment: burir betir jinis joyan ase kivabe\n",
            "Tokenized Sequence: [1595, 10436, 467, 10437, 45, 392]\n",
            "\n",
            "\n",
            "Original Comment: esob oslilota na carle, rap kore dibo\n",
            "Tokenized Sequence: [369, 10438, 1, 10439, 10440, 2, 189]\n",
            "\n",
            "\n",
            "Original Comment: belaous chara namle emn jhaki te ber hobei\n",
            "Tokenized Sequence: [10441, 233, 10442, 246, 10443, 25, 139, 2619]\n",
            "\n",
            "\n",
            "Original Comment: sofolota diya piche vorse\n",
            "Tokenized Sequence: [10444, 76, 1395, 10445]\n",
            "\n",
            "\n",
            "Original Comment: sob pore piche soob udla jay\n",
            "Tokenized Sequence: [8, 62, 1395, 457, 10446, 92]\n",
            "\n",
            "\n",
            "Original Comment: amr personal shampoo tmk na dile valo hoba na\n",
            "Tokenized Sequence: [7, 2331, 3809, 273, 1, 254, 6, 258, 1]\n",
            "\n",
            "\n",
            "Original Comment: de lara maal dar pacha dhoira\n",
            "Tokenized Sequence: [266, 1976, 310, 770, 1162, 1269]\n",
            "\n",
            "\n",
            "Original Comment: apni lengtu gibon pcondo koren\n",
            "Tokenized Sequence: [15, 10447, 10448, 10449, 83]\n",
            "\n",
            "\n",
            "Original Comment: joubon utlaise, kintu manush nai khawar\n",
            "Tokenized Sequence: [10450, 10451, 68, 67, 5, 706]\n",
            "\n",
            "\n",
            "Original Comment: emn coto kapor bou ee lagbe jamar khoroch nai kono\n",
            "Tokenized Sequence: [246, 891, 201, 199, 584, 323, 2329, 10452, 5, 27]\n",
            "\n",
            "\n",
            "Original Comment: gorom ee blouse oo pora nai he he he\n",
            "Tokenized Sequence: [414, 584, 3382, 693, 244, 5, 532, 532, 532]\n",
            "\n",
            "\n",
            "Original Comment: tomay deke dud khawar nesa jagse\n",
            "Tokenized Sequence: [1771, 418, 208, 706, 2213, 10453]\n",
            "\n",
            "\n",
            "Original Comment: biya korba amk? tmr nictola dum dum kore kapabo\n",
            "Tokenized Sequence: [366, 565, 429, 32, 10454, 3971, 3971, 2, 10455]\n",
            "\n",
            "\n",
            "Original Comment: india gia eisob nongra jama pora sikse\n",
            "Tokenized Sequence: [161, 1355, 586, 2293, 179, 244, 10456]\n",
            "\n",
            "\n",
            "Original Comment: ere theka keu, naile amare sesh koira dibo hnadle maraite maraite\n",
            "Tokenized Sequence: [2389, 953, 390, 1834, 408, 204, 99, 189, 10457, 3972, 3972]\n",
            "\n",
            "\n",
            "Original Comment: chamra jhuke gese kotodin rong dekhabi\n",
            "Tokenized Sequence: [1880, 10458, 87, 1815, 1175, 10459]\n",
            "\n",
            "\n",
            "Original Comment: ami tomar dudhe dhoya tulsi pata\n",
            "Tokenized Sequence: [4, 26, 10460, 10461, 10462, 1863]\n",
            "\n",
            "\n",
            "Original Comment: kal raat sopne ese amre rosete chubaiso ahh..\n",
            "Tokenized Sequence: [753, 1026, 10463, 1121, 1255, 10464, 10465, 944]\n",
            "\n",
            "\n",
            "Original Comment: chubby ee valo chila, tultule chilo du-du to...\n",
            "Tokenized Sequence: [10466, 584, 6, 2241, 10467, 94, 893, 893, 506]\n",
            "\n",
            "\n",
            "Original Comment: halar pasay koto current baap\n",
            "Tokenized Sequence: [563, 1209, 33, 1358, 2984]\n",
            "\n",
            "\n",
            "Original Comment: kache keno asona, ador korte pari na tomar moyna\n",
            "Tokenized Sequence: [360, 111, 3570, 1015, 41, 138, 1, 26, 3793]\n",
            "\n",
            "\n",
            "Original Comment: ager moto hendel marte pari na... tmr dosh eta\n",
            "Tokenized Sequence: [561, 16, 10468, 704, 138, 1, 32, 1439, 95]\n",
            "\n",
            "\n",
            "Original Comment: boloto tip kothay kopal ee na buke?\n",
            "Tokenized Sequence: [3285, 929, 528, 1390, 584, 1, 1410]\n",
            "\n",
            "\n",
            "Original Comment: sonapurer thakar vara koto\n",
            "Tokenized Sequence: [10469, 3365, 1170, 33]\n",
            "\n",
            "\n",
            "Original Comment: deksoni karbar, nillojjer moto kapor poira ache chi\n",
            "Tokenized Sequence: [10470, 10471, 10472, 16, 201, 548, 74, 350]\n",
            "\n",
            "\n",
            "Original Comment: ehe bichi baba theke pora nise\n",
            "Tokenized Sequence: [10473, 545, 401, 21, 244, 1324]\n",
            "\n",
            "\n",
            "Original Comment: tumi dine dekhi du-du bar kore chobi dao\n",
            "Tokenized Sequence: [13, 702, 157, 893, 893, 134, 2, 558, 581]\n",
            "\n",
            "\n",
            "Original Comment: dheet holo tomar, kal raat khelar jonno tel diye antena sokto korlam tumi aila na\n",
            "Tokenized Sequence: [10474, 170, 26, 753, 1026, 1087, 28, 720, 49, 10475, 10476, 1097, 13, 3968, 1]\n",
            "\n",
            "\n",
            "Original Comment: din ailo kilvege eo bole ata make\n",
            "Tokenized Sequence: [35, 2007, 10477, 2152, 54, 102, 792]\n",
            "\n",
            "\n",
            "Original Comment: apa apnar paad sungondo ache naki\n",
            "Tokenized Sequence: [603, 22, 10478, 10479, 74, 29]\n",
            "\n",
            "\n",
            "Original Comment: bisri kalo badam!\n",
            "Tokenized Sequence: [1511, 212, 796]\n",
            "\n",
            "\n",
            "Original Comment: kicu pore nai.vitre..?\n",
            "Tokenized Sequence: [270, 62, 5, 10480]\n",
            "\n",
            "\n",
            "Original Comment: ami choke kom dekhi\n",
            "Tokenized Sequence: [4, 2209, 248, 157]\n",
            "\n",
            "\n",
            "Original Comment: mone hochhe ak jama porte bhule geche\n",
            "Tokenized Sequence: [34, 3302, 206, 179, 627, 10481, 635]\n",
            "\n",
            "\n",
            "Original Comment: kalo kalo jnis\n",
            "Tokenized Sequence: [212, 212, 10482]\n",
            "\n",
            "\n",
            "Original Comment: maja nai\n",
            "Tokenized Sequence: [2705, 5]\n",
            "\n",
            "\n",
            "Original Comment: bhitre mama deikha ko\n",
            "Tokenized Sequence: [10483, 625, 482, 1314]\n",
            "\n",
            "\n",
            "Original Comment: kiso nh buja ami\n",
            "Tokenized Sequence: [692, 135, 726, 4]\n",
            "\n",
            "\n",
            "Original Comment: etodin bota dekhe bujlam meye boro hoice\n",
            "Tokenized Sequence: [1003, 1020, 73, 560, 50, 18, 356]\n",
            "\n",
            "\n",
            "Original Comment: eta chilo\n",
            "Tokenized Sequence: [95, 94]\n",
            "\n",
            "\n",
            "Original Comment: noksha dekha fellam apu\n",
            "Tokenized Sequence: [10484, 122, 3581, 19]\n",
            "\n",
            "\n",
            "Original Comment: bsei use hoiche tai kalo hoiche ata kono bepar na\n",
            "Tokenized Sequence: [10485, 403, 759, 40, 212, 759, 102, 27, 684, 1]\n",
            "\n",
            "\n",
            "Original Comment: mask na porlee ja hoi ki\n",
            "Tokenized Sequence: [10486, 1, 10487, 70, 38, 10488]\n",
            "\n",
            "\n",
            "Original Comment: jotoi forsa hou dud kalo takbe\n",
            "Tokenized Sequence: [974, 1900, 1051, 208, 212, 3210]\n",
            "\n",
            "\n",
            "Original Comment: vai tor pata koi\n",
            "Tokenized Sequence: [3, 17, 1863, 93]\n",
            "\n",
            "\n",
            "Original Comment: kalo pakhi deka jai\n",
            "Tokenized Sequence: [212, 1495, 881, 90]\n",
            "\n",
            "\n",
            "Original Comment: dud kalo\n",
            "Tokenized Sequence: [208, 212]\n",
            "\n",
            "\n",
            "Original Comment: hogay pani eshe gece naki tur?\n",
            "Tokenized Sequence: [2239, 394, 2446, 448, 29, 1127]\n",
            "\n",
            "\n",
            "Original Comment: kalo na chocolate color\n",
            "Tokenized Sequence: [212, 1, 10489, 813]\n",
            "\n",
            "\n",
            "Original Comment: bota dekha jai\n",
            "Tokenized Sequence: [1020, 122, 90]\n",
            "\n",
            "\n",
            "Original Comment: ahh tippa dimu\n",
            "Tokenized Sequence: [944, 10490, 630]\n",
            "\n",
            "\n",
            "Original Comment: khaiya boro korso mona?\n",
            "Tokenized Sequence: [776, 18, 1173, 841]\n",
            "\n",
            "\n",
            "Original Comment: boro boro kacha badam\n",
            "Tokenized Sequence: [18, 18, 1359, 796]\n",
            "\n",
            "\n",
            "Original Comment: kalo poysa\n",
            "Tokenized Sequence: [212, 10491]\n",
            "\n",
            "\n",
            "Original Comment: legend hoye bipode aci\n",
            "Tokenized Sequence: [498, 20, 3864, 960]\n",
            "\n",
            "\n",
            "Original Comment: aj kal legend hoye moha muskilei porlam\n",
            "Tokenized Sequence: [123, 753, 498, 20, 10492, 10493, 10494]\n",
            "\n",
            "\n",
            "Original Comment: tar kintu link ace choto belay link ber korsilo\n",
            "Tokenized Sequence: [31, 68, 1154, 207, 129, 3472, 1154, 139, 10495]\n",
            "\n",
            "\n",
            "Original Comment: kala manik\n",
            "Tokenized Sequence: [499, 10496]\n",
            "\n",
            "\n",
            "Original Comment: ami legend na tarpor dekhe felchi\n",
            "Tokenized Sequence: [4, 498, 1, 3788, 73, 10497]\n",
            "\n",
            "\n",
            "Original Comment: veja veja laga kan?\n",
            "Tokenized Sequence: [2459, 2459, 427, 860]\n",
            "\n",
            "\n",
            "Original Comment: kalo badam kalo badam\n",
            "Tokenized Sequence: [212, 796, 212, 796]\n",
            "\n",
            "\n",
            "Original Comment: eto boro keno?\n",
            "Tokenized Sequence: [60, 18, 111]\n",
            "\n",
            "\n",
            "Original Comment: legend na hoye buje gelam\n",
            "Tokenized Sequence: [498, 1, 20, 2045, 439]\n",
            "\n",
            "\n",
            "Original Comment: kala bota dekha jai!\n",
            "Tokenized Sequence: [499, 1020, 122, 90]\n",
            "\n",
            "\n",
            "Original Comment: dosto maya meste hase\n",
            "Tokenized Sequence: [3926, 705, 10498, 2997]\n",
            "\n",
            "\n",
            "Original Comment: bhitore shob kalo\n",
            "Tokenized Sequence: [10499, 127, 212]\n",
            "\n",
            "\n",
            "Original Comment: edit mayre boira dise\n",
            "Tokenized Sequence: [722, 1211, 2490, 205]\n",
            "\n",
            "\n",
            "Original Comment: sabila apu kew char dili na tora\n",
            "Tokenized Sequence: [10500, 19, 142, 990, 2314, 1, 152]\n",
            "\n",
            "\n",
            "Original Comment: bota bheshe uthse\n",
            "Tokenized Sequence: [1020, 10501, 3942]\n",
            "\n",
            "\n",
            "Original Comment: kala kita dekajar\n",
            "Tokenized Sequence: [499, 10502, 10503]\n",
            "\n",
            "\n",
            "Original Comment: oi bokachoda kos\n",
            "Tokenized Sequence: [57, 372, 1272]\n",
            "\n",
            "\n",
            "Original Comment: ami kisu dekhi na sudu kalo dekhi mane andar andar lage\n",
            "Tokenized Sequence: [4, 106, 157, 1, 336, 212, 157, 155, 3973, 3973, 47]\n",
            "\n",
            "\n",
            "Original Comment: eto mota kene?\n",
            "Tokenized Sequence: [60, 214, 10504]\n",
            "\n",
            "\n",
            "Original Comment: badam badam kaca badam\n",
            "Tokenized Sequence: [796, 796, 10505, 796]\n",
            "\n",
            "\n",
            "Original Comment: ami kisu dekhi nai\n",
            "Tokenized Sequence: [4, 106, 157, 5]\n",
            "\n",
            "\n",
            "Original Comment: bota bota\n",
            "Tokenized Sequence: [1020, 1020]\n",
            "\n",
            "\n",
            "Original Comment: acca vai oi tal naki onno kisu bujlam na,\n",
            "Tokenized Sequence: [1460, 3, 57, 3814, 29, 242, 106, 560, 1]\n",
            "\n",
            "\n",
            "Original Comment: ata kono kothaaaa vai\n",
            "Tokenized Sequence: [102, 27, 10506, 3]\n",
            "\n",
            "\n",
            "Original Comment: kola lafaitese deika\n",
            "Tokenized Sequence: [1498, 10507, 3964]\n",
            "\n",
            "\n",
            "Original Comment: vai ami kichu dakinai\n",
            "Tokenized Sequence: [3, 4, 80, 10508]\n",
            "\n",
            "\n",
            "Original Comment: lotion use kore ato kalo ken?\n",
            "Tokenized Sequence: [10509, 403, 2, 43, 212, 146]\n",
            "\n",
            "\n",
            "Original Comment: bra missing ken apu?\n",
            "Tokenized Sequence: [221, 10510, 146, 19]\n",
            "\n",
            "\n",
            "Original Comment: tmr shonay chumu khete chai..gale na\n",
            "Tokenized Sequence: [32, 10511, 3271, 450, 124, 1796, 1]\n",
            "\n",
            "\n",
            "Original Comment: maal maiy naki pola?\n",
            "Tokenized Sequence: [310, 10512, 29, 116]\n",
            "\n",
            "\n",
            "Original Comment: kuttar hoga\n",
            "Tokenized Sequence: [326, 802]\n",
            "\n",
            "\n",
            "Original Comment: bedi chup kor\n",
            "Tokenized Sequence: [783, 1323, 227]\n",
            "\n",
            "\n",
            "Original Comment: vitore thaka talent 40 size dudh amr moto geyainy dr chokhe porbei\n",
            "Tokenized Sequence: [927, 292, 612, 2060, 276, 119, 7, 16, 10513, 747, 1913, 10514]\n",
            "\n",
            "\n",
            "Original Comment: apnak apu na aunty daka drkr\n",
            "Tokenized Sequence: [1438, 19, 1, 1198, 1756, 995]\n",
            "\n",
            "\n",
            "Original Comment: khela ses shonar bangladesh\n",
            "Tokenized Sequence: [130, 225, 3697, 12]\n",
            "\n",
            "\n",
            "Original Comment: apnar dudh khete chai\n",
            "Tokenized Sequence: [22, 119, 450, 124]\n",
            "\n",
            "\n",
            "Original Comment: taka lagle boilo ami dei\n",
            "Tokenized Sequence: [172, 928, 1252, 4, 330]\n",
            "\n",
            "\n",
            "Original Comment: bal marka kotha barta\n",
            "Tokenized Sequence: [48, 325, 10, 10515]\n",
            "\n",
            "\n",
            "Original Comment: tip diye khabe akhn\n",
            "Tokenized Sequence: [929, 49, 930, 151]\n",
            "\n",
            "\n",
            "Original Comment: pic tulso tik ace bt quality amn kn?\n",
            "Tokenized Sequence: [63, 1928, 269, 207, 481, 2493, 213, 239]\n",
            "\n",
            "\n",
            "Original Comment: kom dami magi tui\n",
            "Tokenized Sequence: [248, 3867, 96, 23]\n",
            "\n",
            "\n",
            "Original Comment: kheye diso naki?\n",
            "Tokenized Sequence: [165, 1526, 29]\n",
            "\n",
            "\n",
            "Original Comment: vai cup lagle boilen amk\n",
            "Tokenized Sequence: [3, 1161, 928, 10516, 429]\n",
            "\n",
            "\n",
            "Original Comment: ek kahli ore pai\n",
            "Tokenized Sequence: [125, 2341, 91, 463]\n",
            "\n",
            "\n",
            "Original Comment: haat mara uchit akhn sokoler\n",
            "Tokenized Sequence: [501, 195, 168, 151, 10517]\n",
            "\n",
            "\n",
            "Original Comment: comments on koren vai apnk ektu boki\n",
            "Tokenized Sequence: [1932, 1069, 83, 3, 438, 154, 10518]\n",
            "\n",
            "\n",
            "Original Comment: ekta gaan shunai?\n",
            "Tokenized Sequence: [36, 723, 10519]\n",
            "\n",
            "\n",
            "Original Comment: sala bal pakna.\n",
            "Tokenized Sequence: [159, 48, 1933]\n",
            "\n",
            "\n",
            "Original Comment: evhabe toh vhebe dekhi nai baperta\n",
            "Tokenized Sequence: [2598, 88, 2599, 157, 5, 10520]\n",
            "\n",
            "\n",
            "Original Comment: sob generation gap\n",
            "Tokenized Sequence: [8, 2600, 10521]\n",
            "\n",
            "\n",
            "Original Comment: problem problem na ekta somossha\n",
            "Tokenized Sequence: [433, 433, 1, 36, 10522]\n",
            "\n",
            "\n",
            "Original Comment: kuttar bacchare chud vai\n",
            "Tokenized Sequence: [326, 2601, 2198, 3]\n",
            "\n",
            "\n",
            "Original Comment: ato kharap manush hoy!!\n",
            "Tokenized Sequence: [43, 79, 67, 14]\n",
            "\n",
            "\n",
            "Original Comment: bandir pola\n",
            "Tokenized Sequence: [1531, 116]\n",
            "\n",
            "\n",
            "Original Comment: vhaia tv on kora porjonto ontoto khela chalu rakhen plz\n",
            "Tokenized Sequence: [2602, 872, 1069, 39, 599, 10523, 130, 10524, 1587, 234]\n",
            "\n",
            "\n",
            "Original Comment: bah sundor mittha bollen\n",
            "Tokenized Sequence: [327, 66, 1645, 820]\n",
            "\n",
            "\n",
            "Original Comment: chehara dekhle bujhar upay nai\n",
            "Tokenized Sequence: [667, 332, 10525, 3592, 5]\n",
            "\n",
            "\n",
            "Original Comment: uganda ja vai\n",
            "Tokenized Sequence: [1934, 70, 3]\n",
            "\n",
            "\n",
            "Original Comment: tag marailo kun chudir vai!!!\n",
            "Tokenized Sequence: [829, 2603, 1534, 666, 3]\n",
            "\n",
            "\n",
            "Original Comment: vaii tr pblm kii ??\n",
            "Tokenized Sequence: [1071, 304, 830, 1254]\n",
            "\n",
            "\n",
            "Original Comment: shala valo kore word uccharon kora shikh\n",
            "Tokenized Sequence: [243, 6, 2, 1535, 1936, 39, 2606]\n",
            "\n",
            "\n",
            "Original Comment: poribar theke aisob shikka nite hoy\n",
            "Tokenized Sequence: [2608, 21, 357, 10526, 653, 14]\n",
            "\n",
            "\n",
            "Original Comment: bhai eta kisu hoilo?\n",
            "Tokenized Sequence: [53, 95, 106, 249]\n",
            "\n",
            "\n",
            "Original Comment: vat khaite hobe kno?\n",
            "Tokenized Sequence: [1536, 495, 11, 64]\n",
            "\n",
            "\n",
            "Original Comment: pure khet shala\n",
            "Tokenized Sequence: [1244, 831, 243]\n",
            "\n",
            "\n",
            "Original Comment: arokom kortesen vai?\n",
            "Tokenized Sequence: [1258, 1019, 3]\n",
            "\n",
            "\n",
            "Original Comment: shanto hon vai\n",
            "Tokenized Sequence: [10527, 947, 3]\n",
            "\n",
            "\n",
            "Original Comment: baal di chirba tmi amr\n",
            "Tokenized Sequence: [410, 475, 10528, 69, 7]\n",
            "\n",
            "\n",
            "Original Comment: maiya kew thama vai\n",
            "Tokenized Sequence: [150, 142, 10529, 3]\n",
            "\n",
            "\n",
            "Original Comment: sperm bikri hoy??\n",
            "Tokenized Sequence: [2612, 1074, 14]\n",
            "\n",
            "\n",
            "Original Comment: cringe kheye gelam vai\n",
            "Tokenized Sequence: [1256, 165, 439, 3]\n",
            "\n",
            "\n",
            "Original Comment: hudai etoh kotha\n",
            "Tokenized Sequence: [746, 1938, 10]\n",
            "\n",
            "\n",
            "Original Comment: pet bair hoye gese\n",
            "Tokenized Sequence: [834, 671, 20, 87]\n",
            "\n",
            "\n",
            "Original Comment: mathar chul shob pore jaitese tmr dudh dekhe\n",
            "Tokenized Sequence: [1542, 294, 127, 62, 1268, 32, 119, 73]\n",
            "\n",
            "\n",
            "Original Comment: bolba bolo!\n",
            "Tokenized Sequence: [1530, 526]\n",
            "\n",
            "\n",
            "Original Comment: eishob faizlami baad den\n",
            "Tokenized Sequence: [933, 10530, 745, 148]\n",
            "\n",
            "\n",
            "Original Comment: dekhte bhuut moto!\n",
            "Tokenized Sequence: [112, 10531, 16]\n",
            "\n",
            "\n",
            "Original Comment: zoom korle jail hoye jabe\n",
            "Tokenized Sequence: [1545, 183, 2235, 20, 126]\n",
            "\n",
            "\n",
            "Original Comment: hala malunda\n",
            "Tokenized Sequence: [333, 10532]\n",
            "\n",
            "\n",
            "Original Comment: malu gorur mut khaiya boisha thak vaat lage?\n",
            "Tokenized Sequence: [1077, 1078, 1546, 776, 3420, 550, 3482, 47]\n",
            "\n",
            "\n",
            "Original Comment: tora valo hobi na?\n",
            "Tokenized Sequence: [152, 6, 2294, 1]\n",
            "\n",
            "\n",
            "Original Comment: ekdom tor mtw\n",
            "Tokenized Sequence: [530, 17, 10533]\n",
            "\n",
            "\n",
            "Original Comment: ato kala hoiteso kno din din?\n",
            "Tokenized Sequence: [43, 499, 10534, 64, 35, 35]\n",
            "\n",
            "\n",
            "Original Comment: goru bap pashe naki daan pashe?\n",
            "Tokenized Sequence: [935, 404, 699, 29, 1803, 699]\n",
            "\n",
            "\n",
            "Original Comment: pic j ajk saradin kotobaar dekhlam\n",
            "Tokenized Sequence: [63, 42, 557, 1247, 10535, 278]\n",
            "\n",
            "\n",
            "Original Comment: bichiless halarvai\n",
            "Tokenized Sequence: [10536, 10537]\n",
            "\n",
            "\n",
            "Original Comment: apu naam bolen fb te srch dei\n",
            "Tokenized Sequence: [19, 915, 341, 358, 25, 10538, 330]\n",
            "\n",
            "\n",
            "Original Comment: baal school amr\n",
            "Tokenized Sequence: [410, 821, 7]\n",
            "\n",
            "\n",
            "Original Comment: bangladesh team bolte kisu nai soob maya\n",
            "Tokenized Sequence: [12, 263, 163, 106, 5, 457, 705]\n",
            "\n",
            "\n",
            "Original Comment: baal gula chirbe bangladesh team\n",
            "Tokenized Sequence: [410, 55, 10539, 12, 263]\n",
            "\n",
            "\n",
            "Original Comment: khela baad de khankirpola\n",
            "Tokenized Sequence: [130, 745, 266, 2084]\n",
            "\n",
            "\n",
            "Original Comment: toder moton khankir pola asay bole amra binodon pai\n",
            "Tokenized Sequence: [209, 490, 318, 116, 836, 54, 85, 1041, 463]\n",
            "\n",
            "\n",
            "Original Comment: bujhlam sob kintu apnar jama kapor obostha kn?\n",
            "Tokenized Sequence: [502, 8, 68, 22, 179, 201, 383, 239]\n",
            "\n",
            "\n",
            "Original Comment: unake dekhlei amr voy kore..eto kalaaaa!\n",
            "Tokenized Sequence: [1943, 461, 7, 838, 2, 60, 10540]\n",
            "\n",
            "\n",
            "Original Comment: amar kuttar putki tr theke sada.\n",
            "Tokenized Sequence: [9, 326, 425, 304, 21, 10541]\n",
            "\n",
            "\n",
            "Original Comment: duniya te theke laav bolen\n",
            "Tokenized Sequence: [1805, 25, 21, 1440, 341]\n",
            "\n",
            "\n",
            "Original Comment: bisshas koren apnar video dekhe ami 5 bar haat marsi\n",
            "Tokenized Sequence: [1267, 83, 22, 24, 73, 4, 443, 134, 501, 2136]\n",
            "\n",
            "\n",
            "Original Comment: bangeli dhonsho hobe apndr moto vondo huzur dr jonno.\n",
            "Tokenized Sequence: [2623, 10542, 11, 3915, 16, 1492, 1945, 747, 28]\n",
            "\n",
            "\n",
            "Original Comment: sobai line thaken porimoni sex video link deya hobe\n",
            "Tokenized Sequence: [104, 730, 748, 373, 547, 24, 1154, 567, 11]\n",
            "\n",
            "\n",
            "Original Comment: bangladesh team amdr elakar current ek rokom.\n",
            "Tokenized Sequence: [12, 263, 616, 3936, 1358, 125, 251]\n",
            "\n",
            "\n",
            "Original Comment: mashud hoyto ek tym valo hobe bt amra valo hobo?\n",
            "Tokenized Sequence: [2624, 1123, 125, 2346, 6, 11, 481, 85, 6, 1866]\n",
            "\n",
            "\n",
            "Original Comment: hedar doctor amr\n",
            "Tokenized Sequence: [657, 1947, 7]\n",
            "\n",
            "\n",
            "Original Comment: halay parle fb tei operation koira fele\n",
            "Tokenized Sequence: [10543, 464, 358, 763, 10544, 99, 832]\n",
            "\n",
            "\n",
            "Original Comment: oita nunu naki dildo?\n",
            "Tokenized Sequence: [311, 196, 29, 1949]\n",
            "\n",
            "\n",
            "Original Comment: shala first mone korsilm kantase akhn dekhi acting!\n",
            "Tokenized Sequence: [243, 449, 34, 10545, 10546, 151, 157, 2472]\n",
            "\n",
            "\n",
            "Original Comment: gatimara hoye gelo\n",
            "Tokenized Sequence: [10547, 20, 105]\n",
            "\n",
            "\n",
            "Original Comment: juta maira goru daan koros magi?\n",
            "Tokenized Sequence: [521, 865, 935, 1803, 669, 96]\n",
            "\n",
            "\n",
            "Original Comment: khanki koilo aita?\n",
            "Tokenized Sequence: [285, 2355, 149]\n",
            "\n",
            "\n",
            "Original Comment: ashol khela raat putkimara khela.\n",
            "Tokenized Sequence: [10548, 130, 1026, 10549, 130]\n",
            "\n",
            "\n",
            "Original Comment: hedar pani\n",
            "Tokenized Sequence: [657, 394]\n",
            "\n",
            "\n",
            "Original Comment: magi kew vatican city te patha oine soob purush manush to..ore chudlei thik hoiya jaibo\n",
            "Tokenized Sequence: [96, 142, 10550, 10551, 25, 1621, 2356, 457, 3822, 67, 506, 91, 10552, 61, 232, 874]\n",
            "\n",
            "\n",
            "Original Comment: kahnkir kanki koilo aita\n",
            "Tokenized Sequence: [3460, 713, 2355, 149]\n",
            "\n",
            "\n",
            "Original Comment: ami akhn shck asi j dekhlam!\n",
            "Tokenized Sequence: [4, 151, 10553, 1075, 42, 278]\n",
            "\n",
            "\n",
            "Original Comment: soob magir naam s diya strt hoy?\n",
            "Tokenized Sequence: [457, 363, 915, 2029, 76, 3485, 14]\n",
            "\n",
            "\n",
            "Original Comment: choira halar vai\n",
            "Tokenized Sequence: [10554, 563, 3]\n",
            "\n",
            "\n",
            "Original Comment: madarchood ekat tui\n",
            "Tokenized Sequence: [10555, 10556, 23]\n",
            "\n",
            "\n",
            "Original Comment: jama porso kn?\n",
            "Tokenized Sequence: [179, 1799, 239]\n",
            "\n",
            "\n",
            "Original Comment: soob dekha jaitese jamar niche\n",
            "Tokenized Sequence: [457, 122, 1268, 2329, 509]\n",
            "\n",
            "\n",
            "Original Comment: tmi bascly nengta e!\n",
            "Tokenized Sequence: [69, 10557, 1108, 744]\n",
            "\n",
            "\n",
            "Original Comment: hedar cehara tmr!\n",
            "Tokenized Sequence: [657, 3132, 32]\n",
            "\n",
            "\n",
            "Original Comment: apni jama thik koren age pore fb te post koiren\n",
            "Tokenized Sequence: [15, 179, 61, 83, 71, 62, 358, 25, 110, 1423]\n",
            "\n",
            "\n",
            "Original Comment: nijer fb id dekhe nije chintesi na vai\n",
            "Tokenized Sequence: [147, 358, 1055, 73, 203, 10558, 1, 3]\n",
            "\n",
            "\n",
            "Original Comment: amar bashay dawat roilo apu obosshoi jama khule ashben\n",
            "Tokenized Sequence: [9, 1800, 898, 1452, 19, 10559, 179, 279, 10560]\n",
            "\n",
            "\n",
            "Original Comment: dristy kahli tmr dudh portese sona\n",
            "Tokenized Sequence: [1210, 2341, 32, 119, 3476, 387]\n",
            "\n",
            "\n",
            "Original Comment: kotha kom bol magi\n",
            "Tokenized Sequence: [10, 248, 779, 96]\n",
            "\n",
            "\n",
            "Original Comment: leura kothakar\n",
            "Tokenized Sequence: [2987, 735]\n",
            "\n",
            "\n",
            "Original Comment: hala ekta peshagar\n",
            "Tokenized Sequence: [333, 36, 10561]\n",
            "\n",
            "\n",
            "Original Comment: chudanir pola age mair dite hobe\n",
            "Tokenized Sequence: [10562, 116, 71, 803, 117, 11]\n",
            "\n",
            "\n",
            "Original Comment: kotha kom bol beyadob..tor khahini soob jani\n",
            "Tokenized Sequence: [10, 248, 779, 3240, 17, 3851, 457, 160]\n",
            "\n",
            "\n",
            "Original Comment: tmk chudte chauwa amr mon\n",
            "Tokenized Sequence: [273, 1409, 10563, 7, 84]\n",
            "\n",
            "\n",
            "Original Comment: mod kha haat mar\n",
            "Tokenized Sequence: [593, 663, 501, 487]\n",
            "\n",
            "\n",
            "Original Comment: sohorer prk gula akhn magi para hoye gese.\n",
            "Tokenized Sequence: [10564, 10565, 55, 151, 96, 964, 20, 87]\n",
            "\n",
            "\n",
            "Original Comment: akhn rastaghat patkhet same hoye gese aine magibaji oine magibaji\n",
            "Tokenized Sequence: [151, 10566, 10567, 1459, 20, 87, 10568, 3974, 2356, 3974]\n",
            "\n",
            "\n",
            "Original Comment: apu shoes tag kulo nai keno\n",
            "Tokenized Sequence: [19, 10569, 829, 10570, 5, 111]\n",
            "\n",
            "\n",
            "Original Comment: jutay ekhono tag lagano\n",
            "Tokenized Sequence: [3975, 729, 829, 1420]\n",
            "\n",
            "\n",
            "Original Comment: only bra??? baki dress koi???\n",
            "Tokenized Sequence: [2121, 221, 885, 164, 93]\n",
            "\n",
            "\n",
            "Original Comment: bogoler niche bal kato nai ken?\n",
            "Tokenized Sequence: [10571, 509, 48, 2066, 5, 146]\n",
            "\n",
            "\n",
            "Original Comment: price tag jhule jutay.\n",
            "Tokenized Sequence: [3870, 829, 1176, 3975]\n",
            "\n",
            "\n",
            "Original Comment: use kore iphone, pic dkhle mone hoy symphony...!\n",
            "Tokenized Sequence: [403, 2, 626, 63, 10572, 34, 14, 10573]\n",
            "\n",
            "\n",
            "Original Comment: aita dick dhore rakhar shotik niyom dekhchi\n",
            "Tokenized Sequence: [149, 10574, 734, 1140, 10575, 10576, 2058]\n",
            "\n",
            "\n",
            "Original Comment: inbox aso tomar jaiga baire noi sona\n",
            "Tokenized Sequence: [308, 237, 26, 556, 1262, 943, 387]\n",
            "\n",
            "\n",
            "Original Comment: tumi upore lafiye lafiye lagate valo basle kto engchi bara darkar tomar ???\n",
            "Tokenized Sequence: [13, 853, 1851, 1851, 725, 6, 3816, 982, 3817, 173, 1715, 26]\n",
            "\n",
            "\n",
            "Original Comment: bal khea kono kaj pai nh saradin faltu bol bok kore\n",
            "Tokenized Sequence: [48, 3764, 27, 109, 463, 135, 1247, 416, 779, 10577, 2]\n",
            "\n",
            "\n",
            "Original Comment: taka diye chudea aso fao keu chudte dibe na.\n",
            "Tokenized Sequence: [172, 49, 10578, 237, 10579, 390, 1409, 305, 1]\n",
            "\n",
            "\n",
            "Original Comment: vai amr onek bro hoiche taii\n",
            "Tokenized Sequence: [3, 7, 56, 406, 759, 3282]\n",
            "\n",
            "\n",
            "Original Comment: choda oto soja . chudte chudte amr abostha\n",
            "Tokenized Sequence: [415, 948, 1559, 10580, 1409, 7, 10581]\n",
            "\n",
            "\n",
            "Original Comment: lakh taka diye biye kore jodi thutu use kora hoy thl kichu bolar nei. better choice lubricant..r saper anagona thakle tui korbina\n",
            "Tokenized Sequence: [1540, 172, 49, 267, 2, 98, 10582, 403, 39, 14, 1850, 80, 573, 277, 1253, 10583, 10584, 162, 10585, 10586, 143, 23, 10587]\n",
            "\n",
            "\n",
            "Original Comment: sap jodi taratari na hapay tahole bujhe nio sap daily oi sob rastay jawa asa koreche\n",
            "Tokenized Sequence: [2387, 98, 659, 1, 10588, 113, 843, 2450, 2387, 10589, 57, 8, 890, 1450, 570, 2112]\n",
            "\n",
            "\n",
            "Original Comment: tmr size dekhe monehoy na je tmr boro lagbe. 6 inchi dhuklei holo tmr\n",
            "Tokenized Sequence: [32, 276, 73, 2457, 1, 46, 32, 18, 323, 1159, 10590, 10591, 170, 32]\n",
            "\n",
            "\n",
            "Original Comment: ohhh aiii bepar ami onno kichu vablam\n",
            "Tokenized Sequence: [10592, 10593, 684, 4, 242, 80, 1532]\n",
            "\n",
            "\n",
            "Original Comment: chance dao boudi\n",
            "Tokenized Sequence: [553, 581, 320]\n",
            "\n",
            "\n",
            "Original Comment: eso go sona ami tomake amar lathir oporei bosiye rakhbo\n",
            "Tokenized Sequence: [1146, 137, 387, 4, 339, 9, 10594, 10595, 10596, 3737]\n",
            "\n",
            "\n",
            "Original Comment: amio cheyechilam priyo lathi tmr upor na vitore thak\n",
            "Tokenized Sequence: [238, 10597, 801, 1130, 32, 253, 1, 927, 550]\n",
            "\n",
            "\n",
            "Original Comment: magichuda nstik tormare chuida proman kor tui sottikarer nastik\n",
            "Tokenized Sequence: [10598, 10599, 10600, 1714, 1131, 227, 23, 10601, 589]\n",
            "\n",
            "\n",
            "Original Comment: kathmolla jakir nayeker jutar shoman mullo tor nai\n",
            "Tokenized Sequence: [10602, 10603, 10604, 3076, 3935, 10605, 17, 5]\n",
            "\n",
            "\n",
            "Original Comment: pakistander moto amdr desh thakto taile hindu der dorson kortam\n",
            "Tokenized Sequence: [10606, 16, 616, 97, 769, 312, 89, 44, 10607, 675]\n",
            "\n",
            "\n",
            "Original Comment: ejnnoi tora malaun jati porer vlo sojjo hoa na\n",
            "Tokenized Sequence: [10608, 152, 218, 1718, 1156, 75, 1082, 864, 1]\n",
            "\n",
            "\n",
            "Original Comment: islame borborota sara kisui nai\n",
            "Tokenized Sequence: [1991, 10609, 298, 1467, 5]\n",
            "\n",
            "\n",
            "Original Comment: tomadr bou bon ka ordho nengto kora rastay gurale tomadr debota khushi hoe? sari pora pet pit ber kora rkhla?\n",
            "Tokenized Sequence: [2470, 199, 322, 476, 10610, 2697, 39, 890, 10611, 2470, 3844, 2210, 1004, 1782, 244, 834, 10612, 139, 39, 10613]\n",
            "\n",
            "\n",
            "Original Comment: khanki magi amdr islam nia kono kotha bolbi na\n",
            "Tokenized Sequence: [285, 96, 616, 309, 228, 27, 10, 10614, 1]\n",
            "\n",
            "\n",
            "Original Comment: dormo niropekkhotar name musolman meyeder opoman koto?\n",
            "Tokenized Sequence: [850, 10615, 236, 1337, 431, 600, 33]\n",
            "\n",
            "\n",
            "Original Comment: tdr nobi je 40 bessa bia korse\n",
            "Tokenized Sequence: [10616, 10617, 46, 2060, 1838, 2108, 202]\n",
            "\n",
            "\n",
            "Original Comment: debotar guru brihospoti tar batribodhu momta dhorshon koren\n",
            "Tokenized Sequence: [10618, 3104, 10619, 31, 10620, 10621, 2461, 83]\n",
            "\n",
            "\n",
            "Original Comment: malaun madarchod, pakistan jindbad\n",
            "Tokenized Sequence: [218, 377, 1565, 10622]\n",
            "\n",
            "\n",
            "Original Comment: apni choto khato murkho kafir der sathe kotha blben na\n",
            "Tokenized Sequence: [15, 129, 2445, 3217, 2134, 44, 77, 10, 3715, 1]\n",
            "\n",
            "\n",
            "Original Comment: tui muslim na tui manos na manos\n",
            "Tokenized Sequence: [23, 82, 1, 23, 2400, 1, 2400]\n",
            "\n",
            "\n",
            "Original Comment: kala votka madari\n",
            "Tokenized Sequence: [499, 10623, 10624]\n",
            "\n",
            "\n",
            "Original Comment: dekhte kalaaa tor biya hoibo na\n",
            "Tokenized Sequence: [112, 10625, 17, 366, 454, 1]\n",
            "\n",
            "\n",
            "Original Comment: erum chahara loya gf asha koros\n",
            "Tokenized Sequence: [3862, 10626, 3934, 359, 727, 669]\n",
            "\n",
            "\n",
            "Original Comment: tor ma durga radha bol amake shukh dia jete\n",
            "Tokenized Sequence: [17, 187, 979, 10627, 779, 823, 10628, 252, 1271]\n",
            "\n",
            "\n",
            "Original Comment: tora nun puja korish\n",
            "Tokenized Sequence: [152, 10629, 370, 2607]\n",
            "\n",
            "\n",
            "Original Comment: malaun bachchader dekhle bojha jau malura koto kharap\n",
            "Tokenized Sequence: [218, 10630, 332, 992, 1783, 10631, 33, 79]\n",
            "\n",
            "\n",
            "Original Comment: assa 72 hurera bessa?\n",
            "Tokenized Sequence: [997, 10632, 10633, 1838]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5koIcUvkbAk4"
      },
      "outputs": [],
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(comment_sequences,hate_labels, test_size=0.1, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model=GradientBoostingClassifier(n_estimators=1200, learning_rate=0.2,max_depth=1, random_state=42)\n",
        "model.fit(xtrain,ytrain)\n",
        "model.score(xtest,ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71uh_skFmE24",
        "outputId": "6872d568-ad4f-4f84-e95a-6c1942dbd646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.61"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(xtrain,ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7jb9m6LmEz1",
        "outputId": "f8fbdd5b-9b07-4d94-eb88-f14280e32c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6808421052631579"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=2000, learning_rate=0.03, max_depth=11, random_state=42)\n",
        "xgb_model.fit(xtrain,ytrain)\n",
        "xgb_model.score(xtest,ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SET3U_imExL",
        "outputId": "368be5a0-73c0-46c7-e1c5-2d3a41212af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.632"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the lightgbm model\n",
        "import lightgbm as lgb\n",
        "clf = lgb.LGBMClassifier()\n",
        "clf.fit(xtrain,ytrain)\n",
        "clf.score(xtest,ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2L6wJ23mEuh",
        "outputId": "e11ad1a7-57a1-447c-e41d-75b53c74dbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2556, number of negative: 1944\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4449\n",
            "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 37\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.568000 -> initscore=0.273696\n",
            "[LightGBM] [Info] Start training from score 0.273696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.644"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(xtrain,ytrain)\n",
        "gnb.score(xtest,ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bJAVlWg1JSy",
        "outputId": "f5b60650-d0c2-4e18-8c2f-9900f1a2c9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.558"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "c2aNDYeO4Iz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BXkr_yr5yF9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4eb8c3-bc21-4797-bd03-5b1f927968b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 85, 100)           1063400   \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirect  (None, 85, 1024)          2510848   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirect  (None, 512)               2623488   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6230633 (23.77 MB)\n",
            "Trainable params: 6230633 (23.77 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_diagram.png', show_shapes=True, show_layer_names=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "loJy1NVDG-zS",
        "outputId": "5d7d03cd-9171-4ba5-bd4c-45b9b27cbfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAJzCAYAAACSz21nAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1yUZf4//tfADMyBmeEgAorD0WNQhrIJydeUPpqaoCKKq5WWhm6GeGDNE5qiqx9a5UPBp1SWz66W4ilwU6vVXSIfmVlKKG0KaAIiCinn0wDv3x/9mHVEYEYGBob38/GYP7jua67rfd0H3jP3fd33CIiIwBhjjJkgM2MHwBhjjHUVTnKMMcZMFic5xhhjJouTHGOMMZMlNHYA+ti1axfOnz9v7DAYY6xPO3LkiLFD0Fmv+iZ3/vx5fPvtt8YOg7FWjh49isLCQmOH0aN9++23fPz2coWFhTh69Kixw9BLr/omBwBjxozpVZ8iWN8gEAiwYsUKzJ4929ih9FihoaEAete3AKbt8OHDmDNnjrHD0Euv+ibHGGOM6YOTHGOMMZPFSY4xxpjJ4iTHGGPMZHGSY4wxZrI4yT0hX19fmJubY+TIkQZtd9GiRZDL5RAIBMjMzNS5zqlTp6BUKvH3v//doPHoKiYmBgKBoNXLy8tLr3aMPQ5j6stjb8uSJUu09qf58+e3qnPmzBmsXbsWx44dg7u7u6buK6+80qruxIkTIZfLYW5ujqeeegqXLl3qjmHo7ZNPPoGvry/kcjlcXFywcOFCFBcXa5Z3dLydOHECO3fuRFNTk1a7qampWvX79evXreMyBk5yT+jixYsYP368wdvdt28f9u7dq3cdU/kxCVMZx5Poy2Nvj62tLU6fPo1r164hKSlJa9mmTZsQHx+PdevWISQkBDdu3ICHhwfs7Oxw4MABnDx5Uqv+l19+iSNHjmDatGnIzs6Gj49Pdw5FJykpKZg3bx5CQ0NRWFiItLQ0ZGRkYPLkyWhsbNSpjaCgIIjFYgQGBqKsrExTHhwcjMLCQmRkZGDKlCldNYQehZNcJwkEAmOHAACYOnUqysvLMW3aNKPFsH//fhCR1uvq1at6tWHscdTW1sLf398offflsbdHIpHgpZdewpAhQ2Bpaakp37FjBw4dOoTDhw9DLpdrvSc+Ph5mZmYIDw9HeXl5d4fcKR999BEGDBiAqKgoKJVKjBw5EitXrkRmZiYuXLigqdfR8bZ8+XI888wzmDJliiY5CgQCDBw4EAEBARg8eHC3j80YOMl1kkgkMnibuiTOrkyuRIQjR45gz549XdZHT5WUlIR79+4ZOwyj6E1jz83NxcaNG/Huu+9CLBa3Wu7v74/IyEjcvn0bq1evNkKET66goABOTk5ax/igQYMAALdu3dKrrc2bNyMzMxNxcXEGjbE3Mfkk19TUhOjoaKhUKkgkEjz99NNISUkBAMTFxUEmk8HMzAyjRo2Cg4MDRCIRZDIZfHx8EBAQgEGDBkEsFsPa2hp//OMfW7Wfm5uLYcOGQSaTQSKRICAgAOfOndOpf+C3hBIbG4uhQ4fC0tISSqUSUVFRWn10VOfcuXNQqVQQCAT44IMPAACJiYmQyWSQSqVIS0vD5MmToVAo4OzsjIMHD2rFt337dgwdOhQSiQT9+vWDm5sbtm/f3u1P73jSccTHx0MsFqN///5YsmQJnJycIBaL4e/vr/nkGxERAQsLCzg6Omr6e+uttyCTySAQCFBaWorIyEisWrUKeXl5EAgE8PT07PNj//zzz6FQKLBt27ZuWxe6iI+PBxEhKCiozToxMTEYMmQI9u3bhzNnzrRZj4iwa9cuDB8+HJaWlrCxscH06dPx888/A9DvWGrvWNeVu7t7qw8bLdfj3N3d9WrLxsYG48aNQ1xcXN89HU69yKxZs2jWrFl6vWf16tVkaWlJR48epQcPHtC6devIzMyMLl68SEREmzZtIgB04cIFqq6uptLSUnrppZcIAJ08eZJKSkqourqaIiIiCABlZmZq2g4MDCR3d3e6efMmqdVqunr1Kj333HMkFovp+vXrOvW/fv16EggE9Oc//5kePHhANTU1lJCQQADo8uXLOtcpKCggAPT+++9r4lu/fj0BoLNnz1J5eTndu3ePAgICSCaTUUNDAxERbdu2jczNzSktLY1qamrohx9+IAcHB3rhhRf0Ws9bt24lZ2dnsra2JpFIRK6urhQcHEzfffedXu086TjCw8NJJpPRTz/9RHV1dZSdnU2+vr4kl8spPz+fiIjmzZtHDg4OWv3FxsYSACopKSEiopCQEPLw8NArZiIiAJSSkqL3+x7WE8f+2WefkVwupy1btnRqbERPdvyGh4fTwIEDW5W7u7vTiBEjHvseDw8PunnzJhERffPNN2RmZkaurq5UVVVFRESnT5+m4OBgTf3o6GiysLCg/fv3U1lZGWVlZZGPjw/169ePiouLiUi37dDRsa6r9PR0EolEFB8fTxUVFXT16lUaPnw4TZo0SVNHn+Nt7dq1Wv8rWixfvpzs7Oz0ii0lJYV6Wdogk/4mV1dXh8TERMyYMQMhISGwtrbGhg0bIBKJkJycrFV3xIgRkEqlsLOzw9y5cwEAKpUK/fr1g1Qq1czqavl010Iul8PV1RVCoRBPPfUU9u7di7q6OuzZs6fD/mtra7F79268+OKLWLlyJaytrSGRSGBra6tpX5c6HfH394dCoYC9vT3CwsJQXV2N/Px8AL/Ntho1ahSCgoIgkUjg4+OD4OBgZGRkoKGhQec+XnvtNZw4cQIFBQWoqqrCwYMHkZ+fj3HjxiE7O1vndp50HAAgFAo1n8ZHjBiBxMREVFZWttrWvZGxxj516lRUVFRg48aNnR2CwVRXV+PmzZvw8PDosK6fnx9WrFiBX375Be+8806r5bW1tdi1axdmzpyJ+fPnQ6lUwtvbGx9++CFKS0tbnbJvazvo87+mI+PGjcOaNWsQEREBhUIBLy8vVFZWYt++fZo6+hxvLdferly5olccpsKkk9y1a9dQU1OjNY1dIpHA0dGxVbJ6mIWFBQBozWRqufamVqvb7dPb2xtKpRJZWVkd9p+bm4uamhoEBga22Z4udfTRMraWcdTV1bU6jdHU1ASRSARzc3Od2x00aBCeffZZWFlZwcLCAmPGjNEk8oSEBIPE/rBHx/E4o0ePhlQqbXdb90Z9eewAcO/ePRARpFKpTvVjYmIwdOhQJCQkaF1KAIDs7GxUVVVh9OjRWuW+vr6wsLDQmujxqIe3w5P+r3mc9evXY8+ePTh79iyqqqpw48YN+Pv7w8/PDwUFBQD0O95a1tPdu3f1isNUmHSSq66uBgBs2LBB696QW7duoaampsv6FYlEUKvVHfbf8tMs9vb2bbalS53OmDJlCn744QekpaWhtrYW33//PVJTU/Hyyy/rleQex9vbG+bm5rh+/bqBotWfpaUlSkpKjNa/MZnq2Ovq6gBAa6Zle8RiMZKTkyEQCPD666+jtrZWs6xler2VlVWr91lbW6OyslKnPgz1v+bOnTvYuXMn3nzzTUyYMAEymQxubm7Yu3cvioqKEBsb2+Z72zreJBIJgP+st77GpJNcS2LYvXt3q6m2XfXjq42Njbh//z5UKlWH/bfMCquvr2+zPV3qdMbmzZsxYcIELFiwAAqFAjNnzsTs2bM7vFdPF83NzWhubtb5n5GhqdVqlJWVwdnZ2Sj9G5Mpj73ln/ajNzq3x8/PDytXrkROTg62bt2qKbe2tgaAxyYzfdafof7X5OTkoKmpCQMGDNAqVygUsLW1bffUf1vHW8tlh5b11teYdJJrmRnZ1pNDusK//vUvNDc3w8fHp8P+vby8YGZmhq+++qrN9nSp0xnZ2dnIy8tDSUkJ1Go18vPzkZiYCBsbG73amTRpUquyixcvgojg5+dnqHD1kp6eDiLCmDFjAPx23aqj082mwpTH3r9/fwgEAr3vf9u6dSuGDRuGy5cva8q8vLxgZWWF77//XqvuhQsX0NDQgFGjRunUtqH+17Qk1Tt37miVV1ZW4v79+5pbCfQ53lrWk4ODQ6di661MOsmJxWIsXLgQBw8eRGJiIioqKtDU1ITCwsJWO9GTamhoQHl5ORobG3Hp0iVERETAxcUFCxYs6LB/e3t7zJo1C0ePHkVSUhIqKiqQlZWldbFblzqdsWzZMqhUKlRVVXWqndu3b+PQoUMoKyuDWq3G+fPnsWjRIqhUKixdutQgsXakubkZDx48QGNjI7KyshAZGQmVSoUFCxYAADw9PXH//n2kpqZCrVajpKSk1X1Htra2KCoqwi+//ILKyspekxi6auynT5/ucbcQSKVSuLu76/1L7C2nLR8+DS8Wi7Fq1SocP34cBw4cQEVFBa5cuYKlS5fCyckJ4eHhOrfd0f+asLAwODg4tPsoMTc3N4wfPx579+5FRkYGamtrUVBQoInjjTfeAKDf8daynry9vXVfWaaku6dzdsaTTEGur6+nNWvWkEqlIqFQSPb29hQSEkLZ2dkUFxdHUqmUAJCrqyt9/fXXtGPHDlIqlQSAHBwc6OOPP6ZDhw6Rg4MDASAbGxs6ePAgERElJyfT+PHjqX///iQUCsnOzo7mzp1Lt27d0ql/IqLKykpavHgx2dnZkZWVFY0dO5aio6MJADk7O9OPP/7YYZ3FixeTo6MjASCpVEpBQUGUkJCgGdvgwYMpLy+P9uzZQwqFggCQi4sLXb9+nf75z3+SnZ0dAdC8RCIRDR8+nI4dO6bzel61ahV5eHiQTCYjoVCoiauoqEjnNt5///0nHkd4eDiJRCIaOHAgCYVCUigUNH36dMrLy9O0/+uvv9L48eNJLBaTm5sbvf322xQVFUUAyNPTk/Lz8+nSpUvk4uJCEomExo4dq5lC3hF08haCnjr2U6dOkVwup5iYmCceWwtD3kIQERFBIpGIampqNGXHjx8nDw8PAkD9+vWjZcuWPbbNqKgorVsImpubKTY2lgYPHkwikYhsbGxoxowZdO3aNSIinbdDR8f6jBkzCABFR0e3O+bS0lKKjIwkT09PsrS0JCsrK3r++efp008/1dTR53ibOnUqDRw4kJqbm7XK+8otBL0q2ic5SFj7EhISKDIyUqusvr6eVqxYQZaWllr/RHqy8PBwsrW1NVr/nU1ynWHssevKkEkuJyeHhEIh7d+/31DhdbmmpiYKCAigpKSkbuuztLSUxGIxvffee62W9ZUkZ9KnK1n7iouLERERoTkF0sLCwgIqlQpqtbrXnK4D9JuIYGpMeey1tbX44osvkJOTo5lE4enpiS1btmDLli2dPtXeHZqampCamorKykqEhYV1W7+bN2/GyJEjERERAeC3p7sUFRXh3LlzyM3N7bY4jImTXB8mkUggEomQlJSEu3fvQq1Wo6ioCPv27UN0dDRGjhwJpVL52J/0ePjV0UH7888/d9iGLu2wvun+/fuaBzS//vrrmvK1a9ciNDQUYWFhPf4hzOnp6Th27BhOnz6t8/19nbVr1y5kZmbi1KlTmvt809LSNA9ofvQXGkyWsb9K6oNPVxpeRkYGvfjii6RQKMjc3JyUSiX5+/tTQkICqdVqY4enk7Vr15KFhYXm2uqRI0e6PQYY6XRlTxi7rrrq+P3iiy9ozZo1Bm+3N0tNTaXt27dTY2OjQdvtjacrBUS956mdoaGhAIAjR44YORLGtAkEAqSkpHT7Q617Ez5+e7/Dhw9jzpw5vephz3y6kjHGmMniJMcYY8xkcZJjjDFmsjjJMcYYM1mc5BhjjJmsXje78ujRo8YOgzHG+rRelDYgNHYA+hozZgxWrFhh7DAY0zJnzhxERkYa7RcXeoPdu3cDAB+/vdj58+cRFxdn7DD00uuSnLOzM9+LxHqcOXPmwM/Pj/fNdrTcH8frqHfrbUmOr8kxxhgzWZzkGGOMmSxOcowxxkwWJznGGGMmi5McY4wxk8VJrgt9++23GD58OMzMzCAQCODg4ICYmBhjh4Vjx47B3d1d8ztujo6OmD9/vrHDYqyVJUuWaP3m4OP20zNnzmDt2rWt9utXXnmlVd2JEydCLpfD3NwcTz31FC5dutQdw9DbJ598Al9fX8jlcri4uGDhwoUoLi7WLI+JiXnsbzJ6eXkBAE6cOIGdO3e2+jHd1NRUrfr9+vXr1nEZAye5LjRmzBj8+9//xsSJEwEA165dw4YNG4wcFRASEoIbN27Aw8MDSqUSxcXFOHDggLHDYuyxbG1tcfr0aVy7dg1JSUlayzZt2oT4+HisW7dOa7+2s7PDgQMHWv0w6JdffokjR45g2rRpyM7Oho+PT3cORScpKSmYN28eQkNDUVhYiLS0NGRkZGDy5MlobGzUqY2goCCIxWIEBgairKxMUx4cHIzCwkJkZGRgypQpXTWEHoWTXB9QW1sLf39/Y4fBukBXbtuest9IJBLNL4NbWlpqynfs2IFDhw7h8OHDkMvlWu+Jj4+HmZkZwsPDe/yvhj/qo48+woABAxAVFQWlUomRI0di5cqVyMzMxIULFzT19u/fDyLSel29elWzfPny5XjmmWcwZcoUTXIUCASaXwYfPHhwt4/NGDjJ9QFJSUm4d++escNgXaArt21P3m9yc3OxceNGvPvuuxCLxa2W+/v7IzIyErdv38bq1auNEOGTKygogJOTEwQCgaZs0KBBAIBbt27p1dbmzZuRmZnZ627gNiROckaQmJgImUwGqVSKtLQ0TJ48GQqFAs7Ozjh48CCA3z6JisVi9O/fH0uWLIGTkxPEYjH8/f01n+YiIiJgYWEBR0dHTdtvvfUWZDIZBAIBSktLERkZiVWrViEvLw8CgQCenp56x/v1119jxIgRUCqVEIvF8Pb2xhdffAEAWLRokeb8voeHBy5fvgwAWLhwIaRSKZRKJU6cOIGmpiZER0dDpVJBIpHg6aefRkpKCgDgv//7vyGVSiGXy3Hv3j2sWrUKAwcOxLVr1zq1nnsyIsKuXbswfPhwWFpawsbGBtOnT8fPP/8M4Mm3bVfvN59//jkUCgW2bdvWjWurtfj4eBARgoKC2qwTExODIUOGYN++fThz5kyb9TraFrocrwDa3cf14e7u3urDRcv1OHd3d73asrGxwbhx4xAXF9ernjdpUNSLzJo1i2bNmmXsMPQ2adIkAkAPHjzQlK1fv54A0NmzZ6m8vJzu3btHAQEBJJPJqKGhgYiIwsPDSSaT0U8//UR1dXWUnZ1Nvr6+JJfLKT8/n4iI5s2bRw4ODlr9xcbGEgAqKSkhIqKQkBDy8PBoFZeHhwcplcoO4z9y5Aht3ryZ7t+/T7/++iuNGTOG7OzsNMtDQkLI3Nycbt++rfW+3//+93TixAkiIlq9ejVZWlrS0aNH6cGDB7Ru3ToyMzOjixcvaq2P5cuX0/vvv08zZ86kf//73x3G1lMAoJSUFJ3rR0dHk4WFBe3fv5/KysooKyuLfHx8qF+/flRcXExET75tu3K/+eyzz0gul9OWLVt0HmuLJzl+w8PDaeDAga3K3d3dacSIEY99j4eHB928eZOIiL755hsyMzMjV1dXqqqqIiKi06dPU3BwsKa+LttCl+O1o31cV+np6SQSiSg+Pp4qKiro6tWrNHz4cJo0aZKmztatW8nZ2Zmsra1JJBKRq6srBQcH03fffdeqvbVr1xIAunz5slb58uXLtY5jXaSkpFAvSxvE3+SMzN/fHwqFAvb29ggLC0N1dTXy8/M1y4VCoeYT5ogRI5CYmIjKykokJyd3W4yzZs3Cpk2bYGNjA1tbWwQFBeHXX39FSUkJAGDp0qVoamrSiqmiogIXL17ElClTUFdXh8TERMyYMQMhISGwtrbGhg0bIBKJWo1jx44dWLZsGY4dO4Zhw4Z12xi7U21tLXbt2oWZM2di/vz5UCqV8Pb2xocffojS0lLs2bOn03101X4zdepUVFRUYOPGjZ2O8UlVV1fj5s2b8PDw6LCun58fVqxYgV9++QXvvPNOq+X6bou2jld99vGOjBs3DmvWrEFERAQUCgW8vLxQWVmJffv2aeq89tprOHHiBAoKClBVVYWDBw8iPz8f48aNQ3Z2tlZ7Ldferly5olccpoKTXA9iYWEBAFCr1W3WGT16NKRSqeZUijGIRCIA0ExPnjBhAoYMGYK//OUvmlMihw4dQlhYGMzNzXHt2jXU1NRopjcDv00mcHR0NOo4jCU7OxtVVVUYPXq0Vrmvry8sLCy0JhcYSk/Ybwzl3r17ICJIpVKd6sfExGDo0KFISEjAuXPntJZ1Zls8fLwach9fv3499uzZg7Nnz6Kqqgo3btyAv78//Pz8UFBQAOC3a3TPPvssrKysYGFhgTFjxiA5ORm1tbVISEjQaq9lPd29e1evOEwFJ7leyNLSUvMtqjucPHkSL7zwAuzt7WFpaYk//vGPWssFAgGWLFmCGzdu4OzZswCAv/3tb3jjjTcA/PbJGwA2bNigdY/OrVu3UFNT023j6ClapnRbWVm1WmZtbY3Kysou6be795uuUldXBwBaMy3bIxaLkZycDIFAgNdffx21tbWaZYbaFobax+/cuYOdO3fizTffxIQJEyCTyeDm5oa9e/eiqKgIsbGxbb7X29sb5ubmuH79ula5RCIB8J/11tdwkutl1Go1ysrK4Ozs3KX9ZGRkYPfu3cjPz8eMGTPg6OiICxcuoLy8HDt37mxVf8GCBRCLxdi3bx+uXbsGhUIBFxcXAIC9vT2A335PjB6Z8nz+/PkuHUdPZG1tDQCP/QfaVdu2u/ab7tDyT/vRG53b4+fnh5UrVyInJwdbt27VlBtqWxhqH8/JyUFTUxMGDBigVa5QKGBra9vqVOTDmpub0dzc3Cr5NzQ0APjPeutrOMn1Munp6SAijBkzBsBv117aO735pH744QfIZDJcuXIFarUaf/jDH+Du7g6xWKw1tbmFjY0N5syZg9TUVLz33ntYvHixZtmgQYMgFouRmZlp8Dh7Iy8vL1hZWeH777/XKr9w4QIaGhowatQoAIbdtt2133SH/v37QyAQ6H3/29atWzFs2DDNDGBA923REUPt4y1J9c6dO1rllZWVuH//vuZWgkmTJrV678WLF0FErX64t2U9OTg4dCq23oqTXA/X3NyMBw8eoLGxEVlZWYiMjIRKpcKCBQsAAJ6enrh//z5SU1OhVqtRUlLS6l4aW1tbFBUV4ZdffkFlZWW7/9zUajXu3r2L9PR0yGQyqFQqAL89Oqmurg45OTltXqdYunQp6uvr8dlnn2HatGmacrFYjIULF+LgwYNITExERUUFmpqaUFhY2Opg7gvEYjFWrVqF48eP48CBA6ioqMCVK1ewdOlSODk5ITw8HEDntm1X7TenT582+i0EUqkU7u7uKCws1Ot9Lactzc3Ntcp02Ra6tN3RPh4WFgYHB4d2HyXm5uaG8ePHY+/evcjIyEBtbS0KCgo0cbRcArh9+zYOHTqEsrIyqNVqnD9/HosWLYJKpcLSpUu12mxZT97e3rqvLFNilDmdT6i33ULw7bff0lNPPUVmZmYEgBwdHWnbtm2UkJBAUqmUANDgwYMpLy+P9uzZQwqFggCQi4sLXb9+ncLDw0kkEtHAgQNJKBSSQqGg6dOnU15enqaPX3/9lcaPH09isZjc3Nzo7bffpqioKAJAnp6elJ+fT5cuXSIXFxeSSCQ0duxY+t///V/y8PAgAO2+jh8/TkREa9asIVtbW7K2tqbQ0FD64IMPCAB5eHhopqS3ePbZZ2nt2rWt1kV9fT2tWbOGVCoVCYVCsre3p5CQEMrOzqadO3eSRCIhADRo0CDav39/126YLgA9byFobm6m2NhYGjx4MIlEIrKxsaEZM2bQtWvXNHWeZNsWFxd32X5TXFxMp06dIrlcTjExMXqvI0PeQhAREUEikYhqamo0ZcePH9fs1/369aNly5Y9ts2oqCitWwg62ha6Hq/t7eNERDNmzCAAFB0d3e6YS0tLKTIykjw9PcnS0pKsrKzo+eefp08//VRTZ9WqVeTh4UEymYyEQiE5OzvT4sWLqaioqFV7U6dOpYEDB1Jzc7NWeV+5haBXRdvbklxnhYeHk62trbHD0MuUKVPoxo0bxg6j2+mb5LpST91vDJnkcnJySCgU9qoPRE1NTRQQEEBJSUnd1mdpaSmJxWJ67733Wi3rK0mOT1f2cPpcXDeGh099ZmVlQSwWw83NzYgRMaDn7zf6qK2txRdffIGcnBzNJApPT09s2bIFW7ZsQVVVlZEj7FhTUxNSU1NRWVmJsLCwbut38+bNGDlyJCIiIgD89nSXoqIinDt3Drm5ud0WhzFxkmOdsmbNGuTk5OD69etYuHCh1sw1xgzh/v37mgc0v/7665rytWvXIjQ0FGFhYT3+Iczp6ek4duwYTp8+rfP9fZ21a9cuZGZm4tSpU5p7W9PS0jQPaH70FxpMFSe5HmrdunVITk5GeXk53NzccPToUWOH9FhSqRTDhg3Diy++iM2bN2PEiBHGDqlP6y37ja4+/PBDren4j/4k1LZt2xAREYE//elPRopQN4GBgfj444+1nhfaldLS0lBfX4/09HTY2NhoyqdPn661PktLS7slHmMSEPWep3aGhoYCAI4cOWLkSBjTJhAIkJKSgtmzZxs7lB6Lj9/e7/Dhw5gzZ06vetgzf5NjjDFmsjjJMcYYM1mc5BhjjJksTnKMMcZMltDYAeirsLAQhw8fNnYYjLXSFx82rY+Wx0vx8dt79cZ9vNfNruztU6IZY6y360Vpo3clOcZ6O77VgLHuxdfkGGOMmSxOcowxxkwWJznGGGMmi5McY4wxk8VJjjHGmMniJMcYY8xkcZJjjDFmsjjJMcYYM1mc5BhjjJksTnKMMcZMFic5xhhjJouTHGOMMZPFSY4xxpjJ4iTHGGPMZHGSY4wxZrI4yTHGGDNZnOQYY4yZLE5yjDHGTBYnOcYYYyaLkxxjjDGTxUmOMcaYyeIkxxhjzGRxkmOMMWayOMkxxhgzWZzkGGOMmSxOcowxxkwWJznGGGMmi5McY4wxk8VJjjHGmMniJMcYY8xkcZJjjDFmsjjJMcYYM1mc5BhjjJksobEDYMxU7d27F/fv329VnpaWhlT9wGkAACAASURBVJs3b2qVLVy4EP379++u0BjrMwRERMYOgjFTtGTJEnz00UewtLRss45arYaNjQ2Ki4shFPJnTsYMjU9XMtZF5s6dCwCor69v82Vubo7f//73nOAY6yL8TY6xLkJEGDhwIO7cudNuvW+++QZ+fn7dFBVjfQt/k2OsiwgEAsybNw8WFhZt1hkwYADGjBnTjVEx1rdwkmOsC82dOxcNDQ2PXWZhYYHXXnsNAoGgm6NirO/g05WMdbHBgwcjNzf3scuysrLg7e3dzREx1nfwNznGutj8+fMhEolalXt6enKCY6yLcZJjrIvNnz8fjY2NWmUikQgLFy40UkSM9R18upKxbjBy5EhkZWWh5XATCATIy8uDm5ubkSNjzLTxNznGusGrr74Kc3NzAL8luFGjRnGCY6wbcJJjrBvMnTsXzc3NAABzc3O8+uqrRo6Isb6Bkxxj3cDJyQnPP/88BAIBmpubERoaauyQGOsTOMkx1k1eeeUVEBFeeOEFODo6GjscxvoEk5x4EhoaiqNHjxo7DMYY61VMMB2Y7k/tjBkzBitWrDB2GKyLnD9/HnFxcUhJSTF2KHrZvXs33nzzTchksm7pb86cOYiMjORnY7J2tRxPpshkk5yzszNmz55t7DBYF4qLi+t123js2LEYMGBAt/U3Z84c+Pn59br1xLqfqSY5vibHWDfqzgTHGOMkxxhjzIRxkmOMMWayOMkxxhgzWZzkGGOMmSxOcl3M19cX5ubmGDlypEHbXbRoEeRyOQQCATIzM3Wuc+rUKSiVSvz97383aDy6iomJgUAgaPXy8vIySjzGXh99xZkzZ7B27VocO3YM7u7umu3+yiuvtKo7ceJEyOVymJub46mnnsKlS5eMEHHHPvnkE/j6+kIul8PFxQULFy5EcXGxZnlH+/qJEyewc+dONDU1GWsIfQInuS528eJFjB8/3uDt7tu3D3v37tW7jine7NkZvD663qZNmxAfH49169YhJCQEN27cgIeHB+zs7HDgwAGcPHlSq/6XX36JI0eOYNq0acjOzoaPj4+RIm9bSkoK5s2bh9DQUBQWFiItLQ0ZGRmYPHlyq59VaktQUBDEYjECAwNRVlbWxRH3XZzkuolAIDB2CACAqVOnory8HNOmTTNaDPv37wcRab2uXr1qlFiMvT5qa2vh7+9vlL67w44dO3Do0CEcPnwYcrlca1l8fDzMzMwQHh6O8vJyI0X4ZD766CMMGDAAUVFRUCqVGDlyJFauXInMzExcuHBBU6+jfX358uV45plnMGXKFJ2TI9MPJ7lu8rhfhu4sXRJnVyZXIsKRI0ewZ8+eLuvD1CUlJeHevXvGDqNL5ObmYuPGjXj33XchFotbLff390dkZCRu376N1atXGyHCJ1dQUAAnJyet42vQoEEAgFu3bunV1ubNm5GZmWmyN2MbGye5/19TUxOio6OhUqkgkUjw9NNPax4ZFRcXB5lMBjMzM4waNQoODg4QiUSQyWTw8fFBQEAABg0aBLFYDGtra/zxj39s1X5ubi6GDRsGmUwGiUSCgIAAnDt3Tqf+gd8SSmxsLIYOHQpLS0solUpERUVp9dFRnXPnzkGlUkEgEOCDDz4AACQmJkImk0EqlSItLQ2TJ0+GQqGAs7MzDh48qBXf9u3bMXToUEgkEvTr1w9ubm7Yvn17r32axpOuj/j4eIjFYvTv3x9LliyBk5MTxGIx/P39NZ/iIyIiYGFhofUg5rfeegsymQwCgQClpaWIjIzEqlWrkJeXB4FAAE9PTwDA559/DoVCgW3btnXzGjGs+Ph4EBGCgoLarBMTE4MhQ4Zg3759OHPmTJv1iAi7du3C8OHDYWlpCRsbG0yfPh0///wzAP324/aOM125u7u3+nDScj3O3d1dr7ZsbGwwbtw4xMXF8enzrkAmaNasWTRr1iy93rN69WqytLSko0eP0oMHD2jdunVkZmZGFy9eJCKiTZs2EQC6cOECVVdXU2lpKb300ksEgE6ePEklJSVUXV1NERERBIAyMzM1bQcGBpK7uzvdvHmT1Go1Xb16lZ577jkSi8V0/fp1nfpfv349CQQC+vOf/0wPHjygmpoaSkhIIAB0+fJlnesUFBQQAHr//fc18a1fv54A0NmzZ6m8vJzu3btHAQEBJJPJqKGhgYiItm3bRubm5pSWlkY1NTX0ww8/kIODA73wwgt6reetW7eSs7MzWVtbk0gkIldXVwoODqbvvvtOr3ZSUlLIELvvk66P8PBwkslk9NNPP1FdXR1lZ2eTr68vyeVyys/PJyKiefPmkYODg1Z/sbGxBIBKSkqIiCgkJIQ8PDy06nz22Wckl8tpy5YtnR4fAEpJSel0O0/C3d2dRowY8dhlHh4edPPmTSIi+uabb8jMzIxcXV2pqqqKiIhOnz5NwcHBmvrR0dFkYWFB+/fvp7KyMsrKyiIfHx/q168fFRcXE5Fu262j40xX6enpJBKJKD4+nioqKujq1as0fPhwmjRpkqaOPvv62rVrtY7T7mao46knMslR6ZvkamtrSSqVUlhYmKaspqaGLC0t6Q9/+AMR/SfJVVZWaur89a9/JQB05coVTdl3331HAOjQoUOassDAQHrmmWe0+szKyiIAtHr16g77r6mpIalUSv/1X/+l1cbBgwc1B4YudYja/6deW1urKWtJjrm5uURE5OvrS7/73e+02n7zzTfJzMyM6uvr21u9WvLz8+nSpUtUWVlJ9fX1dP78eXr22WdJIpHQ1atXdW6nO5Jce+sjPDyclEqlVlsXL14kAPTuu+8S0ZMnOUMyVpKrqqoigUBA06ZNe+zyh5McEdGqVasIAC1btoyItJNcTU0NWVlZaR0fRP851lo+DHS03XQ5zvWxYcMGAqB5OTs7U0FBgWa5Pvv6X/7yFwJAf/vb3/SOwxBMOcnx6UoA165dQ01NjdY0dolEAkdHR83pkMexsLAAAK0Lxi3X3tRqdbt9ent7Q6lUIisrq8P+c3NzUVNTg8DAwDbb06WOPlrG1jKOurq6VqdSmpqaIBKJYG5urnO7gwYNwrPPPgsrKytYWFhgzJgxSE5ORm1tLRISEgwSe1d4dH08zujRoyGVStvdZ/qKe/fugYgglUp1qh8TE4OhQ4ciISFB6zQ+AGRnZ6OqqgqjR4/WKvf19YWFhYXWRI9HPbzdnvQ4f5z169djz549OHv2LKqqqnDjxg34+/vDz88PBQUFAPTb11vW0927d/WKg3WMkxyA6upqAMCGDRu07me5desWampquqxfkUgEtVrdYf+FhYUAAHt7+zbb0qVOZ0yZMgU//PAD0tLSUFtbi++//x6pqal4+eWX9Upyj+Pt7Q1zc3Ncv37dQNEaj6WlJUpKSowdhtHV1dUB+G196EIsFiM5ORkCgQCvv/46amtrNctaptdbWVm1ep+1tTUqKyt16sNQx/mdO3ewc+dOvPnmm5gwYQJkMhnc3Nywd+9eFBUVITY2ts33trWvSyQSAP9Zb8xwOMnhP4lh9+7drab7nj9/vkv6bGxsxP3796FSqTrsv2VmWn19fZvt6VKnMzZv3owJEyZgwYIFUCgUmDlzJmbPnt3hvXq6aG5uRnNzs87/EHsqtVqNsrIyODs7GzsUo2v5p63Pjc5+fn5YuXIlcnJysHXrVk25tbU1ADw2memzvg11nOfk5KCpqanVL0ooFArY2toiOzu7zfe2ta83NDQA+M96Y4bDSQ7QzIxs68khXeFf//oXmpub4ePj02H/Xl5eMDMzw1dffdVme7rU6Yzs7Gzk5eWhpKQEarUa+fn5SExMhI2NjV7tTJo0qVXZxYsXQUS9/oc909PTQUQYM2YMAEAoFHZ42tpU9e/fHwKBQO/737Zu3Yphw4bh8uXLmjIvLy9YWVnh+++/16p74cIFNDQ0YNSoUTq1bajjvCWp3rlzR6u8srIS9+/f19xKoM++3rKeHBwcOhUba42THH77FrRw4UIcPHgQiYmJqKioQFNTEwoLC1vtyE+qoaEB5eXlaGxsxKVLlxAREQEXFxcsWLCgw/7t7e0xa9YsHD16FElJSaioqEBWVpbW/Wm61OmMZcuWQaVSoaqqqlPt3L59G4cOHUJZWRnUajXOnz+PRYsWQaVSYenSpQaJtbs0NzfjwYMHaGxsRFZWFiIjI6FSqbBgwQIAgKenJ+7fv4/U1FSo1WqUlJS0uofK1tYWRUVF+OWXX1BZWQm1Wo3Tp0/3+lsIpFIp3N3dNafRddVy2vLhU+BisRirVq3C8ePHceDAAVRUVODKlStYunQpnJycEB4ernPbHR3nYWFhcHBwaPdRYm5ubhg/fjz27t2LjIwM1NbWoqCgQBPHG2+8AUC/fb1lPXl7e+u+sphuun2qSzd4klsI6uvrac2aNaRSqUgoFJK9vT2FhIRQdnY2xcXFkVQqJQDk6upKX3/9Ne3YsYOUSiUBIAcHB/r444/p0KFD5ODgQADIxsaGDh48SEREycnJNH78eOrfvz8JhUKys7OjuXPn0q1bt3Tqn4iosrKSFi9eTHZ2dmRlZUVjx46l6OhozayuH3/8scM6ixcvJkdHRwJAUqmUgoKCKCEhQTO2wYMHU15eHu3Zs4cUCgUBIBcXF7p+/Tr985//JDs7O63ZZCKRiIYPH07Hjh3TeT2vWrWKPDw8SCaTkVAo1MRVVFSk1/YyxGyw999//4nXR3h4OIlEIho4cCAJhUJSKBQ0ffp0ysvL07T/66+/0vjx40ksFpObmxu9/fbbFBUVRQDI09NTM/vOxcWFJBIJjR07loqLi+nUqVMkl8spJiamU+MjMu4tBBERESQSiaimpkZTdvz4cfLw8CAA1K9fP81sykdFRUVp3ULQ3NxMsbGxNHjwYBKJRGRjY0MzZsyga9euERHpvN06Os5mzJhBACg6OrrdsZWWllJkZCR5enqSpaUlWVlZ0fPPP0+ffvqppo4++/rUqVNp4MCB1NzcrPsKNiBTnl1pkqN6kiTH2peQkECRkZFaZfX19bRixQqytLTU+kfWHYx9UIaHh5Otra3R+teVMZNcTk4OCYVC2r9/v1H6fxJNTU0UEBBASUlJ3dZnaWkpicVieu+997qtz0cZ+3jqSny6knWouLgYERERmtMwLSwsLKBSqaBWq/vktSd+enz7PD09sWXLFmzZsqXTp7m7Q1NTE1JTU1FZWYmwsLBu63fz5s0YOXIkIiIiuq3PvoSTHOuQRCKBSCRCUlIS7t69C7VajaKiIuzbtw/R0dEYOXIklErlY39W5OFXd/7jYD3D2rVrERoairCwsB7/EOb09HQcO3YMp0+f1vn+vs7atWsXMjMzcerUqS55vi3jJMd0oFQq8eWXX+Lq1asYMmQIJBIJRowYgeTkZOzYsQMXLlxoNSX7ca9Dhw4ZeygGsW7dOiQnJ6O8vBxubm44evSosUPq0bZt24aIiAj86U9/MnYo7QoMDMTHH3+s9bzRrpSWlob6+nqkp6frPUuZ6U5o7ABY7xAQEIB//OMfxg6jR9i+fTu2b99u7DB6lYkTJ2LixInGDqNHCQ4ORnBwsLHDMHn8TY4xxpjJ4iTHGGPMZHGSY4wxZrI4yTHGGDNZJjvxpLCwEIcPHzZ2GKyLtDxQl7dxx7rqIePMdJjyPiIgMr3fWw8NDeVp3YwxpicTTAeme7py1qxZOt27xa/e+UpJSQEAo8fR018AkJKSYvQ4+NWzXy3Hkyky2STHGGOMcZJjjDFmsjjJMcYYM1mc5BhjjJksTnKMMcZMFic5xhhjJouTXAeOHTsGd3f3dn8nzdXVtdP9+Pr6wtzcHCNHjux80A9ZtGgR5HI5BAIBMjMzda5z6tQpKJVK/P3vfzdoPKz3OHPmDNauXdvqGHjllVda1Z04cSLkcjnMzc3x1FNP4dKlS0aIuGOffPIJfH19IZfL4eLigoULF6K4uFizPCYm5rHHuJeX1xP32dzcjN27d8Pf3/+xy8+dO4fnn38eUqkUTk5OWLNmDerr63Wuc+LECezcuZN/xLcNnOQ6EBISghs3bsDDwwNKpVJzX0ljYyNqampw9+5dg/zA4sWLFzF+/HgDRKxt37592Lt3r951iEzvplCmu02bNiE+Ph7r1q3TOgbs7Oxw4MABnDx5Uqv+l19+iSNHjmDatGnIzs6Gj4+PkSJvW0pKCubNm4fQ0FAUFhYiLS0NGRkZmDx5MhobG7ukz5ycHPy///f/sHLlStTU1LRanp2djYkTJyIwMBAlJSU4fvw4/vKXv2Dp0qU61wkKCoJYLEZgYCDKysq6ZBy9GSe5J2Rubg6JRIL+/ftjyJAhBmtXIBAYrK3OmDp1KsrLyzFt2jRjh9Lj1NbWtvmpvCe3rasdO3bg0KFDOHz4MORyuday+Ph4mJmZITw8vMf/0vejPvroIwwYMABRUVFQKpUYOXIkVq5ciczMTFy4cEFTb//+/a1ulr569are/f3444945513sHTp0jbP0GzduhWOjo549913IZPJ4OfnhzVr1uD//u//8PPPP+tcZ/ny5XjmmWcwZcqULkvYvRUnOQNITU01WFsikchgbbXQJXF2ZXIlIhw5cgR79uzpsj66U1JSEu7du9fr2tZFbm4uNm7ciHfffRdisbjVcn9/f0RGRuL27dtYvXq1ESJ8cgUFBXByctLa1wcNGgQAuHXrlsH7e+aZZ3Ds2DHMmzcPlpaWrZY3Njbi5MmTGDdunFZMkydPBhEhLS1NpzotNm/ejMzMTMTFxRl8LL0ZJzkDiouLg0wmg5mZGUaNGgUHBweIRCLIZDL4+PggICAAgwYNglgshrW1Nf74xz+2aiM3NxfDhg2DTCaDRCJBQEAAzp07p1ne1NSE6OhoqFQqSCQSPP3001qP5CEixMbGYujQobC0tIRSqURUVJRWHx3VOXfuHFQqFQQCAT744AMAQGJiImQyGaRSKdLS0jB58mQoFAo4Ozvj4MGDWvFt374dQ4cOhUQiQb9+/eDm5obt27dj9uzZBlvXT4KIsGvXLgwfPhyWlpawsbHB9OnTNZ+GIyIiYGFhAUdHR8173nrrLchkMggEApSWliIyMhKrVq1CXl4eBAIBPD09ER8fD7FYjP79+2PJkiVwcnKCWCyGv7+/5hvCk7YNAJ9//jkUCgW2bdvW5esoPj4eRISgoKA268TExGDIkCHYt28fzpw502a9jta3PvtUe/u8rtzd3Vt9gGi5Hufu7q53e51148YNVFVVQaVSaZV7eHgAALKysnSq08LGxgbjxo1DXFwcX254GJmgWbNm0axZswzapoeHBymVSq2y5cuX05UrV7TKNm3aRADowoULVF1dTaWlpfTSSy8RADp58iSVlJRQdXU1RUREEADKzMzUvDcwMJDc3d3p5s2bpFar6erVq/Tcc8+RWCym69evExHR6tWrydLSko4ePUoPHjygdevWkZmZGV28eJGIiNavX08CgYD+/Oc/04MHD6impoYSEhIIAF2+fFnnOgUFBQSA3n//fU1869evJwB09uxZKi8vp3v37lFAQADJZDJqaGggIqJt27aRubk5paWlUU1NDf3www/k4OBAL7zwgkG3R0pKCum7+0ZHR5OFhQXt37+fysrKKCsri3x8fKhfv35UXFxMRETz5s0jBwcHrffFxsYSACopKSEiopCQEPLw8NCqEx4eTjKZjH766Seqq6uj7Oxs8vX1JblcTvn5+Z1q+7PPPiO5XE5btmzRa7xERAAoJSVF5/ru7u40YsSIxy7z8PCgmzdvEhHRN998Q2ZmZuTq6kpVVVVERHT69GkKDg7W1NdlfeuyT3W0z+sqPT2dRCIRxcfHU0VFBV29epWGDx9OkyZN0tTZunUrOTs7k7W1NYlEInJ1daXg4GD67rvv9OrrUc899xw988wzWmVfffUVAaDY2NhW9SUSCQUGBupU52Fr167VOo519STHU2/B3+T0UF5erjXj6n/+53/arDtixAhIpVLY2dlh7ty5AACVSoV+/fpBKpVi/vz5AKD5VNtCLpfD1dUVQqEQTz31FPbu3Yu6ujrs2bMHdXV1SExMxIwZMxASEgJra2ts2LABIpEIycnJqK2txe7du/Hiiy9i5cqVsLa2hkQiga2traZ9Xep0xN/fHwqFAvb29ggLC0N1dTXy8/MB/HbqdtSoUQgKCoJEIoGPjw+Cg4ORkZGBhoYGnfswtNraWuzatQszZ87E/PnzoVQq4e3tjQ8//BClpaUGOZUqFAo131pGjBiBxMREVFZWIjk5uVPtTp06FRUVFdi4cWOnY2xPdXU1bt68qfmW0B4/Pz+sWLECv/zyC955551Wy/Vd323tUx3t8/oYN24c1qxZg4iICCgUCnh5eaGyshL79u3T1Hnttddw4sQJFBQUoKqqCgcPHkR+fj7GjRuH7OxsvfrrSMvsSHNz81bLRCIRamtrdarzsMGDBwMArly5YtBYezNOcnp4eHYlEWH58uU6vc/CwgIAtC4It1x7U6vV7b7X29sbSqUSWVlZuHbtGmpqarSmM0skEjg6OuLnn39Gbm4uampqEBgY2GZ7utTRR8vYWsZRV1fX6lRJU1MTRCLRYw/U7pKdnY2qqiqMHj1aq9zX1xcWFhZaEw8MZfTo0ZBKpa0+yPRU9+7dAxHpPFs4JiYGQ4cORUJCgtYpdaBz6/vhfaqjfV4f69evx549e3D27FlUVVXhxo0b8Pf3h5+fHwoKCgD8do3u2WefhZWVFSwsLDBmzBjNB8iEhAS9+utIyzXPx00UaWhogEQi0anOw1q23d27dw0aa2/GSa4T4uLiOnX/jK5EIhHUajWqq6sBABs2bND6Rnnr1i3U1NSgsLAQAGBvb99mW7rU6YwpU6bghx9+QFpaGmpra/H9998jNTUVL7/8slGTXMvUaisrq1bLrK2tUVlZ2SX9WlpaoqSkpEvaNrS6ujoAeOwkiccRi8VITk6GQCDA66+/rvWtwlDru6N9Xld37tzBzp078eabb2LChAmQyWRwc3PD3r17UVRUhNjY2Dbf6+3tDXNzc1y/fl3n/nTRcn22oqJCq7ympgZ1dXVwcnLSqc7DWpJey7ZknOR6vMbGRty/fx8qlUqTmHbv3t1qivP58+c1n/oevZH0YbrU6YzNmzdjwoQJWLBgARQKBWbOnInZs2d3eK9eV7O2tgaAx/5zLSsrg7Ozs8H7VKvVXdZ2V2j5B6nPTcV+fn5YuXIlcnJysHXrVk25odZ3R/u8rnJyctDU1IQBAwZolSsUCtja2rZ7KrK5uRnNzc06J39dubm5QS6Xt5rZmZubCwB4+umndarzsJZLAo9+w+vLOMkZwJ07d7Bw4cIuaftf//oXmpub4ePjo5mZ2daTS7y8vGBmZoavvvqqzfZ0qdMZ2dnZyMvLQ0lJCdRqNfLz85GYmAgbG5su6U9XXl5esLKywvfff69VfuHCBTQ0NGDUqFEAfruu1tEpZF2lp6eDiDBmzBiDt90V+vfvD4FAoPf9b1u3bsWwYcNw+fJlTZmu67sjHe3zumpJqnfu3NEqr6ysxP379zW3EkyaNKnVey9evAgigp+fX6dieJRQKMSUKVOQkZGB5uZmTfnp06chEAgQFBSkU52HtWw7BwcHg8bam3GS6wQiQm1tLY4dOwaFQmGQNhsaGlBeXo7GxkZcunQJERERcHFxwYIFCyAWi7Fw4UIcPHgQiYmJqKioQFNTEwoLC3Hnzh3Y29tj1qxZOHr0KJKSklBRUYGsrCyti/y61OmMZcuWQaVSoaqqyiDtGYpYLMaqVatw/PhxHDhwABUVFbhy5QqWLl0KJycnhIeHAwA8PT1x//59pKamQq1Wo6SkpNWnaFtbWxQVFeGXX35BZWWlJnE1NzfjwYMHaGxsRFZWFiIjI6FSqbBgwYJOtX369OluuYVAKpXC3d1dc0pbVy2nLR8+Ha3r+tal7fb2eQAICwuDg4NDu48Sc3Nzw/jx47F3715kZGSgtrYWBQUFmjjeeOMNAMDt27dx6NAhlJWVQa1W4/z581i0aBFUKpXmCSO69KerjRs34u7du9i0aROqq6tx/vx5xMbGYsGCBRg6dKjOdVq0bDtvb+9Ox2Yyun9CZ9cz5C0Ex48fJw8PDwLQ7mvDhg0UFxdHUqmUAJCrqyt9/fXXtGPHDlIqlQSAHBwc6OOPP6ZDhw6Rg4MDASAbGxs6ePAgERElJyfT+PHjqX///iQUCsnOzo7mzp1Lt27d0sRTX19Pa9asIZVKRUKhkOzt7SkkJISys7OJiKiyspIWL15MdnZ2ZGVlRWPHjqXo6GgCQM7OzvTjjz92WGfx4sXk6OhIAEgqlVJQUBAlJCRoxjZ48GDKy8ujPXv2kEKhIADk4uJC169fp3/+859kZ2entW5EIhENHz6cjh07ZpBtQvRkU56bm5spNjaWBg8eTCKRiGxsbGjGjBl07do1TZ1ff/2Vxo8fT2KxmNzc3Ojtt9+mqKgoAkCenp6Un59Ply5dIhcXF5JIJDR27FgqLi6m8PBwEolENHDgQBIKhaRQKGj69OmUl5fX6bZPnTpFcrmcYmJi9F5P0PMWgoiICBKJRFRTU6Mpe/gY6NevHy1btuyx742KitK6haCj9a3rPtXRPj9jxgwCQNHR0e2OrbS0lCIjI8nT05MsLS3JysqKnn/+efr00081dVatWkUeHh4kk8lIKBRqjoeioiJNHV37O3/+PD3//PPk5OSkORYcHR3J39+fvvrqK029r776in73u9+RpaUlOTk5UVRUFNXV1Wm1pUsdIqKpU6fSwIEDqbm5ud3YHmXKtxCY5Ki64j45ppuEhASKjIzUKquvr6cVK1aQpaWl1j/PzuhpB2V4eDjZ2toaO4xW9E1yOTk5JBQKaf/+/V0YlWE1NTVRQEAAJSUlmWR/uiotLSWxWEzvvfee3u/taceTIfHpSmYwxcXFiIiI0Jz6aWFhYQGVSgW1Iy1lgQAAIABJREFUWt2jr0l1lik8Bd7T0xNbtmzBli1betwp58dpampCamoqKisrERYWZnL96WPz5s0YOXIkIiIijB1Kj8JJjhmMRCKBSCRCUlIS7t69C7VajaKiIuzbtw/R0dEICwsz2LVL1nXWrl2L0NBQhIWF9fiHMKenp+PYsWM4ffq0QX4NpKf1p6tdu3YhMzMTp06d6pLn3/ZmnOSYwSiVSnz55Ze4evUqhgwZAolEghEjRiA5ORk7duzAX//6V2OH2CXWrVuH5ORklJeXw83NDUePHjV2SJ22bds2RERE4E9/+pOxQ2lXYGAgPv74Y61ngppSf7pIS0tDfX090tPTjT6LuScSGjsAZloCAgLwj3/8w9hhdKvt27dj+/btxg7D4CZOnIiJEycaOwzWgeDgYAQHBxs7jB6Lv8kxxhgzWZzkGGOMmSxOcowxxkwWJznGGGMmy2Qnnnz77bcIDQ01dhisi7Q8voi3ccd2796NI0eOGDsM1oPp+yi33kRAZHq/k75r1y69nlDOWHc5e/YsvLy8+AG6rEcyxQ9DJpnkGOupBAIBUlJSMHv2bGOHwlifwNfkGGOMmSxOcowxxkwWJznGGGMmi5McY4wxk8VJjjHGmMniJMcYY8xkcZJjjDFmsjjJMcYYM1mc5BhjjJksTnKMMcZMFic5xhhjJouTHGOMMZPFSY4xxpjJ4iTHGGPMZHGSY4wxZrI4yTHGGDNZnOQYY4yZLE5yjDHGTBYnOcYYYyaLkxxjjDGTxUmOMcaYyeIkxxhjzGRxkmOMMWayOMkxxhgzWZzkGGOMmSxOcowxxkwWJznGGGMmi5McY4wxk8VJjjHGmMniJMcYY8xkcZJjjDFmsjjJMcYYM1mc5BhjjJksARGRsYNgzBS9+uqruHz5slZZQUEB7OzsIJVKNWUikQifffYZBgwY0N0hMmbyhMYOgDFTNXToUOzfv79VeXl5udbfI0aM4ATHWBfh05WMdZH58+dDIBC0W0ckEmHBggXdExBjfRAnOca6iIuLC3x8fNpNdI2NjQgNDe3GqBjrWzjJMdaFXn31VZibmz92mZmZGcaMGQNXV9fuDYqxPoSTHGNdKCwsDM3NzY9dZmZmhldffbWbI2Ksb+Ekx1gX6t+/P8aNG/fYb3NEhJkzZxohKsb6Dk5yjHWxV155BY/eqWNubo4XX3wR/fv3N1JUjPUNnOQY62IhISEQCrXv1iEizJ8/30gRMdZ3cJJjrIspFApMnjxZK9EJhUIEBQUZMSrG+gZOcox1g/nz56OpqQnAbwkuODgYCoXCyFExZvo4yTHWDV5++WXNo7yampowb948I0fEWN/ASY6xbiAWixESEgIAkMlkeOmll4wcEWN9Q6tnVxYWFuKbb74xRiyMmTRnZ2cAgK+vL9LS0owcDWOmZ9CgQfDz89MupEekpKQQAH7xi1/84he/etVr1qxZj6Y0avNXCPgXeBjrnJZnUh45ckRTtm3bNrzzzjttPuqrrzl8+DDmzJnD/29Yp7X1DFi+JsdYN1qzZg0nOMa6ESc5xrrRozeFM8a6Fic5xhhjJouTHGOMMZPFSY4xxpjJ4iTHGGPs/2PvTKOiurK+/y+gqIkqZgFRZHJCUaOSCGpoJI+JMUFBjaQx3bGjIZo0EhGJoGgEowQDBMUYh2Y9r6ZxwmjikLg0AWMkxrTSICrijKIyyVgg034/uOo+FlRBAQWFlfNbiw+cae977t5n3zr3nHP1lm4HOQ8PDxgaGmLMmDHtljt27BhMTU3x/fffqy2zYMECSKVS8Hg8ZGdna1yvJ9GV/I0bN6Jfv37g8XjYunVrl9poaWlBYmIivLy8VOafOXMGEydOhFgshp2dHSIiIvDkyROVZU+ePIkVK1ZoRa/epDt98N133yEuLo47c1IX6Nr+nzcUdpqeng5nZ2fweDzweDy88847bcpOnToVUqkUhoaGGDFiBC5cuKADjTvm3//+Nzw8PCCVSjFo0CDMnz8fDx8+5PJjY2O563z2b+TIkV2WqY2xo6/4VreD3Pnz5+Hj49NhOU32wezYsQPbt2/vdL2eRFfyly1b1q2TZwoKCvDyyy9j6dKlkMvlbfLz8vIwdepU+Pr6oqSkBAcPHsS//vUvLFq0qE3Z1atXIzk5GZGRkd3Wqzfpbh/4+flBKBTC19cXFRUVva0+AN3b//PEs3Y6a9Ys3Lx5Ey4uLrC0tMTu3btx9OhRpfInTpzA/v378eabbyIvLw9jx47Vkebq2bt3L4KCgjBnzhzcu3cPhw8fxunTpzFt2jQ0NTX1iExtjB19yrfUnXjSGXx9fWnMmDGdqqOOtLQ0AkAXL17USnudQS6Xk6enZ6/LVUdBQQEBoK+++qpT9bKzsykgIIB2795NY8aModGjR7cpM3fuXHJycqKWlhYuLT4+nng8Hl25coVLW79+PQ0ZMoTq6uq6rJcu+lWbfRASEkKenp7U2NjYKR1mz56t8gSG54mevnddGW9UocpOiYhcXFzom2++IQMDA7K3t6eKigql/OPHj9OMGTO6Lb+n8PHxof79+yvZ6ObNmwkAnTlzhoiIYmJiaNeuXVqRpy2/6WnfUoU6f9PaOzk+n6+Vdng8nlba6Qo7d+5EcXGxzuRri9GjRyM9PR1BQUEQCARt8puamnD06FF4e3sr9fe0adNARNy5itevX8eqVavw6aefQigUdlkfXfSrtvoAANasWYPs7GwkJSX1iu59iefBJzqyUy8vL4SGhuL+/ftYtmyZDjTsOoWFhbCzs1Oy0YEDBwIA7ty5o3V52vCbvuZbWgty169fx7BhwyCRSCASiTB58mScOXMGwNO5WQcHB/B4PGzevJmrQ0SIj4/H0KFDIRAIYGpqivDwcC5fVb3PP/8cYrEYUqkUxcXFCAsLg729PfLz89Hc3Izo6Gg4ODhAJBJh1KhR2Lt3r5Keu3btwvjx4yEUCiGRSODo6IiYmBiEhoYiLCwMN27cAI/Hg6ura7t6JyQkYPjw4RAIBDA3N8fMmTNx9epVAMCWLVsgkUggFotx+PBhTJs2DTKZDAMGDEBaWhrXzi+//AI3NzeYmppCKBTC3d0dP/74o7ZuiVpu3ryJmpoaODg4KKW7uLgAAHJycgAAycnJICKNPu6ZmZmJF198EWKxGDKZDO7u7qiqqlLZr0lJSZBIJDAwMMC4ceNgY2MDPp8PiUSCsWPHYvLkyRg4cCCEQiHMzMywfPlynfUBAJibm8Pb2xtJSUm9On2oyv40sa3k5GQIhUL069cPH3zwAezs7CAUCuHl5YVz584BAEJCQmBsbAxbW1tO3ocffgiJRAIej4fS0lKV9w4AfvjhB8hkMqxbt67X+qI9NLHT2NhYDBkyBDt27MDJkyfVltOWb2syFmmCs7Nzm4cMxfs4Z2fnTrfXXTTxmz7nW61/2nV1utLZ2Zlu3bpFjY2NdOnSJXrppZdIKBTStWvXiIiosLCQANCmTZu4elFRUcTj8eiLL76gx48fk1wup5SUFKXpSnX1ANCSJUto06ZNFBAQQFeuXKFly5aRQCCgAwcO0OPHjykyMpIMDAzo/PnzRESUmJhIAGj9+vVUVlZG5eXl9PXXX1NQUBAREc2aNYtcXFyUrk2V/OjoaDI2NqZdu3ZRRUUF5eTk0NixY8nKyooePnyopOOpU6eosrKSiouLafLkySSRSKihoYGIiPbv309r1qyh8vJyKisrowkTJpClpSUnp6vTlc/y0ksvtZlyyMzMJAAUHx/fprxIJCJfX18iInJ2diY3N7c2ZVrrVVNTQzKZjOLi4qiuro4ePnxIAQEBVFJSQkSq+3X16tUEgM6dO0e1tbVUWlpKr732GgGgo0ePUklJCdXW1lJISAgBoOzsbJ30gYIVK1Z0ehpdG9OV7dl/e7YVHBxMEomELl++TPX19ZSXl0ceHh4klUrp7t27REQUFBRENjY2SvLi4+MJQLv37siRIySVSmnt2rXdujYi7UxXqrNToqfTlbdu3SIiorNnz5KBgQE5OjpSTU0NEbWdrtSWb3c0FmlKRkYG8fl8Sk5OpqqqKrp06RINHz6cXn31Va5MTEwMDRgwgMzMzIjP55OjoyPNmDGDfv/9907Jak1X/aY3fEsVPT5dKZVK4ejoCCMjI4wYMQLbt29HfX09tm3bprJ8XV0dEhMT8corr2Dp0qUwMzODSCSChYWFxjI3bNiAjz76COnp6XB0dMSWLVvg7++PWbNmwczMDCtXrgSfz0dqaioaGxvx6aefwsfHB5988gksLCxgbm6O9957Dx4eHhrLrKurQ0JCAgICAjBv3jyYmprC3d0dW7duRWlpaZvr9fLygkwmg7W1NQIDA1FbW4u7d+8CAGbPno3Vq1fD3NwcFhYW8PPzQ1lZGUpKSjTWpysoVjipOkORz+ejrq4OtbW1uHXrFvf01R63b99GVVUVRowYAaFQCBsbG6Snp8PKyqrDum5ubhCLxbC0tMTbb78NAHBwcICVlRXEYjHmzZsHANyTtLbQpA+eZfDgwQCA3NxcrerRHdqzLeDpEWKKXyRubm7YsmULqqurkZqa2i2506dPR1VVFVatWtXdS+g2nbFTT09PfPzxx7h9+zY++eSTNvna8u36+vp2x6LO4O3tjYiICISEhEAmk2HkyJGorq7Gjh07uDJ///vf8d1336GwsBA1NTVIS0vD3bt34e3tjby8vE7J6whN/Kav+VaP7ZNzd3eHqamp0k/TZ7l+/Trkcjl8fX21Ii8/Px9yuVxp2axIJIKtrS2uXr2KnJwcVFRU4NVXX1WqZ2hoiCVLlmgsJy8vDzU1NRg/frxSuoeHB4yNjbnpIFUYGxsDABobG1XmK95r9vSyWsV7C1WrsxoaGiASiVBcXAwi4r5m3R7Ozs7o168f5s2bhzVr1uD27dtd0kvRP8/qpegTdX3WVTTpg2dR9MOjR4+0qoe26Mi2AGD8+PEQi8Vaf2DQJZ2xU+DptOXQoUORkpLCvU5RoC3f7mgs6gxRUVHYtm0bTp06hZqaGty8eRNeXl7w9PREYWEhgKfv6F544QWYmJjA2NgYEyZMQGpqKurq6pCSktIpeR2hid/0Nd/q0c3gfD5frdPdu3cPAGBtba0VWbW1tQCAlStXKu0VuXPnDuRyOaqqqgAAZmZm3ZKjWO5qYmLSJs/MzAzV1dUat3X06FH85S9/gbW1NQQCQY+8e1KF4j2Mok8UyOVy1NfXw87ODvX19QCg8uVza0QiEX766SdMmjQJ69atg7OzMwIDA9s8sfUlNOmDZ1E4pqJfnlcEAkGPzxT0Jp2xU+DpIJ2amgoej4d//OMfSjaqLd/uaCzSlAcPHiAuLg7vv/8+pkyZAolEAicnJ2zfvh1FRUWIj49XW9fd3R2Ghoa4du2axvI0QRO/6Wu+1WNBrqmpCeXl5W1ePipQRHt1m487iyJYJiYmgoiU/rKystC/f38AQGlpabfkKIKkKoOvqKjgvv7cEXfv3oW/vz9sbW1x7tw5VFZWIi4urlu6aYqTkxOkUmmb1VnXr18HAIwaNYozPE1/VY4YMQLff/89ioqKEBERgb1792Ljxo3aVVyLaNIHz9LQ0AAAbZ5CnycaGxs7ZaPPA521U+DptOXSpUtRUFCAmJgYLl1bvt3RWKQpBQUFaG5u5sYuBTKZDBYWFu1ORba0tKClpUXj4K8pmvhNX/OtHgtyP//8M1paWtRusBw5ciQMDAyQmZmpFXmK1XiKk1Ja4+joCAsLC5w4caJbckaOHAkTExP88ccfSunnzp1DQ0MDxo0bp1E7ubm5aGxsxOLFi+Hs7AyhUNhr2yeMjIzw+uuv4/Tp02hpaeHSjx8/Dh6PBz8/P+5Uk8rKyg7bKyoqwuXLlwE8dfD169dj7NixXFpfRJM+eBZFP9jY2PSqntokIyMDRIQJEyYAeNoH2p4G7m06Y6fPEhMTg2HDhuHixYtcmrZ8u6OxSFMUQfXBgwdK6dXV1SgvL+e2ErR+BQM8PaSDiODp6dktHVqjid/0Nd/SWpBraGhAZWUlmpqacOHCBYSEhGDQoEF49913VZa3trbG7NmzceDAAezcuRNVVVXIyclRu1ClI4RCIebPn4+0tDRs2bIFVVVVaG5uxr179/DgwQMIBAJERkbi9OnTCAkJwf3799HS0oLq6mpuMLawsEBRURFu376N6upqlQOAUChEWFgYDh48iN27d6Oqqgq5ublYtGgR7OzsEBwcrJG+il+4J0+eRH19PQoKCtqd89c2q1atwqNHj7B69WrU1tYiKysL8fHxePfddzF06FCIxWI4Oztz08rtUVRUhA8++ABXr15FQ0MDLl68iDt37nCDqSb9qgs66oNnUfSDu7u7LlTtEi0tLXj8+DGampqQk5OD0NBQODg4cD7p6uqK8vJyHDp0CI2NjSgpKWnz9K3q3h0/frzPbCHojJ0+i2La8tnFEdry7Y7GIgAIDAyEjY1Nu0eJOTk5wcfHB9u3b8fp06dRV1eHwsJCTo/33nsPAHD//n3s2bMHFRUVaGxsRFZWFhYsWAAHBwfuhBFN5GmKJn7Tp3yr9XLLrizpTU1NJR8fH+rXrx8ZGRmRpaUlvf3223Tnzh0iItq0aRPZ2toSABKLxeTn50dERNXV1bRw4UKytLQkExMTmjRpEkVHRxMAGjBgAC1cuLBNvbi4OBKJRASABg4cqLTT/8mTJxQREUEODg5kZGRE1tbWNGvWLMrLy+PKbN68mdzd3UkoFJJQKKQXXniBUlJSiIjowoULNGjQIBKJRDRp0iRauXKlSr1bWlooPj6eBg8eTHw+n8zNzcnf35/y8/OJiCglJYXEYjEBoMGDB9ONGzdo27ZtJJPJCAANGjSIrl27RhEREWRhYUFmZmY0Z84c7iQDFxcXCg0NJRsbGwJAEomEAgICNL4fWVlZNHHiRLKzsyMABIBsbW3Jy8uLMjMzuXKZmZn04osvkkAgIDs7OwoPD6f6+nouPyQkhPh8Psnlci7tiy++aKPX7du3ycvLi8zNzcnQ0JD69+9PUVFR1NTUpLJfV6xYwfWPo6Mj/fLLL7RhwwYyNTUlAGRjY0PffPMN7dmzh5Nlbm5OaWlpvd4HCqZPn0729vZKJzh0RHe3EKjyG01tKzg4mPh8Ptnb25ORkRHJZDKaOXMm3bhxg2u/rKyMfHx8SCgUkpOTE/3zn/+k8PBwAkCurq509+7dNvfu4cOHdOzYMZJKpRQbG9vla1OgjS0Equz04MGD5OLiQgDIysqKPvroI5V1w8PDlbYQaMu3OxqL/P39CQBFR0e3e22lpaUUGhpKrq6uJBAIyMTEhCZOnEjffvstVyYsLIxcXFxIIpGQkZERN3YWFRVxZTSVp02/6UnfUoU6f9NKkGPoJwUFBWRkZKS1I4OeV0pLS0koFNLGjRs7VU+Xx3oFBweThYWFTmR3Bm2MN8+jnTY3N9PkyZNp586deilPU7rqW6ro8X1yDP3D1dUVa9euxdq1a1FTU6NrdXTGmjVrMGbMGISEhOhalU6hy68n9CbPm502Nzfj0KFDqK6uRmBgoN7J6wy94VssyD0nXL16VeXnNFr/aduIV6xYgTlz5iAwMLDTL/e1jS76ICEhAdnZ2Th27JjWzmdlaJ++ZKcdkZGRgfT0dBw/flzj/X3PkzxN6S3fMuqxlhlaZdiwYTr77Mq6detw4sQJrF+/Hhs2bNCJDkDv98Hhw4fx5MkTZGRkqDy9oa8SGRmJ1NRUNDQ0wMnJCfHx8Zg9e7au1epx+oqddoSvr6/WDsHoi/I0oTd9i0etRo19+/Zh7ty57DtWDEY3mTNnDgBg//79Otak78LGG4a2UOdvbLqSwWAwGHoLC3IMBoPB0FtYkGMwGAyG3sKCHIPBYDD0FrWrKxUv8RgMRtf47bffADBfag/FkU6sjxjd5bfffuOOEnwW9kuOwWAwGHqL2l9ybNkzg9E92BaCjlFsIWB9xOgu6mYD2C85BoPBYOgtLMgxGAwGQ29hQY7BYDAYegsLcgwGg8HQW1iQYzAYDIbe0ieCXHp6Opydndt8MsXIyAhWVlZ45ZVXcPDgQaU6x44dg6mpKb7//nu17S5YsABSqRQ8Hg/Z2dka1+tJdCV/48aN6NevH3g8HrZu3aqyzMmTJ7FixYo298PW1hbz5s1rt/3//ve/CAwMhJOTEwQCAaysrDB69GjExsYCAAIDAzX6TA6Px8P8+fOV5K9atapd2QkJCeDxeDAwMMCwYcNw+vRpfPfdd4iLi/vTfFPtz4o6m33nnXfalJ06dSqkUikMDQ0xYsQIXLhwQQcad8y///1veHh4QCqVYtCgQZg/fz4ePnzI5cfGxqr0m5EjR3ZZZktLCxITE+Hl5aUy/8yZM5g4cSLEYjHs7OwQERGBJ0+ecPlr166Fm5sbZDIZBAIBXF1dsXz58na/71dfX49hw4Zh5cqVANBzPtv6K6q6/DK4i4sLmZqacv+Xl5fTyZMnadiwYQSA9uzZw+UdOXKEZDIZfffdd+22mZaWRgDo4sWLnarXU+hSfkFBAQGgr776qk1edHQ0vfnmm1RVVcWltb4f6sjJySGxWExLliyhW7duUV1dHeXn59Py5cvJ19eXiIjmzp1LJ06coIqKCmpsbKQHDx4QAPLz86OGhgaqra2l4uJiWrhwIX3//fecfABka2tLDQ0NKmU3NTXRoEGDCAAnS0FSUhJ5e3vT48ePNe4jbaLLL4M/L3RnvFFns5aWlgSAjhw50qbO8ePHacaMGV3Wt6fZs2cPAaC4uDiqqKigixcvkrOzM40ZM4YaGxuJiCgmJoYAtPkbMWJEl2Reu3aNJk6cSABo9OjRbfIvXbpEIpGIVq1aRTU1NXT27FmysrKi+fPnc2W8vb0pJSWFysrKqKqqivbu3Ut8Pp9ee+01tXKXLl1KACgqKopL647PqvO3Ph3kFPz4448EgAICAjrdZusg15vI5XLy9PTsdbnqUBfk1q9fT0OGDKG6ujqldE2D3N/+9jfq379/m/QnT57QG2+8QUREgYGBVFtby+UpglzrAWfr1q1KQW7cuHEEgPbt26dS9t69e8nLy0tlkCMiCgkJIU9PT26A6E10GeR60va02XZXx5v2bPabb74hAwMDsre3p4qKCqX8vh7kfHx8qH///tTS0sKlbd68mQDQmTNniOhpkNu1a5dW5GVnZ1NAQADt3r2bxowZozLIzZ07l5ycnJR0io+PJx6PR1euXCEiounTp1NTU5NSvbfeeosA0N27d9u0+euvv9LUqVPbBDmirvusOn/rE9OVHeHo6AgAqKio6HRdHo+nZW00Z+fOnSguLtaZfE24fv06Vq1ahU8//RRCobBLbZSVlaGyshLl5eVK6cbGxty0bFpamkZfJQ4ODsYbb7zB/b948WIAwFdffaWyfEJCAsLCwtS2t2bNGmRnZyMpKalD2fpET9qeru26I5v18vJCaGgo7t+/j2XLlulAw65TWFgIOzs7pXFr4MCBAIA7d+5oXd7o0aORnp6OoKAgCASCNvlNTU04evQovL29lXSaNm0aiAiHDx8GABw5cqTNx0+trKwAAHK5XCm9rq4O4eHhan1S2z77XAS5nJwcAIC3tzeAp/PDDg4O4PF42Lx5M1eOiBAfH4+hQ4dCIBDA1NQU4eHhXL6qep9//jnEYjGkUimKi4sRFhYGe3t75Ofno7m5GdHR0XBwcIBIJMKoUaOwd+9eJd127dqF8ePHQygUQiKRwNHRETExMQgNDUVYWBhu3LgBHo8HV1fXdvVOSEjA8OHDIRAIYG5ujpkzZ+Lq1asAgC1btkAikUAsFuPw4cOYNm0aZDIZBgwYgLS0NK6dX375BW5ubjA1NYVQKIS7uzt+/PHHdvs2OTkZRAQ/P7+u3BoAgIeHB2prazFlyhT8+uuvXW5HFVOmTMHw4cPx888/Iz8/Xynv119/hVwux9SpU9XWNzc3h7e3N5KSkp6LD3N2ZAshISEwNjaGra0tV+fDDz+ERCIBj8dDaWmpSttLTk6GUChEv3798MEHH8DOzg5CoRBeXl44d+5ct9oGgB9++AEymQzr1q3r8T7SxGZjY2MxZMgQ7NixAydPnlRbTlu+p8lYoQnOzs5tHiAU7+OcnZ073V53uXnzJmpqauDg4KCU7uLiAuD/xmZV3L9/HyKRCE5OTkrpUVFR+PDDD2Ftba2yntZ9tvVPu740XSmXy+n48eM0aNAgmjp1KtXU1HB5hYWFBIA2bdrEpUVFRRGPx6MvvviCHj9+THK5nFJSUpSmK9XVA0BLliyhTZs2UUBAAF25coWWLVtGAoGADhw4QI8fP6bIyEgyMDCg8+fPExFRYmIiAaD169dTWVkZlZeX09dff01BQUFERDRr1ixycXFRukZV8qOjo8nY2Jh27dpFFRUVlJOTQ2PHjiUrKyt6+PChko6nTp2iyspKKi4upsmTJ5NEIuHeV+3fv5/WrFlD5eXlVFZWRhMmTCBLS0tOjqrpSmdnZ3Jzc9PofqhDLpfT+PHjuXcDbm5uFBcXR2VlZWrrqJuubC3/1q1b9OWXXxIACg0NVcr39/en1NRUqq6uVjtdSUS0YsUKnUxZd2W6UhNbCAoKIhsbG6V68fHxBIBKSkqISLXtBQcHk0QiocuXL1N9fT3l5eWRh4cHSaVSbkqpq20fOXKEpFIprV27tlPX25XxpiObvXXrFhERnT17lgwMDMjR0ZEbO1pPV2rL9zoaKzQlIyOD+Hw+JScnU1VVFV26dImGDx9Or776KlcmJiaGBgwYQGZmZsTn88nR0ZFmzJhBv//+e6dkteall15qM12ZmZlJACg+Pr5NeZFIpNbnamtrSSqVUkhIiFL6mTNnyM/Pj4iISkpKVE5XEnXNZ5+bd3KKgfLZP3d3d/rf//1fevLkCVe2dbCQy+UkFovpf/7nf5TabP1Orr0g9+z8fl1dHYnFYgqo3dAuAAAgAElEQVQMDOTS5HI5CQQCWrx4MTU0NJCZmRn5+PgoyWtqaqKkpCQi0izIyeVyMjExUZJDRPT7778TAG7QUKWjIoBfv35dZX9+9tlnBICKi4uJqG2Qq6mpIR6PR2+++abK+poGOSKihoYG+vLLL7lFQgCoX79+lJGRobJ8Z4JcRUUFSSQSMjc3J7lcTkREN27coAEDBtCTJ086DHL/+te/CAD9v//3/zS6Fm3R2SCnqS10J8i1vp/nz58nAPTpp592q+2u0tnxRhObVQQ5IqKwsDACQB999BERKQc5bfleR2NFZ1m5cqXS+DdgwAAqLCzk8u/evUsXLlyg6upqevLkCWVlZdELL7xAIpGILl261Gl5ClQFuRMnThAASkhIaFNeJpORl5eXyraioqJoyJAhSouCFA/D9+7dI6L2g1xXfPa5eSdnamoKehp80djYiHv37uHjjz9GSEgIRo0ahdLSUpX1rl+/DrlcDl9fX63okZ+fD7lcrrQsVyQSwdbWFlevXkVOTg4qKirw6quvKtUzNDTEkiVLNJaTl5eHmpoajB8/Xindw8MDxsbG3FSSKoyNjQEAjY2NKvP5fD4AqF2SW1xcDCLS6F1ZR/D5fISEhODKlSv47bffMHPmTBQXF2POnDl4/Phxt9o2NTXFX//6Vzx+/Bh79uwBACQmJmLx4sVcH7SH4voePXrULT16mu7YQlcZP348xGIxNz3X1+mszcbGxmLo0KFISUnBmTNnlPK05XsdjRWdISoqCtu2bcOpU6dQU1ODmzdvwsvLC56enigsLATw9B3dCy+8ABMTExgbG2PChAlITU1FXV0dUlJSOiWvIxTvPJuamtrkNTQ0QCQStUk/ePAg9u3bhx9//BFSqZRLj4yMxPvvvw97e/sO5WrTZ/tckHsWIyMj2NvbY/78+di4cSPy8/Oxfv16lWUV36VSN8/bWWprawEAK1euVNqLcufOHcjlclRVVQEAzMzMuiVHsZjGxMSkTZ6ZmRmqq6s1buvo0aP4y1/+AmtrawgEAixfvrzd8vX19QCg8oVzd3jppZfw7bffYtGiRSgpKcHPP//c7TYVC1C2bt2KiooK7N+/Hx988IFGdRWOqLjevoo2baEzCAQClJSU9Ejb2qazNisUCpGamgoej4d//OMfqKur4/K01d8djRWa8uDBA8TFxeH999/HlClTIJFI4OTkhO3bt6OoqAjx8fFq67q7u8PQ0BDXrl3TWJ4mKN7PKsY7BXK5HPX19bCzs1NK37NnDzZs2ICMjAxuwSDwdD1Ebm4uFixYoJFcbfpsnw5yz+Lu7g4AuHz5ssp8xRPHsxsUu4MiWCYmJnK/LBV/WVlZ6N+/PwCo/WWpKYogqcqhKioqMGDAAI3auXv3Lvz9/WFra4tz586hsrIScXFx7dZRGFJXNl+ePn0aiYmJAIBZs2apfNJTbMjtjKOrY8yYMZgwYQJ+//13BAcHY86cOTA3N9eobkNDAwCofOrsS2jLFjpDY2Njj7XdE3TFZj09PbF06VIUFBQgJiaGS9dWf3c0VmhKQUEBmpububFFgUwmg4WFBfLy8tTWbWlpQUtLi9YfWJ2cnCCVStus7Lx+/ToAYNSoUVzapk2bsHv3bvz0009trmHnzp04deoUDAwMuIcARb+tW7cOPB4Pf/zxB1demz773AS5//znPwCAoUOHqswfOXIkDAwMkJmZqRV5AwcOhFAo5E5KaY2joyMsLCxw4sSJbskZOXIkTExMlG4wAJw7dw4NDQ0YN26cRu3k5uaisbERixcvhrOzM4RCYYfbJxQnoFRWVnZa7//85z+QSCQAnj5YqHr4UKyGfNYRuoPi19yBAwfw8ccfa1xPcX02NjZa0aOn0NQWjIyM1E5Rd5aMjAwQEfdFZW223RN01WZjYmIwbNgwXLx4kUvTlu91NFZoiiKoPnjwQCm9uroa5eXl3FaC1q9IAOD8+fMgInh6enZLh9YYGRnh9ddfx+nTp9HS0sKlHz9+HDweD35+fiAiREREIDc3F4cOHVL5yzg1NbXNA4Bi9iAqKgpEpDRtrE2f7ZNBrq6uDi0tLSAiFBUVITU1FStXroSVlZXawc3a2hqzZ8/GgQMHsHPnTlRVVSEnJwfbtm3rkg5CoRDz589HWloatmzZgqqqKjQ3N+PevXt48OABBAIBIiMjcfr0aYSEhOD+/ftoaWlBdXU1N+BbWFigqKgIt2/fRnV1tcrBQygUIiwsDAcPHsTu3btRVVWF3NxcLFq0CHZ2dggODtZIX8US35MnT6K+vh4FBQUdvsMRi8Vwdnbmpno1obGxEY8ePUJGRgYX5ADA398f+/btQ0VFBSorK3H48GF88sknmDFjhtaC3FtvvQUrKyv4+/t3ajm14voUswF9FU1twdXVFeXl5Th06BAaGxtRUlLS5klbne21tLTg8ePHaGpqQk5ODkJDQ+Hg4IB33323W20fP368V7YQdMVmgf+btnx2L5e2fK+jsQJ4eqydjY1Nu0eJOTk5wcfHB9u3b8fp06dRV1eHwsJCTo/33nsPwNOl+Xv27EFFRQUaGxuRlZWFBQsWwMHBAYsWLdJYnqasWrUKjx49wurVq1FbW4usrCzEx8fj3XffxdChQ3H58mV8/vnn2L59O/h8fpvjxjZu3NhpmVr12dYrUXSxuvLgwYNqV1YKBAIaPHgwLV68mFvmvGnTJrK1tSUAJBaLuSWp1dXVtHDhQrK0tCQTExOaNGkSRUdHcyuUFi5c2KZeXFwciUQiAkADBw5UOkngyZMnFBERQQ4ODmRkZETW1tY0a9YsysvL48ps3ryZ3N3dSSgUklAopBdeeIFSUlKIiOjChQs0aNAgEolENGnSJFq5cqVKvVtaWig+Pp4GDx5MfD6fzM3Nyd/fn/Lz84no6UousVhMAGjw4MF048YN2rZtG8lkMgJAgwYNomvXrlFERARZWFiQmZkZzZkzhzspwcXFhUJDQ8nGxoYAkEQi4U6PCQkJIT6fz61a7Oh+PPt38OBBInq6Amvu3Lnk4uJCAoGAjI2NaejQobRmzRqqr69XutdVVVX08ssvk4WFBQEgAwMDcnV1pXXr1qmUb2Vlxa2MIyJavnw5nT17lvv/2T41MDAgNzc3+uWXX5RkTp8+nezt7ZVObOgNurKFoCNbICIqKysjHx8fEgqF5OTkRP/85z8pPDycAJCrqyu3+u5Z23v48CEFBwcTn88ne3t7MjIyIplMRjNnzqQbN250u+1jx46RVCql2NjYTl1vV8abjmy2tc08S3h4uNKKXm35Xkdjhb+/PwGg6Ojodq+ttLSUQkNDydXVlQQCAZmYmNDEiRPp22+/5cqEhYWRi4sLSSQSMjIy4sa2oqIiroym8rKysmjixIlkZ2fH+bWtrS15eXlRZmYmVy4zM5NefPFFEggEZGdnR+Hh4Zxv5+bmtjtOqNp+QNT+6squ+OxzsYWA0fsUFBSQkZGR1o4J6muUlpaSUCikjRs39rrsvnZ2ZXBwMFlYWOhaDSW6Mt48jzbb3NxMkydPpp07d+qlPG3SVZ99brYQMHoXV1dXrF27FmvXrm33xPDnlTVr1mDMmDEICQnRtSp9An34KsPzZrPNzc04dOgQqqurERgYqHfytI22fZYFOQZWrFiBOXPmIDAwsEuLUPoqCQkJyM7OxrFjx7g9gwz94Hmy2YyMDKSnp+P48eNa2ZPa1+Rpk57wWRbkGACeLuMNCQlRuw/xeePw4cN48uQJMjIyNN5qoM9ERkYiNTUVlZWVcHJywoEDB3StUrd5XmzW19cX33zzjdKZoPokT1v0lM/yiJRPwNy3bx/mzp37XBxmy2D0ZebMmQMA2L9/v4416buw8YahLdT5G/slx2AwGAy9hQU5BoPBYOgtLMgxGAwGQ29hQY7BYDAYegsLcgwGg8HQW4zUZXR0uC+DwdAM5ksdw/qIoQ1mz57dJq3NFoJ79+7h7NmzvaYUg/FnYu7cuQgNDdX6afEMBuPpFyFa+1abIMdgMHoOHo+HvXv34q233tK1KgzGnwL2To7BYDAYegsLcgwGg8HQW1iQYzAYDIbewoIcg8FgMPQWFuQYDAaDobewIMdgMBgMvYUFOQaDwWDoLSzIMRgMBkNvYUGOwWAwGHoLC3IMBoPB0FtYkGMwGAyG3sKCHIPBYDD0FhbkGAwGg6G3sCDHYDAYDL2FBTkGg8Fg6C0syDEYDAZDb2FBjsFgMBh6CwtyDAaDwdBbWJBjMBgMht7CghyDwWAw9BYW5BgMBoOht7Agx2AwGAy9hQU5BoPBYOgtLMgxGAwGQ29hQY7BYDAYegsLcgwGg8HQW1iQYzAYDIbewoIcg8FgMPQWFuQYDAaDobewIMdgMBgMvYUFOQaDwWDoLSzIMRgMBkNvMdK1AgyGvnLnzh00Nze3SX/06BFu3ryplNa/f38IhcLeUo3B+NPAIyLStRIMhj4yffp0HDt2rMNyfD4fjx49grm5eS9oxWD8uWDTlQxGDxEYGNhhGQMDA0ydOpUFOAajh2BBjsHoIQICAjqcgiQivPPOO72kEYPx54MFOQajh5BIJHjjjTfA5/PVlhEIBHjjjTd6USsG488FC3IMRg8SFBSEpqYmlXl8Ph8BAQGQSCS9rBWD8eeBBTkGowd5/fXXYWJiojKvsbERQUFBvawRg/HnggU5BqMHMTY2xpw5c2BsbNwmTyaT4ZVXXtGBVgzGnwcW5BiMHuavf/0rGhoalNL4fD7efvttlcGPwWBoD7ZPjsHoYVpaWmBra4uSkhKl9MzMTLz88ss60orB+HPAfskxGD2MgYEBgoKClFZZWltbY9KkSTrUisH4c8CCHIPRC7z99ttobGwE8PQ93bvvvgsDA+Z+DEZPw6YrGYxegIjg6OiIu3fvAgD++OMPjBs3TsdaMRj6D3uUZDB6AR6Ph7/97W8AAGdnZxbgGIxeos1XCLKyspCQkKALXRgMvaaqqgoAIBQKMWfOHB1rw2DoH56enli6dKlSWptfcoWFhThw4ECvKcVg6Cu//fYbfvvtN+5/mUwGMzMzDBw4UIda9S3u3bvHxhuGVvjtt9+QlZXVJl3t9+T279/fowoxGPqO4tfas7508uRJtgH8Gfbt24e5c+ey8YbRbdTNjrB3cgxGL8ICHIPRu7Agx2AwGAy9hQU5BoPBYOgtLMgxGAwGQ29hQY7BYDAYeku3g5yHhwcMDQ0xZsyYdssdO3YMpqam+P7779WWWbBgAaRSKXg8HrKzszWu15PoSv7GjRvRr18/8Hg8bN26tUtttLS0IDExEV5eXt0qAzxdFbhixQqt6NWbdKcPvvvuO8TFxaG5ubmn1VSLru2/r6Owy/T0dDg7O4PH44HH4+Gdd95pU3bq1KmQSqUwNDTEiBEjcOHCBR1o3DH//ve/4eHhAalUikGDBmH+/Pl4+PAhlx8bG8td57N/I0eO7LLMjvzkzJkzmDhxIsRiMezs7BAREYEnT55w+WvXroWbmxtkMhkEAgFcXV2xfPly1NTUqJVZX1+PYcOGYeXKlQB6zt+6HeTOnz8PHx+fDstpcnrYjh07sH379k7X60l0JX/ZsmU4e/Zsl+sXFBTg5ZdfxtKlSyGXy7tcBgBWr16N5ORkREZGdluv3qS7feDn5wehUAhfX19UVFT0hspt0LX992WetctZs2bh5s2bcHFxgaWlJXbv3o2jR48qlT9x4gT279+PN998E3l5eRg7dqyONFfP3r17ERQUhDlz5uDevXs4fPgwTp8+jWnTpqn9wnx36chP8vLyMHXqVPj6+qKkpAQHDx7Ev/71LyxatIgr89NPP+Gjjz7C7du3UVpais8++wxJSUntHnoQFRWF/Px87v8e8zdqxd69e0lFcrv4+vrSmDFjOlVHHWlpaQSALl68qJX2OoNcLidPT89el6uOgoICAkBfffVVp+plZ2dTQEAA7d69m8aMGUOjR4/uUhkiovXr19OQIUOorq6uy3rpol+12QchISHk6elJjY2NndJh9uzZNHv27C7p31fo6XvXlfGGSLVdEhG5uLjQN998QwYGBmRvb08VFRVK+cePH6cZM2Z0S+eexMfHh/r3708tLS1c2ubNmwkAnTlzhoiIYmJiaNeuXVqRp4kPzJ07l5ycnJR0io+PJx6PR1euXCEiounTp1NTU5NSvbfeeosA0N27d9u0+euvv9LUqVMJAEVFRSnladvftPZO7tnPiHQHHo+nlXa6ws6dO1FcXKwz+dpi9OjRSE9PR1BQEAQCQZfLXL9+HatWrcKnn34KoVDYZX100a/a6gMAWLNmDbKzs5GUlNRT6vZZ+qJPdGSXXl5eCA0Nxf3797Fs2TIdaNh1CgsLYWdnpzQOKk7IuXPnjtbldeQDTU1NOHr0KLy9vZV0mjZtGogIhw8fBgAcOXIEhoaGSnWtrKwAoM2vw7q6OoSHh6v1J237m9aC3PXr1zFs2DBIJBKIRCJMnjwZZ86cAfB0PtfBwQE8Hg+bN2/m6hAR4uPjMXToUAgEApiamiI8PJzLV1Xv888/h1gshlQqRXFxMcLCwmBvb4/8/Hw0NzcjOjoaDg4OEIlEGDVqFPbu3auk565duzB+/HgIhUJIJBI4OjoiJiYGoaGhCAsLw40bN8Dj8eDq6tqu3gkJCRg+fDgEAgHMzc0xc+ZMXL16FQCwZcsWSCQSiMViHD58GNOmTYNMJsOAAQOQlpbGtfPLL7/Azc0NpqamEAqFcHd3x48//qitW9JtkpOTQUTw8/PrsGxmZiZefPFFiMViyGQyuLu7o6qqSmW/JiUlQSKRwMDAAOPGjYONjQ34fD4kEgnGjh2LyZMnY+DAgRAKhTAzM8Py5ct74WrVY25uDm9vbyQlJfXq9KEq+9PEtpKTkyEUCtGvXz988MEHsLOzg1AohJeXF86dOwcACAkJgbGxMWxtbTl5H374ISQSCXg8HkpLS1XeOwD44YcfIJPJsG7dul7ri2fRxC5jY2MxZMgQ7NixAydPnlRbTlu+rMnYownOzs5tHioU7+OcnZ073V53uXnzJmpqauDg4KCU7uLiAgDIyclRW/f+/fsQiURwcnJSSo+KisKHH34Ia2trlfW07m+tf9p1dbrS2dmZbt26RY2NjXTp0iV66aWXSCgU0rVr14iIqLCwkADQpk2buHpRUVHE4/Hoiy++oMePH5NcLqeUlBSl6Up19QDQkiVLaNOmTRQQEEBXrlyhZcuWkUAgoAMHDtDjx48pMjKSDAwM6Pz580RElJiYSABo/fr1VFZWRuXl5fT1119TUFAQERHNmjWLXFxclK5Nlfzo6GgyNjamXbt2UUVFBeXk5NDYsWPJysqKHj58qKTjqVOnqLKykoqLi2ny5MkkkUiooaGBiIj2799Pa9asofLyciorK6MJEyaQpaUlJ6er05XP8tJLL6mdhuuojLOzM7m5ubVJb61XTU0NyWQyiouLo7q6Onr48CEFBARQSUkJEanu19WrVxMAOnfuHNXW1lJpaSm99tprBICOHj1KJSUlVFtbSyEhIQSAsrOzu9oF3eoDBStWrOj0NLo2pivbs//2bCs4OJgkEgldvnyZ6uvrKS8vjzw8PEgqlXLTR0FBQWRjY6MkLz4+ngC0e++OHDlCUqmU1q5d261rI+raeKPOLomeTlfeunWLiIjOnj1LBgYG5OjoSDU1NUTUdrpSW77c0dijKRkZGcTn8yk5OZmqqqro0qVLNHz4cHr11Ve5MjExMTRgwAAyMzMjPp9Pjo6ONGPGDPr99987Jas1qnwgMzOTAFB8fHyb8iKRiHx9fVW2VVtbS1KplEJCQpTSz5w5Q35+fkREVFJSonK6kki7/qa1X3JSqRSOjo4wMjLCiBEjsH37dtTX12Pbtm0qy9fV1SExMRGvvPIKli5dCjMzM4hEIlhYWGgsc8OGDfjoo4+Qnp4OR0dHbNmyBf7+/pg1axbMzMywcuVK8Pl8pKamorGxEZ9++il8fHzwySefwMLCAubm5njvvffg4eGhscy6ujokJCQgICAA8+bNg6mpKdzd3bF161aUlpa2uV4vLy/IZDJYW1sjMDAQtbW13DfFZs+ejdWrV8Pc3BwWFhbw8/NDWVkZSkpKNNanp6itrcWtW7e4J7b2uH37NqqqqjBixAgIhULY2NggPT2dm65oDzc3N4jFYlhaWuLtt98GADg4OMDKygpisRjz5s0DAO7JWlcMHjwYAJCbm6tTPZ6lPdsCACMjI+4XipubG7Zs2YLq6mqkpqZ2S+706dNRVVWFVatWdfcSOk1n7NLT0xMff/wxbt++jU8++aRNvrZ8ub6+vt2xpzN4e3sjIiICISEhkMlkGDlyJKqrq7Fjxw6uzN///nd89913KCwsRE1NDdLS0nD37l14e3sjLy+vU/I6QrGCsvVUJPD0FVVdXZ3Kep999hns7OwQGxvLpdXV1SE0NBRbtmzpUK42/a3H9sm5u7vD1NRU7c/Z69evQy6Xw9fXVyvy8vPzIZfLlZbRikQi2Nra4urVq8jJyUFFRQVeffVVpXqGhoZYsmSJxnLy8vJQU1OD8ePHK6V7eHjA2NiYmw5ShbGxMQBwX4hujeK9pi6XrCsoLi4GEUEsFndY1tnZGf369cO8efOwZs0a3L59u0syFf3z7CoyRZ+o67PeQtEPjx490qke6ujItgBg/PjxEIvFOn9g6A6dsUvg6bTl0KFDkZKSwr0+UaAtX+5o7OkMUVFR2LZtG06dOoWamhrcvHkTXl5e8PT0RGFhIYCn7+heeOEFmJiYwNjYGBMmTEBqairq6uqQkpLSKXkdoXjnqWplZ0NDA0QiUZv0gwcPYt++ffjxxx8hlUq59MjISLz//vuwt7fvUK42/a1HN4Pz+Xy1Tnfv3j0AUDsv21lqa2sBACtXrlTaO3Lnzh3I5XLuW15mZmbdkqNY2mpiYtImz8zMDNXV1Rq3dfToUfzlL3+BtbU1BAKBzt89PUt9fT0AtLsgQ4FIJMJPP/2ESZMmYd26dXB2dkZgYKDap7znEYUzK/rleUUgEPSJmYKu0hm7BJ4O0qmpqeDxePjHP/6hZJPa8uWOxh5NefDgAeLi4vD+++9jypQpkEgkcHJywvbt21FUVIT4+Hi1dd3d3WFoaIhr165pLE8TFO9sFeOnArlcjvr6etjZ2Sml79mzBxs2bEBGRgYcHR259DNnziA3NxcLFizQSK42/a3HglxTUxPKy8vbvLBUoHhCeHZDYXdQBMvExEQQkdJfVlYW+vfvDwAoLS3tlhxFkFTlABUVFRgwYIBG7dy9exf+/v6wtbXFuXPnUFlZibi4uG7ppk0URqbpr8oRI0bg+++/R1FRESIiIrB3715s3LixJ1XsVRoaGgBA5ZPr80JjY2OnbLQv0lm7BP7vQ5oFBQWIiYnh0rXlyx2NPZpSUFCA5uZmbqxSIJPJYGFh0e5UZEtLC1paWjQO/pri5OQEqVTaZmXn9evXAQCjRo3i0jZt2oTdu3fjp59+anMNO3fuxKlTp2BgYMA9BCj6bd26deDxePjjjz+48tr0tx4Lcj///DNaWlrUbrgcOXIkDAwMkJmZqRV5itV4ipNSWuPo6AgLCwucOHGiW3JGjhwJExMTpRsCAOfOnUNDQwPGjRunUTu5ublobGzE4sWL4ezsDKFQqNPtE61RnGpSWVnZYdmioiJcvnwZwFOHX79+PcaOHcul6QOKfrCxsdGxJl0nIyMDRIQJEyYAePrOTtfTwJ2lM3b5LDExMRg2bBguXrzIpWnLlzsaezRFEVQfPHiglF5dXY3y8nJuK0HrVy7A00M5iAienp7d0qE1RkZGeP3113H69Gm0tLRw6cePHwePx4Ofnx+ICBEREcjNzcWhQ4dU/jJOTU1t8wCgmFGIiooCESlNG2vT37QW5BoaGlBZWYmmpiZcuHABISEhGDRoEN59912V5a2trTF79mwcOHAAO3fuRFVVFXJyctQuVOkIoVCI+fPnIy0tDVu2bEFVVRWam5tx7949PHjwAAKBAJGRkTh9+jRCQkJw//59tLS0oLq6mhuMLSwsUFRUhNu3b6O6ulrlACAUChEWFoaDBw9i9+7dqKqqQm5uLhYtWgQ7OzsEBwdrpK/iF+7JkydRX1+PgoKCdt8B9DZisRjOzs7ctHJ7FBUV4YMPPsDVq1fR0NCAixcv4s6dO9xgqkm/9nUU/eDu7q5jTTSnpaUFjx8/RlNTE3JychAaGgoHBwfOJ11dXVFeXo5Dhw6hsbERJSUlbZ7YVd2748eP62wLQWfs8lkU05bPLqDQli93NPYAQGBgIGxsbNo9SszJyQk+Pj7Yvn07Tp8+jbq6OhQWFnJ6vPfeewCeLs3fs2cPKioq0NjYiKysLCxYsAAODg7cKSSayNOUVatW4dGjR1i9ejVqa2uRlZWF+Ph4vPvuuxg6dCguX76Mzz//HNu3bwefz29z3FhXZnS06m+tl1t2ZUlvamoq+fj4UL9+/cjIyIgsLS3p7bffpjt37hAR0aZNm8jW1pYAkFgs5paQVldX08KFC8nS0pJMTExo0qRJFB0dTQBowIABtHDhwjb14uLiSCQSEQAaOHCg0s7/J0+eUEREBDk4OJCRkRFZW1vTrFmzKC8vjyuzefNmcnd3J6FQSEKhkF544QVKSUkhIqILFy7QoEGDSCQS0aRJk2jlypUq9W5paaH4+HgaPHgw8fl8Mjc3J39/f8rPzyciopSUFBKLxQSABg8eTDdu3KBt27aRTCYjADRo0CC6du0aRUREkIWFBZmZmdGcOXO4kw1cXFwoNDSUbGxsCABJJBIKCAjQ+H5kZWXRxIkTyc7OjgAQALK1tSUvLy/KzMzUuExISAjx+XySy+Vc21988UUbvW7fvk1eXl5kbm5OhoaG1L9/f4qKiuJOQGjdrytWrOD6x9HRkX755RfasGEDmZqaEgCysbGhb775hvbs2cRzw54AACAASURBVMPJMjc3p7S0tF7vAwXTp08ne3t7pVMfOqK7WwhU+Y2mthUcHEx8Pp/s7e3JyMiIZDIZzZw5k27cuMG1X1ZWRj4+PiQUCsnJyYn++c9/Unh4OAEgV1dXunv3bpt79/DhQzp27BhJpVKKjY3t8rUp6Mp4o8ouDx48SC4uLgSArKys6KOPPlJZNzw8XGkLgbZ8uaOxx9/fnwBQdHR0u9dWWlpKoaGh5OrqSgKBgExMTGjixIn07bffcmXCwsLIxcWFJBIJGRkZcWNlUVERV0ZTeZr6QGZmJr344oskEAjIzs6OwsPDqb6+noiIcnNzubqq/lRtPyBqfwuBNv1NK0GOoZ8UFBSQkZGR1o4Qel4pLS0loVBIGzdu7FQ9XR7rFRwcTBYWFjqR3Rm6Mt48j3bZ3NxMkydPpp07d+qlPG2ibX9jn9phqMXV1RVr167F2rVr2z1NXN9Zs2YNxowZg5CQEF2r0in6wlaUnuB5s8vm5mYcOnQI1dXVCAwM1Dt52kbb/saC3HPC1atXVX5eo/Wfto16xYoVmDNnDgIDAzv9sl/b6KIPEhISkJ2djWPHjmntfFZG9+lLdtkRGRkZSE9Px/HjxzXe3/c8ydMmPeFvRlpphdHjDBs2TGefXVm3bh1OnDiB9evXY8OGDTrRAej9Pjh8+DCePHmCjIwMlSc+9FUiIyORmpqKhoYGODk5IT4+HrNnz9a1Wlqnr9hlR/j6+mrt0Iu+KE9b9JS/8ajVqLFv3z7MnTuXfceKwegmim9p7d+/X8ea9F3YeMPQFur8jU1XMhgMBkNvYUGOwWAwGHoLC3IMBoPB0FtYkGMwGAyG3sKCHIPBYDD0FrVbCPrSYcEMxvMM86WOYX3E0AaqtsqoDXJ79+7tUWUYDH0nMTERAPDxxx/rWJO+S1ZWFpKSkth4w+g2Cn9rjdog99Zbb/WYMgzGnwHFfh3mS+2TlJTE+ojRbdTtR2Xv5BgMBoOht7Agx2AwGAy9hQU5BoPBYOgtLMgxGAwGQ29hQY7BYDAYekufCHLp6elwdnZu810wIyMjWFlZ4ZVXXsHBgweV6hw7dgympqb4/vvv1ba7YMECSKVS8Hg8ZGdna1yvJ9GV/I0bN6Jfv37g8XjYunWryjInT57EihUr2twPW1tbzJs3r932//vf/yIwMBBOTk4QCASwsrLC6NGjERsbCwAIDAzU6FtwPB4P8+fPV5K/atWqdmUnJCSAx+PBwMAAw4YNw+nTp/Hdd98hLi5Obz8cytAu6mz/nXfeaVN26tSpkEqlMDQ0xIgRI3DhwgUdaNw+sbGxKn1r5MiRbcq2tLQgMTERXl5ebfLWrl0LNzc3yGQyCAQCuLq6Yvny5dzHap8HP+sTQW7WrFm4efMmXFxcYGpqCiICEaGkpAR79+7F/fv3MWvWLKW9NJp8mmPHjh3Yvn27UpquP+mhK/nLli3D2bNn1eavXr0aycnJiIyMbHM/Hj58iN27d6utm5ubCy8vL9ja2uLnn39GZWUlzp49i9deew0ZGRlcuRMnTqCiogKNjY148OABAMDPzw8NDQ2ora1FcXExFi5cqCQfeHofGxsbVcpubm5GcnIyAGDKlCm4evUqXn75Zfj5+UEoFMLX1xcVFRWd7S7Gnwh1tm9paYndu3fj6NGjSuVPnDiB/fv3480330ReXh7Gjh2rI827T0FBAV5++WUsXboUcrm8Tf5PP/2Ejz76CLdv30ZpaSk+++wzJCUlcZ+1eR78rE8EOXWYm5vD19cXX375JYCn355SMH36dFRWVuLNN9/sVJtdrdcV6urq2jwd9aZ8TdmwYQP27NmDffv2QSqVdrr+xo0bYWZmhqSkJDg6OkIoFGLIkCGIiYmBSCQC8PREi4kTJ8LU1BRGRv+3PZPH44HP50MsFsPa2hrjxo1TanvcuHF4+PAhDh06pFJ2eno67O3tVeYtWbIEo0ePxuuvv46mpqZOX9fzjCrbex7a7m3as/3k5GQYGBggODi4z399XBW7du3ifjAo/i5dusTl//e//8Unn3yCRYsWYcyYMSrbMDExQXBwMCwsLCCVSvHWW2/B398fP/zwAwoLCwH0fT/r00FOgaOjIwB06UlBl8cF7dy5E8XFxTqTrwnXr1/HqlWr8Omnn0IoFHapjbKyMlRWVqK8vFwp3djYmJuWTUtLg1gs7rCt4OBgvPHGG9z/ixcvBgB89dVXKssnJCQgLCxMbXtr1qxBdnY2kpKSOpStT/Sk7T0Pdq0JHdm+l5cXQkNDcf/+fSxbtkwHGvYso0ePRnp6OoKCgiAQCFSWOXLkSJuvdFtZWQGA0i+/vuxnz0WQy8nJAQB4e3sDAM6cOQMHBwfweDxs3ryZK0dEiI+Px9ChQyEQCGBqaorw8HAuX1W9zz//HGKxGFKpFMXFxQgLC4O9vT3y8/PR3NyM6OhoODg4QCQSYdSoUW2OH9q1axfGjx8PoVAIiUQCR0dHxMTEIDQ0FGFhYbhx4wZ4PB5cXV3b1TshIQHDhw+HQCCAubk5Zs6ciatXrwIAtmzZAolEArFYjMOHD2PatGmQyWQYMGAA0tLSuHZ++eUXuLm5wdTUFEKhEO7u7vjxxx/b7dvk5GQQEfz8/LpyawAAHh4eqK2txZQpU/Drr792uR1VTJkyBcOHD8fPP/+M/Px8pbxff/0VcrkcU6dOVVvf3Nwc3t7eSEpK0vlUtSZ0ZAshISEwNjaGra0tV+fDDz+ERCIBj8dDaWmpSttLTk6GUChEv3798MEHH8DOzg5CoRBeXl44d+5ct9oGgB9++AEymQzr1q3rxd7qHprYfmxsLIYMGYIdO3bg5MmTastpy4c1GXN0zf379yESieDk5MSl9Wk/o1bs3buXVCT3Ci4uLmRqasr9L5fL6fjx4zRo0CCaOnUq1dTUcHmFhYUEgDZt2sSlRUVFEY/Hoy+++IIeP35McrmcUlJSCABdvHix3XoAaMmSJbRp0yYKCAigK1eu0LJly0ggENCBAwfo8ePHFBkZSQYGBnT+/HkiIkpMTCQAtH79eiorK6Py8nL6+uuvKSgoiIiIZs2aRS4uLkrXqEp+dHQ0GRsb065du6iiooJycnJo7NixZGVlRQ8fPlTS8dSpU1RZWUnFxcU0efJkkkgk1NDQQERE+/fvpzVr1lB5eTmVlZXRhAkTyNLSkpNTUFBAAOirr77i0pydncnNzU2j+6EOuVxO48ePJwAEgNzc3CguLo7KysrU1nnw4AEBoBkzZqgt4+LiQrdu3aIvv/ySAFBoaKhSvr+/P6WmplJ1dTUBIF9fX5XtrFixQskGeovZs2fT7NmzO1VHE1sICgoiGxsbpXrx8fEEgEpKSohIte0FBweTRCKhy5cvU339/2/v3sOautL9gX8DuRFIuMhVEZRLtQJqqVpErfZhjnOspyICSkfb0T7toK2lVGWooFQRtA6OemhlemwdzhntKCge7EU6re3B/nykth2xUBhvKKBSBCwYLuGa9/dHn6SmgATIBeP7eZ78wd4ra71ZWdkve2etnXYqKyuj6dOnk1wup+rq6mHV/fHHH5NcLqfU1NRBvV5zHm8GGvvXr18nIqKzZ8+SlZUVjRs3TnsMKigo0Bm7hvoMD3TM0de2bdvI09OTHBwcSCQS0bhx4yg8PJy++eabPss/8cQTNGXKlAHrbW1tJblcTnFxcb32metzptHf523EJTnNgfLeR1BQEP3P//wPdXR0aMv+Olm0tbWRTCajf/u3f9Op8/Dhw3onOZVKpd2mUqlIJpNRTEyMdltbWxtJJBJ6+eWXqbOzkxwcHOipp57Saa+7u5v27t1LRPoluba2NrKzs9Nph4jom2++IQDag0ZfMWoS+NWrV/vsz+3btxMAqqurI6LeSa6lpYUEAgE988wzfT5f3yRHRNTZ2Un/+Z//SRMnTtS+b66urlRYWNhn+cEkuaamJrK1tSVHR0dqa2sjIqKKigry9PSkjo6OAZPcX//6VwJAf/vb3/R6LYYy2CSn71gYTpL79fv57bffEgDaunXrsOoeKnMdb/QZ+5okR0S0fv16AkBr164lIt0kZ6jP8EDHnMGorq6m8+fPU3NzM3V0dFBRURE99thjZGNjQz/88EOv8vomueTkZHrkkUdIqVT22meuz5lGf5+3EXe58t7ZlV1dXbh58yZef/11xMXFYfLkyWhoaOjzeVevXkVbWxvCwsIMEselS5fQ1tamM+XWxsYG7u7uuHjxIkpKStDU1ITf/va3Os+ztrbGa6+9pnc7ZWVlaGlpwbRp03S2T58+HWKxWHspqS9isRgA+p15KBKJAKDf6b11dXUgIr2+KxuISCRCXFwc/vWvf+Hrr7/G4sWLUVdXh+joaDQ2Ng6rbnt7e/zud79DY2Mjjhw5AuDnO46//PLL2j64H83ru3379rDiMLbhjIWhmjZtGmQymfay2sNisGM/LS0NEyZMwL59+3DmzBmdfYb6DA90zBmMsWPH4rHHHoOdnR3EYjFCQkKQnZ0NlUqFffv2DaoujePHjyM3Nxf/+Mc/+pygNlI/ZyMuyd1LKBRizJgxWLVqFXbt2oVLly5hx44dfZa9efMmAMDFxcUgbbe2tgIANm3apLPOpKqqCm1tbVAqlQAABweHYbWjmUxjZ2fXa5+DgwOam5v1ruuTTz7BvHnz4OLiAolEgj/+8Y/3Ld/e3g4A/X7pPFRPPPEE/vd//xdr1qxBfX09/u///m/YdWomoLz77rtoamrC0aNHsXr1ar2eq5nhqXm9I5Uhx8JgSCQS1NfXG6XukWqwY18qlSI7OxsCgQAvvPACVCqVdp+h3reBjjnDFRQUBGtra1y+fHnQzz1y5AjeeustFBYWaicC/tpI/ZyN6CR3r6CgIABAeXl5n/s1s6M6OjoM0p4mWe7Zs6fXNNyioiKMHj0aAPo9s9SXJkn29UFoamqCp6enXvVUV1cjIiIC7u7uOHfuHO7evYudO3fe9zmaQTmUhZxfffWV9vebIiMj+5w6rFlIa4gP6NSpUxESEoJvvvkGsbGxiI6OhqOjo17P7ezsBPDL6x2pDDUWBqOrq8todY9kQxn7M2fOxLp163DlyhVs27ZNu91Q79tAx5zhUqvVUKvVg/6n9u2338ahQ4fw5Zdfao97fRmpn7MHJsn985//BABMmDChz/2BgYGwsrLC6dOnDdLe2LFjIZVKtXdK+bVx48bByckJn3322bDaCQwMhJ2dHb777jud7efOnUNnZ2evdWP9KS0tRVdXF15++WX4+PhAKpUOuHxCcweUoawB+uc//wlbW1sAP/9j0dc/H5rZkJMnTx50/X3RnM0dO3ZsUD9Eqnl9bm5uBonDWPQdC0KhsN9L1INVWFgIIkJISIjB6x7Jhjr2t23bhokTJ6K4uFi7zVCf4YGOOYPx669RAODbb78FEWHmzJl61UFESExMRGlpKfLz8/s8U73XSP2cjcgkp1KpoFarQUSoqalBdnY2Nm3aBGdn534Pbi4uLoiKisKxY8dw4MABKJVKlJSUYP/+/UOKQSqVYtWqVTh8+DCysrKgVCrR09ODmzdv4scff4REIkFSUhK++uorxMXF4datW1Cr1WhubtYe8J2cnFBTU4PKyko0Nzf3efCQSqVYv349jh8/jkOHDkGpVKK0tBRr1qyBh4cHYmNj9YrXy8sLwM+3J2pvb8eVK1cG/A5HJpPBx8dHe6lXH11dXbh9+zYKCwu1SQ4AIiIikJubi6amJty9excnTpzAG2+8gfDwcIMluaVLl8LZ2RkRERHw8fHR+3ma16e5GjBS6TsW/Pz88NNPPyE/Px9dXV2or69HVVWVTl39jT21Wo3GxkZ0d3ejpKQE8fHx8PLywsqVK4dVd0FBwQO1hGAoYx/45bLlvWvHDPUZHuiYA/x8ezw3N7cBbyV269YtHDlyRHuHoaKiIrz44ovw8vLCmjVr9IqnvLwcf/rTn/Dee+9BJBL1ukXYrl27dMqP2M/Zr2eimGO20/Hjx/udWSmRSMjf359efvll7TTnt99+m9zd3QkAyWQyWrRoERERNTc300svvUSjRo0iOzs7mj17NqWkpBAA8vT0pJdeeqnX83bu3Ek2NjYEgMaOHUsHDx7UxtXR0UGJiYnk5eVFQqGQXFxcKDIyksrKyrRl3nnnHQoKCiKpVEpSqZQee+wx2rdvHxERnT9/nry9vcnGxoZmz55NmzZt6jNutVpNGRkZ5O/vTyKRiBwdHSkiIoIuXbpERD/PwJLJZASA/P39qaKigvbv308KhYIAkLe3N12+fJkSExPJycmJHBwcKDo6mt555x0CQL6+vhQfH09ubm4EgGxtbWnJkiVERBQXF0cikUg7a3Gg9+Pex/Hjx4mI6LPPPqNly5aRr68vSSQSEovFNGHCBNqyZQu1t7frvNdKpZKefPJJcnJyIgBkZWVFfn5+lJ6e3mf7zs7O2hltRER//OMf6ezZs9q/7+1TKysrmjRpEv2///f/dNpcuHAhjRkzhtRq9aDG5XANZQnBQGOBiOjOnTv01FNPkVQqpfHjx9Orr75KCQkJBID8/Py0M+vuHXu1tbUUGxtLIpGIxowZQ0KhkBQKBS1evJgqKiqGXffJkydJLpdTWlraoF6vOWdzDzT2fz327pWQkKAzM9hQn+GBjjkREREEgFJSUu772tavX0++vr5ka2tLQqFQe/yrqanRlikqKqJZs2aRh4eH9jPt7u5OoaGhdPr0aSotLb3v5z8jI0OnTXN9zjQeiCUEzPSuXLlCQqFQJ7lbkoaGBpJKpbRr1y6Ttz2UJGdMsbGx5OTkZO4wdJjzePMgjv2enh6aM2cOHThwwNyh6DDn50zjgVlCwEzLz88PqampSE1N1d5Z3JJs2bIFU6dORVxcnLlDGRFG8t3iTe1BG/s9PT3Iz89Hc3MzYmJizB2OjpH8OeMkx7Bx40ZER0cjJibmgbwRbX92796NCxcu4OTJk9o1g4zd60Ea+4WFhcjLy0NBQYFB1rYaykj/nHGSYwCA9PR0xMXF9bsO8UFz4sQJdHR0oLCwUO+lBpYsKSkJ2dnZuHv3LsaPH49jx46ZO6QR40EZ+2FhYfjggw907i1qbg/C50xApHs3zdzcXCxbtmzk3WSTsQeM5je3jh49auZIRi4+3jBD6e/zxmdyjDHGLBYnOcYYYxaLkxxjjDGLxUmOMcaYxRL2tyM3N9eUcTBmcTS3OeLPUv80Nx7mPmLDdfPmzb5vhv3r1eGaOxDwgx/84Ac/+PEgPfq640mvJQSMMeMRCATIycnB0qVLzR0KYw8F/k6OMcaYxeIkxxhjzGJxkmOMMWaxOMkxxhizWJzkGGOMWSxOcowxxiwWJznGGGMWi5McY4wxi8VJjjHGmMXiJMcYY8xicZJjjDFmsTjJMcYYs1ic5BhjjFksTnKMMcYsFic5xhhjFouTHGOMMYvFSY4xxpjF4iTHGGPMYnGSY4wxZrE4yTHGGLNYnOQYY4xZLE5yjDHGLBYnOcYYYxaLkxxjjDGLxUmOMcaYxeIkxxhjzGJxkmOMMWaxOMkxxhizWJzkGGOMWSxOcowxxiwWJznGGGMWi5McY4wxi8VJjjHGmMUSmjsAxizVe++9h59++qnX9hMnTuD69es621atWgVXV1dThcbYQ0NARGTuIBizRKtXr8Z//dd/QSKR9Fumq6sLjo6OqK2thVDI/3MyZmh8uZIxI3n22WcBAB0dHf0+rK2t8bvf/Y4THGNGwmdyjBkJEWHMmDH48ccf71vu7NmzmDlzpomiYuzhwmdyjBmJQCDA8uXLIRaL+y0zevRohISEmDAqxh4unOQYM6Jnn30WnZ2dfe4Ti8X4/e9/D4FAYOKoGHt48OVKxozM398fV69e7XNfSUkJgoKCTBwRYw8PPpNjzMhWrFgBkUjUa7ufnx8nOMaMjJMcY0a2YsUKdHd362wTiURYtWqVmSJi7OHBlysZM4GpU6eipKQEmo+bQCBARUUFxo8fb+bIGLNsfCbHmAk8//zzsLa2BvBzgnv88cc5wTFmApzkGDOBZ599Fmq1GgBgbW2N559/3swRMfZw4CTHmAl4eHhg1qxZEAgEUKvViI6ONndIjD0UOMkxZiLPPfcciAjz5s2Du7u7ucNh7KHAE08MJDc3F8uWLTN3GIwxCxAVFYWjR4+aOwyLwHeFNbCcnBxzh2Dx9uzZAwB4/fXXzRzJ4O3Zswd/+MMfYGtra9R2ioqKsHfvXh6PDyDN+GaGwUnOwJYuXWruECye5j/cB7GvZ8+ejdGjR5ukrb179z6QffSw4zM4w+Lv5BgzIVMlOMbYzzjJMcYYs1ic5BhjjFksTnKMMcYsFic5xhhjFouT3Ajy4osvQi6XQyAQ4MKFC+YOZ9DUajX27NmD0NDQPvefOXMGs2bNgkwmg4eHBxITE9HR0WHiKH928uRJ2Nvb46OPPjJL+yPdqVOnsHHjRuTl5cHHxwcCgQACgQDPPfdcr7Lz58+HXC6HtbU1AgICcP78eTNEfH9paWna13DvIzAwsFfZ+43j1NRUTJo0CQqFAhKJBH5+fvjjH/+IlpYWAMCHH36InTt3oqenx+iviemHk9wI8v777+O9994zdxhDcuXKFTz55JNYt24d2traeu0vKyvD/PnzERYWhvr6ehw/fhx//etfsWbNGjNEC/A9EPr35ptvIjMzE0lJSYiMjMS1a9fg6+uLUaNG4dChQ/jkk090yn/22Wc4evQonnnmGZSVlSE4ONhMkQ/fQOP4yy+/xNq1a1FZWYmGhgZs374de/fu1d6mbdGiRZBKpQgLC0NTU5Opw2d94CTHhu3777/HG2+8gTVr1mDq1Kl9ltm2bRvc3d2xdetW2NraYubMmUhMTMR///d/4+LFiyaOGFi4cCHu3r2LZ555xuRtA4BKper3jNec3nrrLRw5cgS5ubmQy+U6+zIzM2FlZYXY2FjcvXvXTBEO3cGDB0FEOo8ffvhBu1+fcWxnZ4fY2Fg4OTlBLpdj6dKliIiIwKeffoobN24AAF577TVMmTIFTz/9dK/fEWSmx0luhBEIBOYOYdCmTJmCvLw8LF++HBKJpNf+7u5ufPLJJ5g7d67O61uwYAGICCdOnDBluCPCgQMHUFdXZ+4wdFy9ehWbN2/G1q1bIZVKe+0PDQ1FfHw8bt26hQ0bNpghQuMaaBwDwMcff6z9ySQNZ2dnANA589uyZQsuXLiAvXv3Gi9gphdOcmZERMjIyMCECRMgkUhgb2+PhIQEnTI9PT1ISUmBl5cXbGxsMHnyZO2tmrKysmBrawuZTIYTJ05gwYIFUCgU8PT0xOHDh7V1nD59GjNmzIBMJoNCoUBQUBCUSuWA9RvKtWvX0NLSAi8vL53tvr6+AICSkhKDtjeQM2fOwMvLCwKBAO+88w4A/foyMzMTUqkUrq6uWL16NTw8PCCVShEaGopz584BAOLi4iAWi3VuwPzKK6/A1tYWAoEADQ0NiI+Px/r161FRUQGBQAA/Pz8AwKeffgqFQoH09HST9odGZmYmiAiLFi3qt0xaWhoeeeQRvP/++zh16lS/5YgIu3fvxqOPPgqJRAJHR0csXrxYe9au79g1xfgcrlu3bsHGxkbn9wEdHR0xd+5c7N27ly+Nmxsxg8jJyaHBdmdycjIJBAL685//TI2NjdTW1kb79u0jAFRcXExERBs2bCCJRELHjh2jxsZGSkpKIisrK/r222+1dQCgL774gu7evUt1dXU0Z84csrW1pc7OTmppaSGFQkE7d+4klUpFtbW1tGTJEqqvr9er/sF64oknaMqUKTrbTp8+TQAoIyOjV3kbGxsKCwsbVBtRUVEUFRU1pPg0bty4QQDo7bff1m4bqC+JiGJjY8nW1pbKy8upvb2dysrKaPr06SSXy6m6upqIiJYvX05ubm467WVkZBAAbb9HRkaSr6+vTpmPP/6Y5HI5paamDuu1EQ1tPPr4+NCkSZP63Ofr60vXr18nIqKzZ8+SlZUVjRs3jlpaWoiIqKCggMLDw7XlU1JSSCwW08GDB6mpqYlKSkooODiYnJ2dqba2loj0629Djc9t27aRp6cnOTg4kEgkonHjxlF4eDh98803fZbvaxz3pbW1leRyOcXFxfXat3HjRp3Psr4MMb7ZL/hMzkxUKhX27NmD3/zmN1i3bh0cHBxgY2MDJycnbZn29nZkZWUhIiICkZGRcHBwwKZNmyASiZCdna1TX2hoKBQKBVxcXBATE4PW1lZUV1ejsrISSqUSAQEBkEqlcHNzQ15eHpydnQdV/3BoZlD++jIPAIhEIqhUKoO1ZQj99aWGUCjUnqFMmjQJWVlZaG5uHnafLVy4EEqlEps3bx7uSxi01tZWXL9+XXt2fT8zZ87E66+/jsrKSrzxxhu99qtUKuzevRtLlizBihUrYG9vj6CgILz77rtoaGjA/v37dcr319+GHJ+///3v8eGHH+LGjRtoaWnB4cOHUV1djblz56KsrGxQdd1r+/bt8PDwQFpaWq99/v7+AIDS0tIh18+Gj5OcmVy9ehVtbW0ICwvrt8ylS5fQ1tamM83ZxsYG7u7u952sIRaLAQBdXV3w8fGBq6srVqxYgS1btqCysnLY9Q+W5vudvr6E7+zshI2NjcHaMrR7+7I/06ZNg0wmM8sEGkOpq6sDEUEmk+lVPi0tDRMmTMC+fftw5swZnX1lZWVoaWnBtGnTdLZPnz4dYrFYe2m3L/f2tyHH59ixY/HYY4/Bzs4OYrEYISEhyM7Ohkqlwr59+wZVl8bx48eRm5uLf/zjH70m6QDQ9uXt27eHVD8zDE5yZnLz5k0AgIuLS79lWltbAQCbNm3SWdtTVVXV5/TmvtjY2ODLL7/E7NmzkZ6eDh8fH8TExEClUhmkfn1ovp/SfA+o0dbWhvb2dnh4eBisLXORSCSor683dxhD1t7eDgD9Trj4NalUiuzsV90T1wAAIABJREFUbAgEArzwwgs6Z+OaqfN2dna9nufg4IDm5ma92jD2+AwKCoK1tTUuX7486OceOXIEb731FgoLCzFu3Lg+y2j+edP0LTMPTnJmojm7ud9iaE0C3LNnT6+pz0VFRXq3FRAQgI8++gg1NTVITExETk4Odu3aZbD6BzJ+/HjI5XJUVVXpbL969SoAYPLkyQZryxy6urrQ1NQET09Pc4cyZJoD8mAWMc+cORPr1q3DlStXsG3bNu12BwcHAOgzmQ2mn4w9PtVqNdRqtd6JXePtt9/GoUOH8OWXX973VyU6OzsBYERfqXgYcJIzk8DAQFhZWeH06dP9lhk7diykUumw7n5SU1OD8vJyAD8fNHbs2IHg4GCUl5cbpH59CIVCPP300/jqq6+gVqu12wsKCiAQCO47m+9BUFhYCCJCSEgIgJ9f7/0ub45Erq6uEAgEg17/tm3bNkycOBHFxcXabYGBgbCzs8N3332nU/bcuXPo7OzE448/rlfdhhyfv/3tb3tt+/bbb0FEmDlzpl51EBESExNRWlqK/Pz8Ps9U76XpSzc3t8EHzAyGk5yZuLi4ICoqCseOHcOBAwegVCpRUlKi86W8VCrFqlWrcPjwYWRlZUGpVKKnpwc3b97Ejz/+qFc7NTU1WL16NS5evIjOzk4UFxejqqoKISEhBqlfX5s3b8bt27fx5ptvorW1FUVFRcjIyMDKlSsxYcIEg7ZlbGq1Go2Njeju7kZJSQni4+Ph5eWFlStXAgD8/Pzw008/IT8/H11dXaivr+91Fuvk5ISamhpUVlaiubkZXV1dKCgoMNsSAplMBh8fH+1ldH1pLlveO6lIKpVi/fr1OH78OA4dOgSlUonS0lKsWbMGHh4eiI2N1bvugcZnTEwM3NzcBryV2K1bt3DkyBE0NTWhq6sLRUVFePHFF+Hl5aX3XXfKy8vxpz/9Ce+99x5EIlGvW4Tt2rVLp7ymL4OCgvSqnxmJ6Sd0WqahTNlubm6ml156iUaNGkV2dnY0e/ZsSklJIQDk6elJ33//PXV0dFBiYiJ5eXmRUCgkFxcXioyMpLKyMtq3bx/JZDICQP7+/lRRUUH79+8nhUJBAMjb25s+//xzCg0NJUdHR7K2tqbRo0dTcnIydXd3ExHdt359FRUV0axZs8jDw4MAEAByd3en0NBQOn36tLbc6dOnacaMGSSRSMjDw4MSEhKovb19UH1GNPwp1m+//Ta5u7sTAJLJZLRo0SK9+vLy5csUGxtLIpGIxowZQ0KhkBQKBS1evJgqKiq09d+5c4eeeuopkkqlNH78eHr11VcpISGBAJCfnx9VV1fT+fPnydvbm2xsbGj27NlUW1tLJ0+eJLlcTmlpaUN+bRpDGY9xcXEkEomora1Nu+348ePk6+tLAMjZ2ZnWrl3b53MTEhJ0lhCo1WrKyMggf39/EolE5OjoSBEREXTp0iUiIr37e6DxGRERQQAoJSXlvq9t/fr15OvrS7a2tiQUCsnT05Neeuklqqmp0ZYZaByXlpZqt/f1+PUSmYULF9KYMWNIrVYP6n3gJQSGxUnOQIZyUGFDY86DQGxsLDk5OZml7cEYyni8cuUKCYVCOnjwoJGiMryenh6aM2cOHThwwNyh6GhoaCCpVEq7du0a9HM5yRkWX65kbJAs9Q7zfn5+SE1NRWpqqvau+iNZT08P8vPz0dzcjJiYGHOHo2PLli2YOnUq4uLizB3KQ4+THOvTxYsX+/xpkl8/RtrBhQ3Pxo0bER0djZiYmBF/E+bCwkLk5eWhoKBA7/V9prB7925cuHABJ0+ehEgkMnc4Dz1OcqxPEydO7DVtu6/HkSNHzB2qySQlJSE7Oxt3797F+PHjcezYMXOHZBTp6emIi4vDjh07zB3KfYWFheGDDz7QuU+ouZ04cQIdHR0oLCyEo6OjucNhAITmDoCxB8X27duxfft2c4dhEvPnz8f8+fPNHcYDJzw8HOHh4eYOg92Dz+QYY4xZLE5yjDHGLBYnOcYYYxaLkxxjjDGLxRNPDCw3N9fcIVg8ze2SuK/7p7mBMffRg+fmzZsP9M2+RxoBEf82uyHk5uZi2bJl5g6DMWYBoqKicPToUXOHYRH4TM7A+H8G44uOjgYAPgjch+afLh6PDx7N+GaGwd/JMcYYs1ic5BhjjFksTnKMMcYsFic5xhhjFouTHGOMMYvFSY4xxpjF4iT3gMjLy4OPj0+v33MTi8VwdXXFvHnzkJGRgcbGRnOHyizUqVOnsHHjxl5j8bnnnutVdv78+ZDL5bC2tkZAQADOnz9vhogH1tXVhe3bt8PPzw9isRgODg4IDAxEZWVln+Xb29sxceJEbNq0CQDw4YcfYufOnRb7Q7qWgJPcAyIyMhLXrl2Dr68v7O3tQURQq9Woq6tDbm4uxo8fj8TERAQEBOC7774zd7jMwrz55pvIzMxEUlKSzlgcNWoUDh06hE8++USn/GeffYajR4/imWeeQVlZGYKDg80U+f0tW7YMf/vb3/DBBx+gra0N//rXv+Dr69vvL6MnJyfj0qVL2r8XLVoEqVSKsLAwNDU1mSpsNgic5B5gAoEADg4OmDdvHrKzs5Gbm4vbt29j4cKFI/5XnR9UKpUKoaGhD1zdw/HWW2/hyJEjyM3NhVwu19mXmZkJKysrxMbGPnBj7siRI8jPz8fRo0fxxBNPQCgUwsPDAydOnEBgYGCv8mfPnsUPP/zQa/trr72GKVOm4Omnn0Z3d7cpQmeDwEnOgkRFRWHlypWoq6vDu+++a+5wLNKBAwdQV1f3wNU9VFevXsXmzZuxdetWSKXSXvtDQ0MRHx+PW7duYcOGDWaIcOj+8pe/IDg4GEFBQQOWValUSEhIwN69e/vcv2XLFly4cKHf/cx8OMlZmJUrVwIACgoKAAA9PT1ISUmBl5cXbGxsMHnyZOTk5AAAsrKyYGtrC5lMhhMnTmDBggVQKBTw9PTE4cOHtXWePn0aM2bMgEwmg0KhQFBQEJRK5YD1jyREhN27d+PRRx+FRCKBo6MjFi9ejIsXLwIA4uLiIBaL4e7urn3OK6+8AltbWwgEAjQ0NCA+Ph7r169HRUUFBAIB/Pz8kJmZCalUCldXV6xevRoeHh6QSqUIDQ3FuXPnhlU3AHz66adQKBRIT083YW/9IjMzE0SERYsW9VsmLS0NjzzyCN5//32cOnWq33IDvQf6jkdDjLnOzk58/fXXmDp1ql7lk5OT8corr8DFxaXP/Y6Ojpg7dy727t3Lt1IbaYgZRE5ODpmiO319fcne3r7f/UqlkgDQ2LFjiYhow4YNJJFI6NixY9TY2EhJSUlkZWVF3377LRERJScnEwD64osv6O7du1RXV0dz5swhW1tb6uzspJaWFlIoFLRz505SqVRUW1tLS5Ysofr6er3qN4aoqCiKiooa1HNSUlJILBbTwYMHqampiUpKSig4OJicnZ2ptraWiIiWL19Obm5uOs/LyMggANrXGxkZSb6+vjplYmNjydbWlsrLy6m9vZ3Kyspo+vTpJJfLqbq6elh1f/zxxySXyyk1NXVQr9dQ49HHx4cmTZrU5z5fX1+6fv06ERGdPXuWrKysaNy4cdTS0kJERAUFBRQeHq4tr897MNB4JDLMmLt+/ToBoKlTp9K8efPI3d2dJBIJTZw4kd555x1Sq9XasmfOnKFFixYREVF9fT0BoOTk5F51bty4kQBQcXGx3nH0ZSjjm/WPz+QsjFwuh0AgQHNzM9rb25GVlYWIiAhERkbCwcEBmzZtgkgkQnZ2ts7zQkNDoVAo4OLigpiYGLS2tqK6uhqVlZVQKpUICAiAVCqFm5sb8vLy4OzsPKj6zUmlUmH37t1YsmQJVqxYAXt7ewQFBeHdd99FQ0MD9u/fP+w2hEKh9gxl0qRJyMrKQnNz87D7YeHChVAqldi8efOwYxys1tZWXL9+Hb6+vgOWnTlzJl5//XVUVlbijTfe6LV/sO9Bf+PRUGNOM7HExcUF6enpKCsrw+3bt7F48WKsXbsWf//737Vxx8fHIysra8A6/f39AQClpaV6x8GMj5OchWltbQURQaFQ4NKlS2hra9P5Et3Gxgbu7u7aS0R9EYvFAH6eXu3j4wNXV1esWLECW7Zs0ZlaPdT6Ta2srAwtLS2YNm2azvbp06dDLBZrLysa0rRp0yCTyUZUPwxWXV0diAgymUyv8mlpaZgwYQL27duHM2fO6Owbzntw73g01JiTSCQAgICAAISGhsLJyQn29vbYunUr7O3ttUk3KSkJf/jDHzBmzJgB69T00+3bt/WOgxkfJzkLc/nyZQDAxIkT0draCgDYtGmTztq6qqoqtLW16VWfjY0NvvzyS8yePRvp6enw8fFBTEwMVCqVQeo3Bc3Ubjs7u177HBwc0NzcbJR2JRIJ6uvrjVK3KbS3twP4JSEMRCqVIjs7GwKBAC+88AJUKpV2n6HeA0ONOQ8PDwBAQ0ODznaxWAxvb29UVFTgzJkzKC0txYsvvqhXnTY2NgB+6Tc2MnCSszCffvopAGDBggXaL8n37NkDItJ5aH45Wh8BAQH46KOPUFNTg8TEROTk5GDXrl0Gq9/YHBwcAKDPA2lTU5NRfoW5q6vLaHWbiuagPZiFzjNnzsS6detw5coVbNu2TbvdUO+BocacnZ0d/P39UV5e3mtfd3c37O3tceDAAXzxxRewsrLSJlNN++np6RAIBDprUjs7OwH80m9sZOAkZ0Fqa2uxZ88eeHp64oUXXsDYsWMhlUpx4cKFIddZU1OjPRC4uLhgx44dCA4ORnl5uUHqN4XAwEDY2dn1WiR/7tw5dHZ24vHHHwfw8/dqXV1dBmmzsLAQRISQkBCD120qrq6uEAgEg17/tm3bNkycOBHFxcXabfq+BwMx5JhbtmwZiouLce3aNe22trY2VFVVISgoCNnZ2b0SqebMPDk5GUSkc/lV009ubm7Djo0ZDie5BxARoaWlBWq1WvvBy8nJwaxZs2BtbY38/HwoFApIpVKsWrUKhw8fRlZWFpRKJXp6enDz5k38+OOPerVVU1OD1atX4+LFi+js7ERxcTGqqqoQEhJikPpNQSqVYv369Th+/DgOHToEpVKJ0tJSrFmzBh4eHoiNjQUA+Pn54aeffkJ+fj66urpQX1+PqqoqnbqcnJxQU1ODyspKNDc3axOXWq1GY2Mjuru7UVJSgvj4eHh5eWmXdAy17oKCArMtIZDJZPDx8cHNmzcH9TzNZUtra2udbfq8B/rUPdCYi4mJgZub24C3Elu3bh28vb2xcuVKVFdX486dO0hMTIRKpepz8sxANP2kz7o7ZkKmnMppyYy9hODDDz+kyZMnk0wmI7FYTFZWVgSABAIBOTg40IwZMyg1NZXu3Lmj87yOjg5KTEwkLy8vEgqF5OLiQpGRkVRWVkb79u0jmUxGAMjf358qKipo//79pFAoCAB5e3vT559/TqGhoeTo6EjW1tY0evRoSk5Opu7u7gHrN5ahTLFWq9WUkZFB/v7+JBKJyNHRkSIiIujSpUvaMnfu3KGnnnqKpFIpjR8/nl599VVKSEggAOTn50fV1dV0/vx58vb2JhsbG5o9ezbV1tZSbGwsiUQiGjNmDAmFQlIoFLR48WKqqKgYdt0nT54kuVxOaWlpg3q9hhqPcXFxJBKJqK2tTbvt+PHj5OvrSwDI2dmZ1q5d2+dzExISdJYQDPQe6DMeL1++POCYi4iIIACUkpIy4Ou7ceMGPfvss+To6EgSiYRmzJhBBQUF/Za/3xKChQsX0pgxY3SWHwwFLyEwLE5yBmKqdXJs5B0EYmNjycnJydxh6DDUeLxy5QoJhUI6ePCgAaIyjZ6eHpozZw4dOHDAZG02NDSQVCqlXbt2DbuukTa+H3R8uZIxA7DUu9D7+fkhNTUVqamp/d60eCTp6elBfn4+mpubERMTY7J2t2zZgqlTpyIuLs5kbTL9cJJjjN3Xxo0bER0djZiYmBF/E+bCwkLk5eWhoKBA7/V9w7V7925cuHABJ0+ehEgkMkmbTH+c5BgbhqSkJGRnZ+Pu3bsYP348jh07Zu6QjCI9PR1xcXHYsWOHuUO5r7CwMHzwwQc69wk1phMnTqCjowOFhYVwdHQ0SZtscITmDoCxB9n27duxfft2c4dhEvPnz8f8+fPNHcaIEh4ejvDwcHOHwe6Dz+QYY4xZLE5yjDHGLBYnOcYYYxaLkxxjjDGLxRNPDCw6OtrcIVi8r7/+GgD39f1objHFffTg+frrr7X3PGXDJyDi32o3hKKiIuzevdvcYbAR7osvvkBgYCDfxJfdl+bXHNjwcZJjzIQEAgFycnKwdOlSc4fC2EOBv5NjjDFmsTjJMcYYs1ic5BhjjFksTnKMMcYsFic5xhhjFouTHGOMMYvFSY4xxpjF4iTHGGPMYnGSY4wxZrE4yTHGGLNYnOQYY4xZLE5yjDHGLBYnOcYYYxaLkxxjjDGLxUmOMcaYxeIkxxhjzGJxkmOMMWaxOMkxxhizWJzkGGOMWSxOcowxxiwWJznGGGMWi5McY4wxi8VJjjHGmMXiJMcYY8xicZJjjDFmsTjJMcYYs1ic5BhjjFksTnKMMcYsFic5xhhjFouTHGOMMYvFSY4xxpjF4iTHGGPMYnGSY4wxZrEERETmDoIxS/T888+juLhYZ9uNGzcwatQoyGQy7TaRSISPP/4Yo0ePNnWIjFk8obkDYMxSTZgwAQcPHuy1/e7duzp/T5o0iRMcY0bClysZM5IVK1ZAIBDct4xIJMLKlStNExBjDyFOcowZibe3N4KDg++b6Lq7uxEdHW3CqBh7uHCSY8yInn/+eVhbW/e5z8rKCiEhIRg3bpxpg2LsIcJJjjEjiomJgVqt7nOflZUVnn/+eRNHxNjDhZMcY0bk6uqKuXPn9nk2R0RYsmSJGaJi7OHBSY4xI3vuuefw65U61tbW+M1vfgNXV1czRcXYw4GTHGNGFhkZCaFQd7UOEWHFihVmioixhwcnOcaMTKFQYMGCBTqJTigUYtGiRWaMirGHAyc5xkxgxYoV6OnpAfBzggsPD4dCoTBzVIxZPk5yjJnAf/zHf2hv5dXT04Ply5ebOSLGHg6c5BgzAalUisjISACAra0t/v3f/93METH2cOB7VxpRUVERbty4Ye4w2Ajh6ekJAJg+fTpOnDhh5mjYSLJ06VJzh2Cx+FcIjCg6OhrHjh0zdxiMsRGOD8PGw5crjSwqKgpExA8jPwAgJyfH7HEM9EhLS0N3d7dZ2o6KiuLxOMIeOTk5Zj5CWT5OcoyZUGJiYr/3smSMGR4nOcZM6NeLwhljxsVJjjHGmMXiJMcYY8xicZJjjDFmsTjJMcYYs1ic5Ea4F198EXK5HAKBABcuXDB3OIOmVquxZ88ehIaGDquMKZw8eRL29vb46KOPzBrHSHXq1Cls3LgReXl58PHxgUAggEAgwHPPPder7Pz58yGXy2FtbY2AgACcP3/eDBEPrKurC9u3b4efnx/EYjEcHBwQGBiIysrKPsu3t7dj4sSJ2LRpEwDgww8/xM6dO7X3JWUjDye5Ee7999/He++9Z+4whuTKlSt48sknsW7dOrS1tQ25jKkQ8YLc/rz55pvIzMxEUlISIiMjce3aNfj6+mLUqFE4dOgQPvnkE53yn332GY4ePYpnnnkGZWVlCA4ONlPk97ds2TL87W9/wwcffIC2tjb861//gq+vL1paWvosn5ycjEuXLmn/XrRoEaRSKcLCwtDU1GSqsNkg8HxmZhTff/89UlNTsWbNGrS2tvaZQPQpY0oLFy7E3bt3zda+SqVCWFgYzp49a7YY+vLWW2/hyJEj+P777yGVSnX2ZWZm4rnnnkNsbCzKyspgb29vpigH78iRI8jPz8f333+PoKAgAICHh0e/t1w7e/Ysfvjhh17bX3vtNVy7dg1PP/00vvrqK14mMsLwmdwDQCAQmDuEQZsyZQry8vKwfPlySCSSIZd5mBw4cAB1dXXmDkPH1atXsXnzZmzdurVXggOA0NBQxMfH49atW9iwYYMZIhy6v/zlLwgODtYmuPtRqVRISEjA3r17+9y/ZcsWXLhwod/9zHw4yY0wRISMjAxMmDABEokE9vb2SEhI0CnT09ODlJQUeHl5wcbGBpMnT9beHigrKwu2traQyWQ4ceIEFixYAIVCAU9PTxw+fFhbx+nTpzFjxgzIZDIoFAoEBQVBqVQOWL+lOnPmDLy8vCAQCPDOO+8A0K8vMzMzIZVK4erqitWrV8PDwwNSqRShoaE4d+4cACAuLg5isRju7u7a9l555RXY2tpCIBCgoaEB8fHxWL9+PSoqKiAQCODn5wcA+PTTT6FQKJCenm7iHoH29RHRfX/gNS0tDY888gjef/99nDp1qt9yRITdu3fj0UcfhUQigaOjIxYvXoyLFy8C0H/sGmJ8dnZ24uuvv8bUqVP1Kp+cnIxXXnkFLi4ufe53dHTE3LlzsXfvXrNfkWC/QsxooqKiKCoqalDPSU5OJoFAQH/+85+psbGR2traaN++fQSAiouLiYhow4YNJJFI6NixY9TY2EhJSUlkZWVF3377rbYOAPTFF1/Q3bt3qa6ujubMmUO2trbU2dlJLS0tpFAoaOfOnaRSqai2tpaWLFlC9fX1etU/WE888QRNmTJl2GXuBwDl5OQM+flERDdu3CAA9Pbbb2u3DdSXRESxsbFka2tL5eXl1N7eTmVlZTR9+nSSy+VUXV1NRETLly8nNzc3nfYyMjIIgLbfIyMjydfXV6fMxx9/THK5nFJTU4f12oiGNh59fHxo0qRJfe7z9fWl69evExHR2bNnycrKisaNG0ctLS1ERFRQUEDh4eHa8ikpKSQWi+ngwYPU1NREJSUlFBwcTM7OzlRbW0tE+vW3Icbn9evXCQBNnTqV5s2bR+7u7iSRSGjixIn0zjvvkFqt1pY9c+YMLVq0iIiI6uvrCQAlJyf3qnPjxo06n1N95OTkEB+GjYvP5EYQlUqFPXv24De/+Q3WrVsHBwcH2NjYwMnJSVumvb0dWVlZiIiIQGRkJBwcHLBp0yaIRCJkZ2fr1BcaGgqFQgEXFxfExMSgtbUV1dXVqKyshFKpREBAAKRSKdzc3JCXlwdnZ+dB1f8w6a8vNYRCofYMZdKkScjKykJzc/Ow+2zhwoVQKpXYvHnzcF/CoLW2tuL69evw9fUdsOzMmTPx+uuvo7KyEm+88Uav/SqVCrt378aSJUuwYsUK2NvbIygoCO+++y4aGhqwf/9+nfL99behxqdmYomLiwvS09NRVlaG27dvY/HixVi7di3+/ve/a+OOj49HVlbWgHX6+/sDAEpLS/WOgxkfJ7kR5OrVq2hra0NYWFi/ZS5duoS2tjYEBgZqt9nY2MDd3V172acvYrEYwM9Tpn18fODq6ooVK1Zgy5YtOtOlh1r/w+TevuzPtGnTIJPJHug+q6urAxFpf9F8IGlpaZgwYQL27duHM2fO6OwrKytDS0sLpk2bprN9+vTpEIvF2ku7fbm3vw01PjXfAQcEBCA0NBROTk6wt7fH1q1bYW9vr026SUlJ+MMf/oAxY8YMWKemn27fvq13HMz4OMmNIDdv3gSAfq/7Az//dw0AmzZt0q5TEggEqKqq0nsKvo2NDb788kvMnj0b6enp8PHxQUxMDFQqlUHqZz+TSCSor683dxhD1t7eDgB6TwqSSqXIzs6GQCDACy+8AJVKpd2nmV5vZ2fX63kODg5obm7Wqw1DjU8PDw8AQENDg852sVgMb29vVFRU4MyZMygtLcWLL76oV502NjYAfuk3NjJwkhtBNLPXOjo6+i2jSYB79uzp9dtURUVFercVEBCAjz76CDU1NUhMTEROTg527dplsPofdl1dXWhqatL+GviDSHPQHsxC55kzZ2LdunW4cuUKtm3bpt3u4OAAAH0ms8H0k6HGp52dHfz9/VFeXt5rX3d3N+zt7XHgwAF88cUXsLKy0iZTTfvp6ekQCAT47rvvtM/r7OwE8Eu/sZGBk9wIEhgYCCsrK5w+fbrfMmPHjoVUKh3W3U9qamq0H24XFxfs2LEDwcHBKC8vN0j9DCgsLAQRISQkBMDP39nd7/LmSOTq6gqBQDDotYPbtm3DxIkTUVxcrN0WGBgIOzs7naQAAOfOnUNnZycef/xxveo25PhctmwZiouLce3aNe22trY2VFVVISgoCNnZ2b0SqebMPDk5GUSkc/lV009ubm7Djo0ZDie5EcTFxQVRUVE4duwYDhw4AKVSiZKSEp0v5aVSKVatWoXDhw8jKysLSqUSPT09uHnzJn788Ue92qmpqcHq1atx8eJFdHZ2ori4GFVVVQgJCTFI/Q8jtVqNxsZGdHd3o6SkBPHx8fDy8sLKlSsBAH5+fvjpp5+Qn5+Prq4u1NfXo6qqSqcOJycn1NTUoLKyEs3Nzejq6kJBQYHZlhDIZDL4+PhoL6PrS3PZ8t4fh5VKpVi/fj2OHz+OQ4cOQalUorS0FGvWrIGHhwdiY2P1rnug8RkTEwM3N7cBbyW2bt06eHt7Y+XKlaiursadO3eQmJgIlUrV5+SZgWj6SZ91d8yETDyb86EylCnbzc3N9NJLL9GoUaPIzs6OZs+eTSkpKQSAPD096fvvv6eOjg5KTEwkLy8vEgqF5OLiQpGRkVRWVkb79u0jmUxGAMjf358qKipo//79pFAoCAB5e3vT559/TqGhoeTo6EjW1tY0evRoSk5Opu7ubiKi+9avr6KiIpo1axZ5eHgQAAJA7u7uFBoaSqdPn9a7jL4wzCUEb7/9Nrm7uxMAkslktGjRIr368vLlyxQbG0sikYjGjBlDQqGQFAoFLV68mCoqKrT137lzh5566imSSqU0fvx4evXVVykhIYEAkJ+fH1VXV9P58+fJ29ubbGxsaPbs2VRbW0snT54kuVxOaWlpQ35tGkMZj3FxcSQSiagkmIhWAAANE0lEQVStrU277fjx4+Tr60sAyNnZmdauXdvncxMSEnSWEKjVasrIyCB/f38SiUTk6OhIERERdOnSJSIivft7oPEZERFBACglJWXA13fjxg169tlnydHRkSQSCc2YMYMKCgr6LX+/JQQLFy6kMWPG6Cw/GAgvITA+7l0jGspBhQ3NcJPccMTGxpKTk5NZ2h6MoYzHK1eukFAopIMHDxopKsPr6emhOXPm0IEDB0zWZkNDA0mlUtq1a9egnsdJzvj4ciVjBmCpd6H38/NDamoqUlNT+71p8UjS09OD/Px8NDc3IyYmxmTtbtmyBVOnTkVcXJzJ2mT64STH9Hbx4kWdadv9PUx5cGHGt3HjRkRHRyMmJsasN7DWR2FhIfLy8lBQUKD3+r7h2r17Ny5cuICTJ09CJBKZpE2mP05yTG8TJ07sNdusr8eRI0fMHarJJCUlITs7G3fv3sX48eNx7Ngxc4dkFOnp6YiLi8OOHTvMHcp9hYWF4YMPPtC5T6gxnThxAh0dHSgsLISjo6NJ2mSDw78JwdgwbN++Hdu3bzd3GCYxf/58zJ8/39xhjCjh4eEIDw83dxjsPvhMjjHGmMXiJMcYY8xicZJjjDFmsTjJMcYYs1g88cTIvv76a0RHR5s7jIfCnj17cPToUXOHMWJ9/fXXAMDjcQQZ7C3T2ODxmRxjjDGLxWdyRhYSEsJnFyYgEAjw+uuvY+nSpeYOZcTSnMHxeBw5cnNzsWzZMnOHYdH4TI4xxpjF4iTHGGPMYnGSY4wxZrE4yTHGGLNYnOQYY4xZLE5yD7C8vDz4+Pj0+qkbsVgMV1dXzJs3DxkZGWhsbDR3qMwCnTp1Chs3buw1Dp977rleZefPnw+5XA5ra2sEBATg/PnzZohYP2q1Gnv27EFoaKjO9g8//BA7d+602N8OtFSc5B5gkZGRuHbtGnx9fWFvbw8iglqtRl1dHXJzczF+/HgkJiYiICAA3333nbnDZRbkzTffRGZmJpKSknTG4ahRo3Do0CF88sknOuU/++wzHD16FM888wzKysoQHBxspsjv78qVK3jyySexbt06tLW16exbtGgRpFIpwsLC0NTUZKYI2WBxkrMwAoEADg4OmDdvHrKzs5Gbm4vbt29j4cKFI/4HLx9EKpWq13/8D0Ldw/HWW2/hyJEjyM3NhVwu19mXmZkJKysrxMbGPnDj7fvvv8cbb7yBNWvWYOrUqX2Wee211zBlyhQ8/fTT6O7uNnGEbCg4yVm4qKgorFy5EnV1dXj33XfNHY7FOXDgAOrq6h64uofq6tWr2Lx5M7Zu3QqpVNprf2hoKOLj43Hr1i1s2LDBDBEO3ZQpU5CXl4fly5dDIpH0W27Lli24cOEC9u7da8Lo2FBxknsIrFy5EgBQUFAAAOjp6UFKSgq8vLxgY2ODyZMnIycnBwCQlZUFW1tbyGQynDhxAgsWLIBCoYCnpycOHz6srfP06dOYMWMGZDIZFAoFgoKCoFQqB6x/pCAi7N69G48++igkEgkcHR2xePFiXLx4EQAQFxcHsVis8wvTr7zyCmxtbSEQCNDQ0ID4+HisX78eFRUVEAgE8PPzQ2ZmJqRSKVxdXbF69Wp4eHhAKpUiNDQU586dG1bdAPDpp59CoVAgPT3dhL31i8zMTBARFi1a1G+ZtLQ0PPLII3j//fdx6tSpfssN9B7oOxZNPd4cHR0xd+5c7N27F0RktHaYgRAzmqioKIqKijJ6O76+vmRvb9/vfqVSSQBo7NixRES0YcMGkkgkdOzYMWpsbKSkpCSysrKib7/9loiIkpOTCQB98cUXdPfuXaqrq6M5c+aQra0tdXZ2UktLCykUCtq5cyepVCqqra2lJUuWUH19vV71GwMAysnJ0bt8SkoKicViOnjwIDU1NVFJSQkFBweTs7Mz1dbWEhHR8uXLyc3NTed5GRkZBED7WiMjI8nX11enTGxsLNna2lJ5eTm1t7dTWVkZTZ8+neRyOVVXVw+r7o8//pjkcjmlpqbq/Vo1DDEefXx8aNKkSX3u8/X1pevXrxMR0dmzZ8nKyorGjRtHLS0tRERUUFBA4eHh2vL6vAcDjUUi44y3J554gqZMmdLv/o0bNxIAKi4uHnIbREQ5OTnEh2Hj4jO5h4BcLodAIEBzczPa29uRlZWFiIgIREZGwsHBAZs2bYJIJEJ2drbO80JDQ6FQKODi4oKYmBi0traiuroalZWVUCqVCAgIgFQqhZubG/Ly8uDs7Dyo+s1FpVJh9+7dWLJkCVasWAF7e3sEBQXh3XffRUNDA/bv3z/sNoRCofYMZdKkScjKykJzc/Ow+2DhwoVQKpXYvHnzsGMcrNbWVly/fh2+vr4Dlp05cyZef/11VFZW4o033ui1f7DvQX9j0Vzjzd/fHwBQWlpqtDaYYXCSewi0traCiKBQKHDp0iW0tbUhMDBQu9/Gxgbu7u7ay0R9EYvFAICuri74+PjA1dUVK1aswJYtW1BZWaktN9T6TamsrAwtLS2YNm2azvbp06dDLBZrLysa0rRp0yCTyUZMHwxFXV0diAgymUyv8mlpaZgwYQL27duHM2fO6Owbzntw71g013jT9MHt27eN1gYzDE5yD4HLly8DACZOnIjW1lYAwKZNm3TW1lVVVfWaMt0fGxsbfPnll5g9ezbS09Ph4+ODmJgYqFQqg9RvbJrp33Z2dr32OTg4oLm52SjtSiQS1NfXG6VuU2hvbweA+07KuJdUKkV2djYEAgFeeOEFqFQq7T5DvQfmGm82NjYAfukTNnJxknsIfPrppwCABQsWwMXFBcDPPzBKRDqPoqIivesMCAjARx99hJqaGiQmJiInJwe7du0yWP3G5ODgAAB9Hkibmprg6elp8Da7urqMVrepaA7sg1kMPXPmTKxbtw5XrlzBtm3btNsN9R6Ya7x1dnYC+KVP2MjFSc7C1dbWYs+ePfD09MQLL7yAsWPHQiqV4sKFC0Ous6amBuXl5QB+Psjs2LEDwcHBKC8vN0j9xhYYGAg7O7teC+TPnTuHzs5OPP744wB+/l6tq6vLIG0WFhaCiBASEmLwuk3F1dUVAoFg0Ovftm3bhokTJ6K4uFi7Td/3YCDmGm+aPnBzczNpu2zwOMlZCCJCS0sL1Go1iAj19fXIycnBrFmzYG1tjfz8fCgUCkilUqxatQqHDx9GVlYWlEolenp6cPPmTfz44496tVVTU4PVq1fj4sWL6OzsRHFxMaqqqhASEmKQ+o1NKpVi/fr1OH78OA4dOgSlUonS0lKsWbMGHh4eiI2NBQD4+fnhp59+Qn5+Prq6ulBfX4+qqiqdupycnFBTU4PKyko0NzdrE5darUZjYyO6u7tRUlKC+Ph4eHl5aZdzDLXugoICsy0hkMlk8PHxwc2bNwf1PM1lS2tra51t+rwH+tQ90HiLiYmBm5ubQW8lpumDoKAgg9XJjMTk8zkfIsZeQvDhhx/S5MmTSSaTkVgsJisrKwJAAoGAHBwcaMaMGZSamkp37tzReV5HRwclJiaSl5cXCYVCcnFxocjISCorK6N9+/aRTCYjAOTv708VFRW0f/9+UigUBIC8vb3p888/p9DQUHJ0dCRra2saPXo0JScnU3d394D1GwsGuYRArVZTRkYG+fv7k0gkIkdHR4qIiKBLly5py9y5c4eeeuopkkqlNH78eHr11VcpISGBAJCfnx9VV1fT+fPnydvbm2xsbGj27NlUW1tLsbGxJBKJaMyYMSQUCkmhUNDixYupoqJi2HWfPHmS5HI5paWlDbqPDDEe4+LiSCQSUVtbm3bb8ePHydfXlwCQs7MzrV27ts/nJiQk6CwhGOg90GcsXr58ecDxFhERQQAoJSXlvq+tqKiIZs2aRR4eHgSAAJC7uzuFhobS6dOndcouXLiQxowZQ2q1ekj9qMFLCIyPe9eITLVOjg0+yRlTbGwsOTk5mTuMXgwxHq9cuUJCoZAOHjxooKiMr6enh+bMmUMHDhwwSH0NDQ0klUpp165dw66Lk5zx8eVKxozAUu9U7+fnh9TUVKSmpqKlpcXc4Qyop6cH+fn5aG5uRkxMjEHq3LJlC6ZOnYq4uDiD1MeMi5McY2xQNm7ciOjoaMTExIz4mzAXFhYiLy8PBQUFeq/vu5/du3fjwoULOHnyJEQikQEiZMbGSY4xA0pKSkJ2djbu3r2L8ePH49ixY+YOySjS09MRFxeHHTt2mDuU+woLC8MHH3ygc5/QoTpx4gQ6OjpQWFgIR0dHA0THTEFo7gAYsyTbt2/H9u3bzR2GScyfPx/z5883dxgmEx4ejvDwcHOHwQaJz+QYY4xZLE5yjDHGLBYnOcYYYxaLkxxjjDGLxUmOMcaYxRIQ8e+3G0t0dLTFTiFnjBkOH4aNh5OcERUVFeHGjRvmDoMxNsItXbrU3CFYLE5yjDHGLBZ/J8cYY8xicZJjjDFmsTjJMcYYs1hCAEfNHQRjjDFmDP8fTTUmJAbFvc0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adafactor(1e-3), metrics=['accuracy'])\n",
        "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=30, batch_size=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXy7keu-7ij2",
        "outputId": "a271b209-9969-43c2-ba4f-9e5090ad6b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1125/1125 [==============================] - 63s 48ms/step - loss: 0.6842 - accuracy: 0.5673 - val_loss: 0.6808 - val_accuracy: 0.5600\n",
            "Epoch 2/30\n",
            "1125/1125 [==============================] - 35s 31ms/step - loss: 0.6395 - accuracy: 0.6233 - val_loss: 0.6067 - val_accuracy: 0.6820\n",
            "Epoch 3/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.5005 - accuracy: 0.7564 - val_loss: 0.5612 - val_accuracy: 0.7020\n",
            "Epoch 4/30\n",
            "1125/1125 [==============================] - 32s 28ms/step - loss: 0.4110 - accuracy: 0.8189 - val_loss: 0.6596 - val_accuracy: 0.6660\n",
            "Epoch 5/30\n",
            "1125/1125 [==============================] - 32s 29ms/step - loss: 0.3156 - accuracy: 0.8691 - val_loss: 0.6586 - val_accuracy: 0.7220\n",
            "Epoch 6/30\n",
            "1125/1125 [==============================] - 32s 29ms/step - loss: 0.2372 - accuracy: 0.9078 - val_loss: 0.6309 - val_accuracy: 0.7280\n",
            "Epoch 7/30\n",
            "1125/1125 [==============================] - 31s 27ms/step - loss: 0.1705 - accuracy: 0.9353 - val_loss: 0.8207 - val_accuracy: 0.7340\n",
            "Epoch 8/30\n",
            "1125/1125 [==============================] - 31s 27ms/step - loss: 0.1131 - accuracy: 0.9584 - val_loss: 1.2297 - val_accuracy: 0.7080\n",
            "Epoch 9/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0761 - accuracy: 0.9749 - val_loss: 1.2467 - val_accuracy: 0.7280\n",
            "Epoch 10/30\n",
            "1125/1125 [==============================] - 33s 29ms/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 1.3778 - val_accuracy: 0.7440\n",
            "Epoch 11/30\n",
            "1125/1125 [==============================] - 32s 28ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 1.8084 - val_accuracy: 0.7140\n",
            "Epoch 12/30\n",
            "1125/1125 [==============================] - 32s 28ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 1.7873 - val_accuracy: 0.7400\n",
            "Epoch 13/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 2.0619 - val_accuracy: 0.7260\n",
            "Epoch 14/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 2.0862 - val_accuracy: 0.7140\n",
            "Epoch 15/30\n",
            "1125/1125 [==============================] - 31s 27ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 2.1516 - val_accuracy: 0.7320\n",
            "Epoch 16/30\n",
            "1125/1125 [==============================] - 31s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.1971 - val_accuracy: 0.7220\n",
            "Epoch 17/30\n",
            "1125/1125 [==============================] - 33s 29ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 2.3788 - val_accuracy: 0.7400\n",
            "Epoch 18/30\n",
            "1125/1125 [==============================] - 32s 28ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 2.1273 - val_accuracy: 0.7280\n",
            "Epoch 19/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 2.3357 - val_accuracy: 0.7300\n",
            "Epoch 20/30\n",
            "1125/1125 [==============================] - 33s 29ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 2.4114 - val_accuracy: 0.7260\n",
            "Epoch 21/30\n",
            "1125/1125 [==============================] - 32s 28ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.5585 - val_accuracy: 0.7100\n",
            "Epoch 22/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 2.4933 - val_accuracy: 0.7240\n",
            "Epoch 23/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 2.5942 - val_accuracy: 0.7360\n",
            "Epoch 24/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 2.3874 - val_accuracy: 0.7200\n",
            "Epoch 25/30\n",
            "1125/1125 [==============================] - 32s 29ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 2.3843 - val_accuracy: 0.7260\n",
            "Epoch 26/30\n",
            "1125/1125 [==============================] - 33s 29ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 2.4986 - val_accuracy: 0.7240\n",
            "Epoch 27/30\n",
            "1125/1125 [==============================] - 32s 29ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 2.5024 - val_accuracy: 0.7320\n",
            "Epoch 28/30\n",
            "1125/1125 [==============================] - 32s 29ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 2.4794 - val_accuracy: 0.7440\n",
            "Epoch 29/30\n",
            "1125/1125 [==============================] - 31s 28ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 2.6749 - val_accuracy: 0.7360\n",
            "Epoch 30/30\n",
            "1125/1125 [==============================] - 31s 27ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 2.4743 - val_accuracy: 0.7360\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dbf3ae9e770>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#noble bhai\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adafactor(1e-3), metrics=['accuracy'])\n",
        "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=100, batch_size=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIHtzjk1mEoz",
        "outputId": "9fe9badc-77b5-43e6-fc49-48161cd75390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1188/1188 [==============================] - 93s 48ms/step - loss: 0.6847 - accuracy: 0.5648 - val_loss: 0.6472 - val_accuracy: 0.6280\n",
            "Epoch 2/100\n",
            "1188/1188 [==============================] - 35s 30ms/step - loss: 0.6294 - accuracy: 0.6478 - val_loss: 0.5496 - val_accuracy: 0.7080\n",
            "Epoch 3/100\n",
            "1188/1188 [==============================] - 34s 28ms/step - loss: 0.5005 - accuracy: 0.7598 - val_loss: 0.7148 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.4082 - accuracy: 0.8185 - val_loss: 0.5657 - val_accuracy: 0.7520\n",
            "Epoch 5/100\n",
            "1188/1188 [==============================] - 34s 29ms/step - loss: 0.3252 - accuracy: 0.8613 - val_loss: 0.6449 - val_accuracy: 0.7480\n",
            "Epoch 6/100\n",
            "1188/1188 [==============================] - 35s 30ms/step - loss: 0.2454 - accuracy: 0.9011 - val_loss: 0.6342 - val_accuracy: 0.7600\n",
            "Epoch 7/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.1699 - accuracy: 0.9371 - val_loss: 0.8421 - val_accuracy: 0.7320\n",
            "Epoch 8/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.1132 - accuracy: 0.9589 - val_loss: 0.8389 - val_accuracy: 0.7600\n",
            "Epoch 9/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0709 - accuracy: 0.9773 - val_loss: 1.1556 - val_accuracy: 0.7480\n",
            "Epoch 10/100\n",
            "1188/1188 [==============================] - 34s 28ms/step - loss: 0.0490 - accuracy: 0.9863 - val_loss: 1.3787 - val_accuracy: 0.7480\n",
            "Epoch 11/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 1.4447 - val_accuracy: 0.7520\n",
            "Epoch 12/100\n",
            "1188/1188 [==============================] - 33s 27ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 1.5896 - val_accuracy: 0.7400\n",
            "Epoch 13/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 1.8300 - val_accuracy: 0.7320\n",
            "Epoch 14/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 1.9729 - val_accuracy: 0.7480\n",
            "Epoch 15/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 2.0404 - val_accuracy: 0.7440\n",
            "Epoch 16/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 2.0148 - val_accuracy: 0.7360\n",
            "Epoch 17/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 1.9763 - val_accuracy: 0.7600\n",
            "Epoch 18/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 1.9389 - val_accuracy: 0.7360\n",
            "Epoch 19/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 2.0190 - val_accuracy: 0.7360\n",
            "Epoch 20/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 2.1728 - val_accuracy: 0.7360\n",
            "Epoch 21/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 2.3978 - val_accuracy: 0.7520\n",
            "Epoch 22/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 1.9655 - val_accuracy: 0.7560\n",
            "Epoch 23/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 2.4220 - val_accuracy: 0.7400\n",
            "Epoch 24/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 2.2854 - val_accuracy: 0.7560\n",
            "Epoch 25/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 2.5443 - val_accuracy: 0.7360\n",
            "Epoch 26/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 2.3576 - val_accuracy: 0.7600\n",
            "Epoch 27/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.3309 - val_accuracy: 0.7640\n",
            "Epoch 28/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 2.3981 - val_accuracy: 0.7480\n",
            "Epoch 29/100\n",
            "1188/1188 [==============================] - 33s 27ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 2.4088 - val_accuracy: 0.7480\n",
            "Epoch 30/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.2884 - val_accuracy: 0.7560\n",
            "Epoch 31/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.4038 - val_accuracy: 0.7560\n",
            "Epoch 32/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 2.2823 - val_accuracy: 0.7720\n",
            "Epoch 33/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 2.3095 - val_accuracy: 0.7600\n",
            "Epoch 34/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.3901 - val_accuracy: 0.7480\n",
            "Epoch 35/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 2.3341 - val_accuracy: 0.7520\n",
            "Epoch 36/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 2.2309 - val_accuracy: 0.7520\n",
            "Epoch 37/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 2.1923 - val_accuracy: 0.7520\n",
            "Epoch 38/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 2.2401 - val_accuracy: 0.7400\n",
            "Epoch 39/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 2.3596 - val_accuracy: 0.7400\n",
            "Epoch 40/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 2.4459 - val_accuracy: 0.7560\n",
            "Epoch 41/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 2.4928 - val_accuracy: 0.7560\n",
            "Epoch 42/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 2.4807 - val_accuracy: 0.7600\n",
            "Epoch 43/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 2.4214 - val_accuracy: 0.7560\n",
            "Epoch 44/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 2.2584 - val_accuracy: 0.7640\n",
            "Epoch 45/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 2.1567 - val_accuracy: 0.7600\n",
            "Epoch 46/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.2966 - val_accuracy: 0.7560\n",
            "Epoch 47/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.2348 - val_accuracy: 0.7520\n",
            "Epoch 48/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 2.1932 - val_accuracy: 0.7520\n",
            "Epoch 49/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 2.2136 - val_accuracy: 0.7680\n",
            "Epoch 50/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 2.1651 - val_accuracy: 0.7720\n",
            "Epoch 51/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.1941 - val_accuracy: 0.7600\n",
            "Epoch 52/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 2.0880 - val_accuracy: 0.7680\n",
            "Epoch 53/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.1770 - val_accuracy: 0.7640\n",
            "Epoch 54/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 2.1725 - val_accuracy: 0.7560\n",
            "Epoch 55/100\n",
            "1188/1188 [==============================] - 31s 27ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.2156 - val_accuracy: 0.7480\n",
            "Epoch 56/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 2.1832 - val_accuracy: 0.7600\n",
            "Epoch 57/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 2.1955 - val_accuracy: 0.7640\n",
            "Epoch 58/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 2.3747 - val_accuracy: 0.7320\n",
            "Epoch 59/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 2.2479 - val_accuracy: 0.7480\n",
            "Epoch 60/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 2.1610 - val_accuracy: 0.7600\n",
            "Epoch 61/100\n",
            "1188/1188 [==============================] - 31s 26ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.2694 - val_accuracy: 0.7640\n",
            "Epoch 62/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.2506 - val_accuracy: 0.7440\n",
            "Epoch 63/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 2.2571 - val_accuracy: 0.7600\n",
            "Epoch 64/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 2.2468 - val_accuracy: 0.7600\n",
            "Epoch 65/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 2.3405 - val_accuracy: 0.7360\n",
            "Epoch 66/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 2.4218 - val_accuracy: 0.7680\n",
            "Epoch 67/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 2.2923 - val_accuracy: 0.7640\n",
            "Epoch 68/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 2.2865 - val_accuracy: 0.7520\n",
            "Epoch 69/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.3824 - val_accuracy: 0.7440\n",
            "Epoch 70/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.4240 - val_accuracy: 0.7560\n",
            "Epoch 71/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.4774 - val_accuracy: 0.7440\n",
            "Epoch 72/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 2.4339 - val_accuracy: 0.7640\n",
            "Epoch 73/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 2.5352 - val_accuracy: 0.7320\n",
            "Epoch 74/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.4794 - val_accuracy: 0.7480\n",
            "Epoch 75/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 2.4883 - val_accuracy: 0.7440\n",
            "Epoch 76/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 2.3355 - val_accuracy: 0.7480\n",
            "Epoch 77/100\n",
            "1188/1188 [==============================] - 33s 27ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 2.3190 - val_accuracy: 0.7560\n",
            "Epoch 78/100\n",
            "1188/1188 [==============================] - 33s 27ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 2.4838 - val_accuracy: 0.7560\n",
            "Epoch 79/100\n",
            "1188/1188 [==============================] - 33s 27ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 2.5464 - val_accuracy: 0.7480\n",
            "Epoch 80/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 2.4320 - val_accuracy: 0.7480\n",
            "Epoch 81/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.4051 - val_accuracy: 0.7360\n",
            "Epoch 82/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 2.3617 - val_accuracy: 0.7480\n",
            "Epoch 83/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 2.3101 - val_accuracy: 0.7600\n",
            "Epoch 84/100\n",
            "1188/1188 [==============================] - 32s 27ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 2.2911 - val_accuracy: 0.7240\n",
            "Epoch 85/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 2.2233 - val_accuracy: 0.7600\n",
            "Epoch 86/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.5705 - val_accuracy: 0.7160\n",
            "Epoch 87/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 2.4490 - val_accuracy: 0.7400\n",
            "Epoch 88/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 2.3048 - val_accuracy: 0.7600\n",
            "Epoch 89/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 2.4121 - val_accuracy: 0.7160\n",
            "Epoch 90/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 2.2775 - val_accuracy: 0.7440\n",
            "Epoch 91/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 2.3059 - val_accuracy: 0.7480\n",
            "Epoch 92/100\n",
            "1188/1188 [==============================] - 34s 29ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 2.3580 - val_accuracy: 0.7480\n",
            "Epoch 93/100\n",
            "1188/1188 [==============================] - 34s 29ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 2.2981 - val_accuracy: 0.7400\n",
            "Epoch 94/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 2.3146 - val_accuracy: 0.7360\n",
            "Epoch 95/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 2.3011 - val_accuracy: 0.7400\n",
            "Epoch 96/100\n",
            "1188/1188 [==============================] - 34s 28ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 2.4053 - val_accuracy: 0.7400\n",
            "Epoch 97/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 9.7778e-04 - accuracy: 0.9998 - val_loss: 2.2773 - val_accuracy: 0.7360\n",
            "Epoch 98/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.3849 - val_accuracy: 0.7320\n",
            "Epoch 99/100\n",
            "1188/1188 [==============================] - 34s 28ms/step - loss: 7.6629e-04 - accuracy: 0.9998 - val_loss: 2.4007 - val_accuracy: 0.7320\n",
            "Epoch 100/100\n",
            "1188/1188 [==============================] - 33s 28ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 2.3387 - val_accuracy: 0.7440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b2443590e50>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WkYMvLAlmEd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X6XSyVYPmEbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_9XvkvFmEWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IwwZflQmETp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVvI-hHXmERR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnzea4LomEOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uv3TgGVamEL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0CoFSHZZmEJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcPj-JH7mEGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ucZD2HBVwpN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Mish(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Mish, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs * tf.tanh(tf.nn.softplus(inputs))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mish, self).get_config()\n",
        "        return config"
      ],
      "metadata": {
        "id": "aYE7HQEidYNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED6conXvbINX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93684a7d-1267-4611-efaf-a762f3c3b38a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(tf.keras.layers.Bidirectional(LSTM(150, activation=tf.keras.activations.mish)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpFc5fPfbMCu",
        "outputId": "0e94af45-6023-4fd9-a398-7db2d60149b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 95s 555ms/step - loss: 0.6670 - accuracy: 0.5958 - val_loss: 0.6467 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 34s 486ms/step - loss: 0.6006 - accuracy: 0.7602 - val_loss: 0.5844 - val_accuracy: 0.7040\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 32s 452ms/step - loss: 0.4394 - accuracy: 0.8400 - val_loss: 0.4999 - val_accuracy: 0.7560\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 31s 442ms/step - loss: 1.2825 - accuracy: 0.8960 - val_loss: 0.5130 - val_accuracy: 0.7120\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 30s 420ms/step - loss: 0.2853 - accuracy: 0.9260 - val_loss: 0.4865 - val_accuracy: 0.7520\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 30s 425ms/step - loss: 0.2091 - accuracy: 0.9404 - val_loss: 0.4857 - val_accuracy: 0.7560\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 29s 404ms/step - loss: 0.1520 - accuracy: 0.9538 - val_loss: 0.5177 - val_accuracy: 0.7400\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 29s 410ms/step - loss: 0.1114 - accuracy: 0.9653 - val_loss: 0.5669 - val_accuracy: 0.7480\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 30s 417ms/step - loss: 0.0897 - accuracy: 0.9758 - val_loss: 0.5541 - val_accuracy: 0.7520\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 29s 410ms/step - loss: 0.0678 - accuracy: 0.9838 - val_loss: 0.6245 - val_accuracy: 0.7480\n",
            "8/8 [==============================] - 0s 27ms/step\n",
            "Test Accuracy: 0.696\n",
            "Precision: 0.6863905325443787\n",
            "Recall: 0.8345323741007195\n",
            "F1 Score: 0.7532467532467532\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.fit(X_train, y_train_hate, validation_data=(X_val, y_val_hate), epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test_hate, y_pred)\n",
        "precision = precision_score(y_test_hate, y_pred)\n",
        "recall = recall_score(y_test_hate, y_pred)\n",
        "f1 = f1_score(y_test_hate, y_pred)\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of folds for k-fold cross-validation\n",
        "n_splits = 5  # You can adjust this value as needed\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Create a StratifiedKFold object to split the data\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Create and compile your model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(tf.keras.layers.Bidirectional(LSTM(100)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "# Loop over the different folds\n",
        "for train_index, val_index in skf.split(X_train, y_train_hate):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train_hate[train_index], y_train_hate[val_index]\n",
        "\n",
        "\n",
        "    # # Train your model on the current fold\n",
        "    # model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=8, verbose=0)  # Set verbose to 0 to suppress training output\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    history =   model.fit(X_train_fold, y_train_fold, epochs=30, batch_size=4, verbose=0)  # Set verbose to 0 to suppress training output\n",
        "\n",
        "\n",
        "    train_loss, train_accuracy = model.evaluate(X_train_fold, y_train_fold, verbose=0)\n",
        "    print(f'Fold {fold_no} Training Loss: {train_loss}')\n",
        "    print(f'Fold {fold_no} Training Accuracy: {train_accuracy}')\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Loss: {val_loss}')\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    fold_no +=1\n",
        "\n",
        "\n",
        "\n",
        "#     # Evaluate the model on the validation fold\n",
        "#     y_pred = model.predict(X_val_fold)\n",
        "#     y_pred = (y_pred > 0.5)\n",
        "\n",
        "#     # Calculate evaluation metrics for this fold\n",
        "#     accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "#     precision = precision_score(y_val_fold, y_pred)\n",
        "#     recall = recall_score(y_val_fold, y_pred)\n",
        "#     f1 = f1_score(y_val_fold, y_pred)\n",
        "\n",
        "#     # Append the metrics to the lists\n",
        "#     accuracy_scores.append(accuracy)\n",
        "#     precision_scores.append(precision)\n",
        "#     recall_scores.append(recall)\n",
        "#     f1_scores.append(f1)\n",
        "\n",
        "# # Calculate and print the mean and standard deviation of evaluation metrics\n",
        "# print(f\"Mean Accuracy: {np.mean(accuracy_scores):.2f}\")\n",
        "# print(f\"Mean Precision: {np.mean(precision_scores):.2f}\")\n",
        "# print(f\"Mean Recall: {np.mean(recall_scores):.2f}\")\n",
        "# print(f\"Mean F1 Score: {np.mean(f1_scores):.2f}\")\n",
        "\n",
        "# # Optionally, you can also print the standard deviation\n",
        "# print(f\"Standard Deviation of Accuracy: {np.std(accuracy_scores):.2f}\")\n",
        "# print(f\"Standard Deviation of Precision: {np.std(precision_scores):.2f}\")\n",
        "# print(f\"Standard Deviation of Recall: {np.std(recall_scores):.2f}\")\n",
        "# print(f\"Standard Deviation of F1 Score: {np.std(f1_scores):.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DBXb1nqlGCT",
        "outputId": "a7f2d674-2c3c-40b6-d491-49de30bfd62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Fold 1 Training Loss: 5.4361048995588135e-09\n",
            "Fold 1 Training Accuracy: 1.0\n",
            "Fold 1 Validation Loss: 4.045029163360596\n",
            "Fold 1 Validation Accuracy: 0.6833333373069763\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Fold 2 Training Loss: 0.0003851827059406787\n",
            "Fold 2 Training Accuracy: 0.9997222423553467\n",
            "Fold 2 Validation Loss: 0.3124501407146454\n",
            "Fold 2 Validation Accuracy: 0.9511111378669739\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Fold 3 Training Loss: 3.80992126736146e-09\n",
            "Fold 3 Training Accuracy: 1.0\n",
            "Fold 3 Validation Loss: 0.0686328187584877\n",
            "Fold 3 Validation Accuracy: 0.9877777695655823\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Fold 4 Training Loss: 0.0003977434535045177\n",
            "Fold 4 Training Accuracy: 0.9997222423553467\n",
            "Fold 4 Validation Loss: 0.019438281655311584\n",
            "Fold 4 Validation Accuracy: 0.9988889098167419\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Fold 5 Training Loss: 0.0003883047611452639\n",
            "Fold 5 Training Accuracy: 0.9997222423553467\n",
            "Fold 5 Validation Loss: 4.174307468929328e-05\n",
            "Fold 5 Validation Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-39JZz5sc_u",
        "outputId": "3128ad9b-7a57-456d-adfe-6489ec777125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-17 08:12:57--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.91, 18.165.83.44, 18.165.83.79, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3934298272 (3.7G) [application/octet-stream]\n",
            "Saving to: cc.bn.300.bin.gz\n",
            "\n",
            "cc.bn.300.bin.gz    100%[===================>]   3.66G  16.1MB/s    in 3m 45s  \n",
            "\n",
            "2023-10-17 08:16:43 (16.7 MB/s) - cc.bn.300.bin.gz saved [3934298272/3934298272]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oR-HhVRse5s",
        "outputId": "615a2b36-4ad4-43e2-e6d7-c05d17d19dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.6633 - accuracy: 0.6190 - val_loss: 0.6679 - val_accuracy: 0.5660\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.6563 - accuracy: 0.6250 - val_loss: 0.6670 - val_accuracy: 0.5640\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6499 - accuracy: 0.6250 - val_loss: 0.6672 - val_accuracy: 0.5640\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6443 - accuracy: 0.6302 - val_loss: 0.6635 - val_accuracy: 0.5740\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6364 - accuracy: 0.6495 - val_loss: 0.6578 - val_accuracy: 0.5800\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6272 - accuracy: 0.6770 - val_loss: 0.6522 - val_accuracy: 0.6140\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.6177 - accuracy: 0.6980 - val_loss: 0.6472 - val_accuracy: 0.6160\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6077 - accuracy: 0.7100 - val_loss: 0.6425 - val_accuracy: 0.6300\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.5962 - accuracy: 0.7215 - val_loss: 0.6379 - val_accuracy: 0.6340\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5828 - accuracy: 0.7360 - val_loss: 0.6339 - val_accuracy: 0.6380\n",
            "16/16 [==============================] - 1s 31ms/step\n",
            "Test Accuracy: 0.626\n",
            "Precision: 0.6394984326018809\n",
            "Recall: 0.7391304347826086\n",
            "F1 Score: 0.6857142857142856\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train_hate, validation_data=(X_val, y_val_hate), epochs=10, batch_size=5)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test_hate, y_pred)\n",
        "precision = precision_score(y_test_hate, y_pred)\n",
        "recall = recall_score(y_test_hate, y_pred)\n",
        "f1 = f1_score(y_test_hate, y_pred)\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have defined your model and compiled it already\n",
        "\n",
        "# Combine X_train and X_temp, y_train_hate and y_temp_hate, y_train_type and y_temp_type\n",
        "all_X = np.concatenate((X_train, X_temp), axis=0)\n",
        "all_y_hate = np.concatenate((y_train_hate, y_temp_hate), axis=0)\n",
        "all_y_type = np.concatenate((y_train_type, y_temp_type), axis=0)\n",
        "\n",
        "# Set the number of folds (e.g., 5-fold cross-validation)\n",
        "n_splits = 5\n",
        "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "all_test_accuracy = []\n",
        "all_precision = []\n",
        "all_recall = []\n",
        "all_f1 = []\n",
        "\n",
        "# Iterate over folds\n",
        "for train_index, test_index in kf.split(all_X, all_y_hate):\n",
        "    X_train_fold, X_val_fold = all_X[train_index], all_X[test_index]\n",
        "    y_train_fold, y_val_fold = all_y_hate[train_index], all_y_hate[test_index]\n",
        "\n",
        "    # Assuming you have defined your model and compiled it already\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "    model.add(tf.keras.layers.Bidirectional(LSTM(100)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Assuming max_sequence_length is defined\n",
        "    model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=20, batch_size=4)\n",
        "\n",
        "    # Make predictions on the test set of the current fold\n",
        "    y_pred_fold = model.predict(X_val_fold)\n",
        "    y_pred_fold = (y_pred_fold > 0.5)\n",
        "\n",
        "    # Calculate evaluation metrics for the current fold\n",
        "    test_accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
        "    precision_fold = precision_score(y_val_fold, y_pred_fold)\n",
        "    recall_fold = recall_score(y_val_fold, y_pred_fold)\n",
        "    f1_fold = f1_score(y_val_fold, y_pred_fold)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    all_test_accuracy.append(test_accuracy_fold)\n",
        "    all_precision.append(precision_fold)\n",
        "    all_recall.append(recall_fold)\n",
        "    all_f1.append(f1_fold)\n",
        "\n",
        "# Calculate and print average metrics across all folds\n",
        "average_test_accuracy = np.mean(all_test_accuracy)\n",
        "average_precision = np.mean(all_precision)\n",
        "average_recall = np.mean(all_recall)\n",
        "average_f1 = np.mean(all_f1)\n",
        "\n",
        "print(f'Average Test Accuracy: {average_test_accuracy}')\n",
        "print(f'Average Precision: {average_precision}')\n",
        "print(f'Average Recall: {average_recall}')\n",
        "print(f'Average F1 Score: {average_f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slF_0Qnh_xSY",
        "outputId": "eca28746-2ff6-46b7-8594-3efa95561111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 24s 21ms/step - loss: 0.6160 - accuracy: 0.6520 - val_loss: 0.5504 - val_accuracy: 0.6990\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2765 - accuracy: 0.8867 - val_loss: 0.6252 - val_accuracy: 0.7200\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0747 - accuracy: 0.9710 - val_loss: 0.8693 - val_accuracy: 0.7250\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.2156 - val_accuracy: 0.7060\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 1.2796 - val_accuracy: 0.7040\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 1.5435 - val_accuracy: 0.7140\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.8207 - val_accuracy: 0.7000\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.2542e-04 - accuracy: 1.0000 - val_loss: 1.8428 - val_accuracy: 0.7060\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 6.0038e-05 - accuracy: 1.0000 - val_loss: 2.0208 - val_accuracy: 0.7040\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 3.0049e-05 - accuracy: 1.0000 - val_loss: 2.1146 - val_accuracy: 0.7050\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.7666e-05 - accuracy: 1.0000 - val_loss: 2.2283 - val_accuracy: 0.7070\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 9.6757e-06 - accuracy: 1.0000 - val_loss: 2.3324 - val_accuracy: 0.7090\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.3918e-06 - accuracy: 1.0000 - val_loss: 2.4641 - val_accuracy: 0.7090\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 3.0001e-06 - accuracy: 1.0000 - val_loss: 2.6011 - val_accuracy: 0.7070\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.5547e-06 - accuracy: 1.0000 - val_loss: 2.7229 - val_accuracy: 0.7050\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 8.2360e-07 - accuracy: 1.0000 - val_loss: 2.8800 - val_accuracy: 0.7040\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 4.3600e-07 - accuracy: 1.0000 - val_loss: 2.9934 - val_accuracy: 0.7050\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 2.2875e-07 - accuracy: 1.0000 - val_loss: 3.1509 - val_accuracy: 0.7050\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 1.1717e-07 - accuracy: 1.0000 - val_loss: 3.2914 - val_accuracy: 0.7080\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 6.3179e-08 - accuracy: 1.0000 - val_loss: 3.4041 - val_accuracy: 0.7080\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 25s 20ms/step - loss: 0.6160 - accuracy: 0.6560 - val_loss: 0.5633 - val_accuracy: 0.7010\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2775 - accuracy: 0.8857 - val_loss: 0.5709 - val_accuracy: 0.7440\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0822 - accuracy: 0.9743 - val_loss: 0.9164 - val_accuracy: 0.7140\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 1.2301 - val_accuracy: 0.7030\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 1.2503 - val_accuracy: 0.7080\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.5125 - val_accuracy: 0.6990\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 1.5174 - val_accuracy: 0.7020\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 1.5727 - val_accuracy: 0.7100\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.8015 - val_accuracy: 0.7120\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: 1.3850 - val_accuracy: 0.7070\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 1.4210 - val_accuracy: 0.7100\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 1.5375 - val_accuracy: 0.7170\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 7.2368e-04 - accuracy: 0.9995 - val_loss: 1.7471 - val_accuracy: 0.7130\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.9449e-04 - accuracy: 0.9995 - val_loss: 1.7904 - val_accuracy: 0.7130\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.5727e-04 - accuracy: 0.9998 - val_loss: 1.8793 - val_accuracy: 0.7130\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.6399e-04 - accuracy: 0.9998 - val_loss: 1.9379 - val_accuracy: 0.7080\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.0507e-04 - accuracy: 0.9998 - val_loss: 2.0487 - val_accuracy: 0.7060\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.7522e-04 - accuracy: 0.9998 - val_loss: 2.1234 - val_accuracy: 0.7070\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.3503e-04 - accuracy: 0.9995 - val_loss: 2.2320 - val_accuracy: 0.7050\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 4.4872e-04 - accuracy: 0.9995 - val_loss: 2.3169 - val_accuracy: 0.7090\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 23s 20ms/step - loss: 0.6158 - accuracy: 0.6600 - val_loss: 0.5529 - val_accuracy: 0.7100\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2632 - accuracy: 0.8955 - val_loss: 0.6406 - val_accuracy: 0.7050\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0717 - accuracy: 0.9762 - val_loss: 0.8632 - val_accuracy: 0.7100\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 1.1836 - val_accuracy: 0.6940\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 1.4901 - val_accuracy: 0.7040\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 1.1773 - val_accuracy: 0.7050\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3024 - val_accuracy: 0.6960\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.4791 - val_accuracy: 0.7000\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.7785 - val_accuracy: 0.6910\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 1.9016 - val_accuracy: 0.6920\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 9.0347e-04 - accuracy: 0.9992 - val_loss: 2.1701 - val_accuracy: 0.6950\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.7161 - val_accuracy: 0.7030\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.8771 - val_accuracy: 0.6880\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 1.7426 - val_accuracy: 0.6820\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 6.7792e-04 - accuracy: 0.9998 - val_loss: 1.9357 - val_accuracy: 0.6850\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 2.0678 - val_accuracy: 0.6480\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 1.7170 - val_accuracy: 0.6680\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 1.9694 - val_accuracy: 0.6850\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.1778e-04 - accuracy: 0.9995 - val_loss: 2.0371 - val_accuracy: 0.6860\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.0202e-04 - accuracy: 0.9995 - val_loss: 2.1003 - val_accuracy: 0.6850\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 24s 20ms/step - loss: 0.6059 - accuracy: 0.6610 - val_loss: 0.5611 - val_accuracy: 0.7100\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2821 - accuracy: 0.8890 - val_loss: 0.6270 - val_accuracy: 0.7330\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0987 - accuracy: 0.9675 - val_loss: 0.8219 - val_accuracy: 0.7240\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.9730 - val_accuracy: 0.7220\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 1.1610 - val_accuracy: 0.7240\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 1.3343 - val_accuracy: 0.7270\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 1.4044 - val_accuracy: 0.7230\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.7209 - val_accuracy: 0.7240\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.7567 - val_accuracy: 0.7200\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 6.9115e-04 - accuracy: 0.9998 - val_loss: 1.9335 - val_accuracy: 0.7200\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 1.4612 - val_accuracy: 0.7270\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 1.5185 - val_accuracy: 0.7350\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.5385 - val_accuracy: 0.7300\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 6.0123e-04 - accuracy: 0.9998 - val_loss: 1.6533 - val_accuracy: 0.7350\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.8796e-04 - accuracy: 0.9995 - val_loss: 1.7252 - val_accuracy: 0.7350\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.4452e-04 - accuracy: 0.9998 - val_loss: 1.7915 - val_accuracy: 0.7340\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 4.3472e-04 - accuracy: 0.9995 - val_loss: 1.8671 - val_accuracy: 0.7330\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.3483e-04 - accuracy: 0.9998 - val_loss: 1.9166 - val_accuracy: 0.7320\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.1726e-04 - accuracy: 0.9995 - val_loss: 2.0024 - val_accuracy: 0.7300\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 3.9531e-04 - accuracy: 0.9995 - val_loss: 2.0909 - val_accuracy: 0.7290\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 24s 21ms/step - loss: 0.6213 - accuracy: 0.6497 - val_loss: 0.5374 - val_accuracy: 0.7410\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2633 - accuracy: 0.8925 - val_loss: 0.6446 - val_accuracy: 0.7230\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0826 - accuracy: 0.9688 - val_loss: 0.8727 - val_accuracy: 0.7000\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 1.1486 - val_accuracy: 0.7260\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 1.1547 - val_accuracy: 0.7170\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.2452 - val_accuracy: 0.7090\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 1.2615 - val_accuracy: 0.6970\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 1.4903 - val_accuracy: 0.7120\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.5625 - val_accuracy: 0.7080\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 6.8026e-04 - accuracy: 0.9995 - val_loss: 1.7009 - val_accuracy: 0.7100\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.9924e-04 - accuracy: 0.9995 - val_loss: 1.8343 - val_accuracy: 0.7070\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 5.6481e-04 - accuracy: 0.9998 - val_loss: 1.9592 - val_accuracy: 0.7060\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.9281e-04 - accuracy: 0.9995 - val_loss: 2.0327 - val_accuracy: 0.7070\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 4.4913e-04 - accuracy: 0.9998 - val_loss: 2.1858 - val_accuracy: 0.7110\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 4.2042e-04 - accuracy: 0.9995 - val_loss: 2.2958 - val_accuracy: 0.7090\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 4.4081e-04 - accuracy: 0.9998 - val_loss: 2.3614 - val_accuracy: 0.7090\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.0929e-04 - accuracy: 0.9995 - val_loss: 2.5121 - val_accuracy: 0.7110\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.3200 - val_accuracy: 0.7080\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 1.3726 - val_accuracy: 0.7050\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.5378 - val_accuracy: 0.7140\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "Average Test Accuracy: 0.709\n",
            "Average Precision: 0.7678338557707169\n",
            "Average Recall: 0.6988796979407309\n",
            "Average F1 Score: 0.730926951770114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have defined your model and compiled it already\n",
        "\n",
        "# Combine X_train and X_temp, y_train_hate and y_temp_hate, y_train_type and y_temp_type\n",
        "all_X = np.concatenate((X_train, X_temp), axis=0)\n",
        "all_y_hate = np.concatenate((y_train_hate, y_temp_hate), axis=0)\n",
        "all_y_type = np.concatenate((y_train_type, y_temp_type), axis=0)\n",
        "\n",
        "# Set the number of folds (e.g., 5-fold cross-validation)\n",
        "n_splits = 5\n",
        "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "all_train_accuracy = []\n",
        "all_test_accuracy = []\n",
        "all_precision = []\n",
        "all_recall = []\n",
        "all_f1 = []\n",
        "\n",
        "# Iterate over folds\n",
        "for train_index, test_index in kf.split(all_X, all_y_hate):\n",
        "    X_train_fold, X_val_fold = all_X[train_index], all_X[test_index]\n",
        "    y_train_fold, y_val_fold = all_y_hate[train_index], all_y_hate[test_index]\n",
        "\n",
        "    # Assuming you have defined your model and compiled it already\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "    model.add(tf.keras.layers.Bidirectional(LSTM(100)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Assuming max_sequence_length is defined\n",
        "    history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10, batch_size=4)\n",
        "\n",
        "    # Make predictions on the test set of the current fold\n",
        "    y_pred_fold = model.predict(X_val_fold)\n",
        "    y_pred_fold = (y_pred_fold > 0.5)\n",
        "\n",
        "    # Calculate evaluation metrics for the current fold\n",
        "    train_accuracy_fold = history.history['accuracy'][-1]\n",
        "    test_accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
        "    precision_fold = precision_score(y_val_fold, y_pred_fold)\n",
        "    recall_fold = recall_score(y_val_fold, y_pred_fold)\n",
        "    f1_fold = f1_score(y_val_fold, y_pred_fold)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    all_train_accuracy.append(train_accuracy_fold)\n",
        "    all_test_accuracy.append(test_accuracy_fold)\n",
        "    all_precision.append(precision_fold)\n",
        "    all_recall.append(recall_fold)\n",
        "    all_f1.append(f1_fold)\n",
        "\n",
        "# Calculate and print average metrics across all folds\n",
        "average_train_accuracy = np.mean(all_train_accuracy)\n",
        "average_test_accuracy = np.mean(all_test_accuracy)\n",
        "average_precision = np.mean(all_precision)\n",
        "average_recall = np.mean(all_recall)\n",
        "average_f1 = np.mean(all_f1)\n",
        "\n",
        "print(f'Average Training Accuracy: {average_train_accuracy}')\n",
        "print(f'Average Test Accuracy: {average_test_accuracy}')\n",
        "print(f'Average Precision: {average_precision}')\n",
        "print(f'Average Recall: {average_recall}')\n",
        "print(f'Average F1 Score: {average_f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j21KQ2vtASXj",
        "outputId": "11e4fa5a-07c0-4ffa-9108-e20a9643e73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 22s 19ms/step - loss: 0.6160 - accuracy: 0.6500 - val_loss: 0.5382 - val_accuracy: 0.7220\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2639 - accuracy: 0.8923 - val_loss: 0.6109 - val_accuracy: 0.7120\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0921 - accuracy: 0.9668 - val_loss: 0.7804 - val_accuracy: 0.7140\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.9584 - val_accuracy: 0.7130\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 1.6085 - val_accuracy: 0.7020\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.6854 - val_accuracy: 0.7180\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 1.8995e-04 - accuracy: 1.0000 - val_loss: 1.8148 - val_accuracy: 0.7050\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 4.9182e-05 - accuracy: 1.0000 - val_loss: 2.0537 - val_accuracy: 0.7070\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 1.5806e-05 - accuracy: 1.0000 - val_loss: 2.3151 - val_accuracy: 0.7100\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 6.0346e-06 - accuracy: 1.0000 - val_loss: 2.4816 - val_accuracy: 0.7120\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 23s 20ms/step - loss: 0.6116 - accuracy: 0.6568 - val_loss: 0.5518 - val_accuracy: 0.7180\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2800 - accuracy: 0.8857 - val_loss: 0.5679 - val_accuracy: 0.7410\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0789 - accuracy: 0.9740 - val_loss: 0.7253 - val_accuracy: 0.7150\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 1.0211 - val_accuracy: 0.7130\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 1.1066 - val_accuracy: 0.7110\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.5196 - val_accuracy: 0.7230\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.7896 - val_accuracy: 0.6940\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 9.3445e-04 - accuracy: 0.9998 - val_loss: 1.8998 - val_accuracy: 0.7080\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 6.9539e-04 - accuracy: 0.9998 - val_loss: 1.9703 - val_accuracy: 0.6980\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.5297e-04 - accuracy: 0.9998 - val_loss: 2.2046 - val_accuracy: 0.6950\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 23s 20ms/step - loss: 0.6133 - accuracy: 0.6522 - val_loss: 0.5560 - val_accuracy: 0.7130\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2662 - accuracy: 0.8940 - val_loss: 0.6588 - val_accuracy: 0.7160\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 1.2272 - val_accuracy: 0.7220\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 1.2158 - val_accuracy: 0.7080\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 1.5473 - val_accuracy: 0.6900\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.2234 - val_accuracy: 0.7120\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 1.3588 - val_accuracy: 0.7000\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 1.6178 - val_accuracy: 0.7010\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.8554 - val_accuracy: 0.7090\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.7033 - val_accuracy: 0.7010\n",
            "32/32 [==============================] - 1s 4ms/step\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 24s 20ms/step - loss: 0.6075 - accuracy: 0.6532 - val_loss: 0.5705 - val_accuracy: 0.7240\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2732 - accuracy: 0.8975 - val_loss: 0.6625 - val_accuracy: 0.7170\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0872 - accuracy: 0.9688 - val_loss: 0.8440 - val_accuracy: 0.7190\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 1.1085 - val_accuracy: 0.7260\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 1.1382 - val_accuracy: 0.7170\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 1.2197 - val_accuracy: 0.7270\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.4577 - val_accuracy: 0.7250\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 1.6194 - val_accuracy: 0.7130\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 1.2118 - val_accuracy: 0.6980\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 1.3675 - val_accuracy: 0.7250\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 23s 20ms/step - loss: 0.6156 - accuracy: 0.6460 - val_loss: 0.5302 - val_accuracy: 0.7250\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2787 - accuracy: 0.8873 - val_loss: 0.5763 - val_accuracy: 0.7190\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 0.8109 - val_accuracy: 0.7220\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 1.1172 - val_accuracy: 0.7010\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 1.3642 - val_accuracy: 0.7070\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 1.8140 - val_accuracy: 0.7130\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.8880 - val_accuracy: 0.7090\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 7.7278e-04 - accuracy: 0.9998 - val_loss: 1.9835 - val_accuracy: 0.7050\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 7.9408e-04 - accuracy: 0.9998 - val_loss: 1.9820 - val_accuracy: 0.7140\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 1.3766 - val_accuracy: 0.7140\n",
            "32/32 [==============================] - 1s 6ms/step\n",
            "Average Training Accuracy: 0.9976499915122986\n",
            "Average Test Accuracy: 0.7094\n",
            "Average Precision: 0.7681898874461839\n",
            "Average Recall: 0.6999378989989318\n",
            "Average F1 Score: 0.7317685333096445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nO-rvl_ZT_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IhqwCrynZmzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
      ],
      "metadata": {
        "id": "iZz5BCdhZuUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
      ],
      "metadata": {
        "id": "0hcxveoYZyvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "mnb = MultinomialNB()\n",
        "bnb = BernoulliNB()"
      ],
      "metadata": {
        "id": "A36mBoIuZ7yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb.fit(X_train,y_train)\n",
        "y_pred1 = gnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred1))\n",
        "print(confusion_matrix(y_test,y_pred1))\n",
        "print(precision_score(y_test,y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlwHHrRhZ_7k",
        "outputId": "66c2fb2b-44dd-4096-ac78-eb85b97c8873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.645\n",
            "[[299  99]\n",
            " [256 346]]\n",
            "0.7775280898876404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnb.fit(X_train,y_train)\n",
        "y_pred2 = mnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred2))\n",
        "print(confusion_matrix(y_test,y_pred2))\n",
        "print(precision_score(y_test,y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDwe0yMOaJdV",
        "outputId": "c1766887-6444-404a-f9ff-fa943e3633ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.723\n",
            "[[266 132]\n",
            " [145 457]]\n",
            "0.7758913412563667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb.fit(X_train,y_train)\n",
        "y_pred3 = bnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred3))\n",
        "print(confusion_matrix(y_test,y_pred3))\n",
        "print(precision_score(y_test,y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX90ZLOVaPA4",
        "outputId": "1cf83787-de2d-4dc2-975f-8962833bb380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.687\n",
            "[[176 222]\n",
            " [ 91 511]]\n",
            "0.6971350613915416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "wf_fnF7kaVYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#svc = SVC(kernel='rbf', gamma=1.0)\n",
        "svc = SVC(kernel='linear')\n",
        "\n",
        "knc = KNeighborsClassifier()\n",
        "mnb = MultinomialNB()\n",
        "dtc = DecisionTreeClassifier(max_depth=5)\n",
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
        "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
        "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
        "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
        "xgb = XGBClassifier(n_estimators=50,random_state=2)"
      ],
      "metadata": {
        "id": "BLm_NqFwaaXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = {\n",
        "    'SVC' : svc,\n",
        "    'KN' : knc,\n",
        "    'NB': mnb,\n",
        "    'DT': dtc,\n",
        "    'LR': lrc,\n",
        "    'RF': rfc,\n",
        "    'AdaBoost': abc,\n",
        "    'BgC': bc,\n",
        "    'ETC': etc,\n",
        "    'GBDT':gbdt,\n",
        "    'xgb':xgb\n",
        "}"
      ],
      "metadata": {
        "id": "bnP86c1Daes8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test,y_pred)\n",
        "    precision = precision_score(y_test,y_pred)\n",
        "\n",
        "    return accuracy,precision"
      ],
      "metadata": {
        "id": "1ypf2scBajSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_classifier(svc,X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "id": "Wdy5UjdkargO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a69464-efac-417b-c436-9dd3f7500786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.703, 0.7520661157024794)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for name,clf in clfs.items():\n",
        "\n",
        "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
        "\n",
        "    print(\"For \",name)\n",
        "    print(\"Accuracy - \",current_accuracy)\n",
        "    print(\"Precision - \",current_precision)\n",
        "\n",
        "    accuracy_scores.append(current_accuracy)\n",
        "    precision_scores.append(current_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qylskeP1auYk",
        "outputId": "cb9326f0-cffe-453e-9c3f-17e204ed5076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For  SVC\n",
            "Accuracy -  0.703\n",
            "Precision -  0.7520661157024794\n",
            "For  KN\n",
            "Accuracy -  0.611\n",
            "Precision -  0.609007164790174\n",
            "For  NB\n",
            "Accuracy -  0.723\n",
            "Precision -  0.7758913412563667\n",
            "For  DT\n",
            "Accuracy -  0.629\n",
            "Precision -  0.6290502793296089\n",
            "For  LR\n",
            "Accuracy -  0.684\n",
            "Precision -  0.716012084592145\n",
            "For  RF\n",
            "Accuracy -  0.693\n",
            "Precision -  0.7178729689807977\n",
            "For  AdaBoost\n",
            "Accuracy -  0.644\n",
            "Precision -  0.6576923076923077\n",
            "For  BgC\n",
            "Accuracy -  0.669\n",
            "Precision -  0.7174959871589085\n",
            "For  ETC\n",
            "Accuracy -  0.69\n",
            "Precision -  0.7347266881028939\n",
            "For  GBDT\n",
            "Accuracy -  0.642\n",
            "Precision -  0.6455847255369929\n",
            "For  xgb\n",
            "Accuracy -  0.669\n",
            "Precision -  0.6858710562414266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Accuracy',ascending=False)"
      ],
      "metadata": {
        "id": "4C5LvyXea1Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "yXm2HwivhBxF",
        "outputId": "d157b7ad-1b88-40cd-dfe6-c1640016337e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Algorithm  Accuracy  Precision\n",
              "2         NB     0.723   0.775891\n",
              "0        SVC     0.703   0.752066\n",
              "5         RF     0.693   0.717873\n",
              "8        ETC     0.690   0.734727\n",
              "4         LR     0.684   0.716012\n",
              "7        BgC     0.669   0.717496\n",
              "10       xgb     0.669   0.685871\n",
              "6   AdaBoost     0.644   0.657692\n",
              "9       GBDT     0.642   0.645585\n",
              "3         DT     0.629   0.629050\n",
              "1         KN     0.611   0.609007"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69f8c44a-ba49-4993-bc7f-2e8bab94e776\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NB</td>\n",
              "      <td>0.723</td>\n",
              "      <td>0.775891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.703</td>\n",
              "      <td>0.752066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RF</td>\n",
              "      <td>0.693</td>\n",
              "      <td>0.717873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ETC</td>\n",
              "      <td>0.690</td>\n",
              "      <td>0.734727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LR</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.716012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BgC</td>\n",
              "      <td>0.669</td>\n",
              "      <td>0.717496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>xgb</td>\n",
              "      <td>0.669</td>\n",
              "      <td>0.685871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.644</td>\n",
              "      <td>0.657692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GBDT</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.645585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DT</td>\n",
              "      <td>0.629</td>\n",
              "      <td>0.629050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KN</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.609007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69f8c44a-ba49-4993-bc7f-2e8bab94e776')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69f8c44a-ba49-4993-bc7f-2e8bab94e776 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69f8c44a-ba49-4993-bc7f-2e8bab94e776');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed7c23f7-35e7-4ae9-a43f-dc3cd66660c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed7c23f7-35e7-4ae9-a43f-dc3cd66660c8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed7c23f7-35e7-4ae9-a43f-dc3cd66660c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}